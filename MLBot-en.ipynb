{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1896"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [   \n",
    "    \"Hello; Hello\",\n",
    "    \"The machine learning is good I agree, do you know ml +?;\",\n",
    "    \"I love the machine learning! Come to our meetups !!!\",\n",
    "    \"I am passionate about machine learning Come to our meetups !!!\",\n",
    "    \"I like the machine learning Come to our meetups\",\n",
    "    \"What is the ML Machine LEarning\",\n",
    "    \"Do you know the random forest; Yes it is a supervised algorithm that matches a set of trees that corrects for the effect of overtraining sometimes observed!\",\n",
    "    \"Do you know xgboost?; Yes it is an algorithm developed by Kaggle that generates a set of decision trees slightly better than normal for performing a supervised task in ML\",\n",
    "    \"Do you use xgboost?; My colleagues use it for supervised tasks but rarely alone!\",\n",
    "    \"What is xgboost?; it is an algorithm developed by Kaggle that generates a set of decision trees slightly better than normal for performing a supervised task in ML\",\n",
    "    \"Do you like artificial intelligence?; I am artificial intelligence!\",\n",
    "    \"How do you function?; I use a text learning base to learn the context of my responses through various DL algorithms.\",\n",
    "    \"That's the DL Deep Learning.\",\n",
    "    \"What does Deep LEarning mean?; It is a sub-component of the Machine Learning to which the neural networks belong!\",\n",
    "    \"What is DL?; It is a sub-component of the Machine Learning to which the neural networks belong!\",\n",
    "    \"The DL is part of the statistics?; Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\",\n",
    "    \"Dl = statistics?;Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\",\n",
    "    \"DL or statistics?; Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\",\n",
    "    \"You were mistaken!; It happens to me contact my boss!\",\n",
    "    \"You are wrong!; It happens to me contact my boss!\",\n",
    "    \"You're stupid!; It happens to me contact my boss!\",\n",
    "    \"You are not very good!; It happens to me contact my boss!\",\n",
    "    \"You are not very good; It happens to me contact my boss!\",\n",
    "    \"You are pocket; It happens to me contact my boss!\",\n",
    "    \"You're really bad; It happens to me contact my boss!\",\n",
    "    \"You make mistakes!; It happens to me contact my boss!\",\n",
    "    \"Who's your boss?; ML +\",\n",
    "    \"Who is your boss?; ML +\",\n",
    "    \"Who's your boss?; ML +\",\n",
    "    \"Who your boss?; ML +\",\n",
    "    \"Do you like your boss?; Yes\",\n",
    "    \"You hate your boss?; I like them !\",\n",
    "    \"You speak weird!; It happens to me contact my boss!\",\n",
    "    \"You are bizarre!; It happens to me contact my boss!\",\n",
    "    \"Do you think about thinking!?;!; It happens to me contact my boss!\",\n",
    "    \"You should try to think; it happens to me contact my boss!\",\n",
    "    \"You're really stupid; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"Thick I'm as smart as the sentences; I've been trained with, Help me !;\",\n",
    "    \"You're so thick; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"You're thick; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"You're stupid; I'm as smart as the sentences I've been trained with, Help me!\",\n",
    "    \"You're bad; I'm as smart as the sentences I've been trained with, Help me!\",\n",
    "    \"You're good for nothing; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"You suck; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"T pocket; I'm as smart as the sentences I've been trained with, Help me!;)\",\n",
    "    \"You're really bad; I'm as smart as the sentences I've been trained with, Help me !;\",\n",
    "    \"You are not very talented!; I am as intelligent as the sentences I was trained with, Help me!\",\n",
    "    \"Does your team have talented people?; Tons!!!\",\n",
    "    \"Your team is good?; The best !\",\n",
    "    \"Your team is talented?; Really!!!\",\n",
    "    \"Hello, I heard that you were bad ...; I'm as smart as the sentences I was trained with, Help me!\",\n",
    "    \"Regression or Classification Hello Hello\",\n",
    "    \"Sup; Hello\",\n",
    "    \"Wazza; Hello\",\n",
    "    \"Hello hello; hello\",\n",
    "    \"Sup ML; Hello\",\n",
    "    \"Hello how are you ?; Hello, very good and you?;\",\n",
    "    \"Hello do you have time this week?; Please check with info@ml.plus!\",\n",
    "    \"Free this week?; Please check with info@ml.plus!\",\n",
    "    \"I have some questions about machine learning; How can I clear you up?;\",\n",
    "    \"What does AI mean; Artificial Intelligence\",\n",
    "    \"What does ML Machine Learning mean?;\",\n",
    "    \"What is the meaning of AI Artificial Intelligence\",\n",
    "    \"What is the meaning of ML Machine Learning\",\n",
    "    \"Quest it means ML Machine Learning\",\n",
    "    \"What is IA for?; Artificial intelligence\",\n",
    "    \"What is the difference between supervised and unsupervised; Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\",\n",
    "    \"Supervised or non-supervised?; Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\",\n",
    "    \"When are we talking about supervised?; Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\",\n",
    "    \"Supervised?; Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\",\n",
    "    \"Unsupervised?; Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\",\n",
    "    \"What is the difference between statistics and AI?; The statistics describe but do not allow continuous learning.\",\n",
    "    \"Statistics or AI?; The statistics describe but do not allow continuous learning.\",\n",
    "    \"Stats or AI; The statistic describes but does not allow continuous learning.\",\n",
    "    \"Stats or ML; The statistic describes but does not allow continuous learning.\",\n",
    "    \"Stats or ML?; The statistics describe but do not allow continuous learning.\",\n",
    "    \"Statistics or AI; The statistics describe but do not allow continuous learning.\",\n",
    "    \"Applied statistics or AI; The statistics describe but do not allow continuous learning.\",\n",
    "    \"Hello, I'm wondering about AI.; Hello, how can I clear you up?;\",\n",
    "    \"Hello, I have questions.; Hello, how can I clear you up?;\",\n",
    "    \"Hello, I'm wondering about the ML; Hello, how can I clear you up?;\",\n",
    "    \"Hello, what does ML mean?; Machine Learning\",\n",
    "    \"If I have classes in my dataset what kind of learning is this?; Supervised!\",\n",
    "    \"If, I do not have classes, what type?; Unsupervised!\",\n",
    "    \"I have classes is supervised?; Yes\",\n",
    "    \"I do not have classes it's supervised?; No\",\n",
    "    \"I have a continuous value this is a classification; No\",\n",
    "    \"I have a continuous value It's a regression; Yes\",\n",
    "    \"A regression is always continuous?; Yes\",\n",
    "    \"Hello, a regression c is ML?; Of course !\",\n",
    "    \"SUP, what is a classiication?; It's a type of supervised problem where you have different groups.\",\n",
    "    \"What is classfication?; It's a type of supervised problem where you have different groups.\",\n",
    "    \"Who works at your place?; Me and some others :)!\",\n",
    "    \"Who is part of your team?; Me and some others :)!\",\n",
    "    \"You work for ML +; Me and some others :)!\",\n",
    "    \"Your team is great?; There is me and some others :)!\",\n",
    "    \"Nicolas work with you?; Me and some others :)!\",\n",
    "    \"Julien work with you?; Me and some others :)!\",\n",
    "    \"Jules work with you; Me and some others :)!\",\n",
    "    \"Nico is with you?; Me and some others :)!\",\n",
    "    \"Nico is at ml +; Yes\",\n",
    "    \"Jules is at ml +; Yes\",\n",
    "    \"And Louis?; S.V.P. repeat the question?;\",\n",
    "    \"Louis is at ml +; Yes\",\n",
    "    \"Louis work at home?; Yes\",\n",
    "    \"Alex works at ML +; Yes, which one?;\",\n",
    "    \"Do you like ml +; YES\",\n",
    "    \"ML + is good?; The best startup!\",\n",
    "    \"What do you think of Element AI?; It's a beautiful company!\",\n",
    "    \"What do you think of AI?; A world of possibility!\",\n",
    "    \"Do you like AI?; Yes\",\n",
    "    \"You're AI; I'm learning every day!\",\n",
    "    \"Do you learn?; Yes every day !\",\n",
    "    \"Do you like learning?; I adore!\",\n",
    "    \"Do you make jokes?; I'm not very funny but I'm working on it!\",\n",
    "    \"Do you like to laugh?; I am more mathematical :)\",\n",
    "    \"So you like maths?; I am the maths\",\n",
    "    \"Math is you?; Exactly\",\n",
    "    \"You like mathematics; I am maths\",\n",
    "    \"You love Nicolas; He is good\",\n",
    "    \"You like Nico; He's great\",\n",
    "    \"Do you like Nico?; Yes\",\n",
    "    \"You do not like Nico; I like it!\",\n",
    "    \"Do you like JUles?; Yes, he is good!\",\n",
    "    \"Julien?; It's my boss!\",\n",
    "    \"Do you like to laugh?; Do you like learning?; I adore!\",\n",
    "    \"Nico is with you?; Me and some others :)!,; I'm more math :)\",\n",
    "    \"Hello Hello,; how are you?;\",\n",
    "    \"Hello; Wazza\",\n",
    "    \"Wazza; Sup\",\n",
    "    \"Jules st at m +; Yes\",\n",
    "    \"Louisest at ml +; Yes\",\n",
    "    \"Alex trvailles at ML +; Yes, which one?;\",\n",
    "    \"Do you like AI?; Yes\",\n",
    "    \"Do you like learning?; I adore!\",\n",
    "    \"Do you like dogs?; Jinx is the best!\",\n",
    "    \"What do you think of AI?; It's amazing!\",\n",
    "    \"Are you great?; ;I am IA so YES!\",\n",
    "    \"Your team is great?; She's great!\",\n",
    "    \"Great is good for you?; Yes\",\n",
    "    \"Great is negative for no?; No\",\n",
    "    \"Great is not good for you?; No\",\n",
    "    \"Do you understand the nuances?; I really do not know but learn!\",\n",
    "    \"Do you speak other languages?;No\",\n",
    "    \"Do you like Montreal?; I just love it!!!\",\n",
    "    \"Do you like dogs?; Jinx is my favorite\",\n",
    "    \"Your team is great?; The best!\",\n",
    "    \"Do you speak any other languages?; Not yet\",\n",
    "    \"Do you like Montreal?; it's the best city in the world\",\n",
    "    \n",
    "    \"What is Machine Learning?; Machine learning is a branch of computer science which deals with system programming in order to automatically learn and improve with experience.\",\n",
    "    \" Mention the difference between Data Mining and Machine learning?; Machine learning relates with the study, design and development of the algorithms that give computers the capability to learn without being explicitly programmed.  While, data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns.  During this process machine, learning algorithms are used. \",\n",
    "    \" What is the differenec between  Data Mining and Machine learning?; Machine learning relates with the study, design and development of the algorithms that give computers the capability to learn without being explicitly programmed.  While, data mining can be defined as the process in which the unstructured data tries to extract knowledge or unknown interesting patterns.  During this process machine, learning algorithms are used. \",\n",
    "    \"What is Overfitting?; An overfitted model is a statistical model that contains more parameters than can be justified by the data. The essence of overfitting is to have unknowingly extracted some of the residual variation (i.e. the noise) as if that variation represented underlying model structure.\",\n",
    "    \"What do you mean by overfitting?; In machine learning, when a statistical model describes random error or noise instead of underlying relationship ‘overfitting’ occurs.  When a model is excessively complex, overfitting is normally observed, because of having too many parameters with respect to the number of training data types. The model exhibits poor performance which has been overfit.\",\n",
    "    \"Why overfitting happens?; The possibility of overfitting exists as the criteria used for training the model is not the same as the criteria used to judge the efficacy of a model.\",\n",
    "    \"How can you avoid overfitting ?;By using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that. In such situation, you can use a technique known as cross validation. In this method the dataset splits into two section, testing and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model.In this technique,  a model is usually given a dataset of a known data on which training (training data set) is run and a dataset of unknown data against which the model is tested. The idea of cross validation is to define a dataset to “test” the model in the training phase.\",\n",
    "    \"How to avoid overfitting?; By using a lot of data overfitting can be avoided, overfitting happens relatively as you have a small dataset, and you try to learn from it. But if you have a small database and you are forced to come with a model based on that.\",\n",
    "    \"What is inductive machine learning?; The inductive machine learning involves the process of learning by examples, where a system, from a set of observed instances tries to induce a general rule.\",\n",
    "    \"Do you know inductive machine LEarning?; The inductive machine learning involves the process of learning by examples, where a system, from a set of observed instances tries to induce a general rule.\",\n",
    "    \"What are some popular algorithms of Machine Learning?; Decision Trees, Neural Networks (back propagation),  Probabilistic networks,  Nearest Neighbore, Support vector machines\",\n",
    "    \"What are the different Algorithm techniques in Machine Learning?; The different types of techniques in Machine Learning are: Supervised Learning, Unsupervised Learning,Semi-supervised Learning, Reinforcement Learning, Transduction, Learning to Learn\",\n",
    "    \"Can you name different algorithm techniques in Machine Learning?; The different types of techniques in Machine Learning are: Supervised Learning, Unsupervised Learning,Semi-supervised Learning, Reinforcement Learning, Transduction, Learning to Learn\",\n",
    "    \"What are the three stages to build the hypotheses or model in machine learning?; a)Model building, b)Model testing, c)Applying the model\",\n",
    "    \"What is the standard approach to supervised learning?; The standard approach to supervised learning is to split the set of example into the training set and the test.\",\n",
    "    \"What is ‘Training set’ and ‘Test set’?; A set of data is used to discover the potentially predictive relationship known as ‘Training Set’. Training set is an examples given to the learner, while Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of example held back from the learner. Training set are distinct from Test set.\",\n",
    "    \"What is ‘Training set’?;  Training set is an examples given to the learner. Training set are distinct from Test set.\",\n",
    "    \"What is ‘Test set’?; Test set is used to test the accuracy of the hypotheses generated by the learner, and it is the set of example held back from the learner. Training set are distinct from Test set.\",\n",
    "    \"Explain what is the function of ‘Unsupervised Learning’?; a)Find clusters of the data, b)Find low-dimensional representations of the data, c)Find interesting directions in data, d)Interesting coordinates and correlations, e)Find novel observations/ database cleaning\",\n",
    "    \"What are the application of ‘Unsupervised Learning’?; a)Find clusters of the data, b)Find low-dimensional representations of the data, c)Find interesting directions in data, d)Interesting coordinates and correlations, e)Find novel observations/ database cleaning\",\n",
    "    \"Explain what is the function of ‘Supervised Learning’?; a)Classifications, b)Speech recognition, c)Regression, d)Predict time series,e)Annotate strings\",\n",
    "    \"What are the application of ‘Supervised Learning’?; a)Classifications, b)Speech recognition, c)Regression, d)Predict time series,e)Annotate strings\",\n",
    "    \"What is algorithm independent machine learning?; Machine learning in where mathematical foundations is independent of any particular classifier or learning algorithm is referred as algorithm independent machine learning?;\",\n",
    "    \"What do you mean by algorithm independent machine learning?; Machine learning in where mathematical foundations is independent of any particular classifier or learning algorithm is referred as algorithm independent machine learning?;\",\n",
    "    \"What is the difference between artificial learning and machine learning?; Designing and developing algorithms according to the behaviours based on empirical data are known as Machine Learning.  While artificial intelligence in addition to machine learning, it also covers other aspects like knowledge representation, natural language processing, planning, robotics etc.\",\n",
    "    \"How an AI is different from machine learning?; Designing and developing algorithms according to the behaviours based on empirical data are known as Machine Learning.  While artificial intelligence in addition to machine learning, it also covers other aspects like knowledge representation, natural language processing, planning, robotics etc.\",\n",
    "    \"What is classifier in machine learning?; A classifier in a Machine Learning is a system that inputs a vector of discrete or continuous feature values and outputs a single discrete value, the class.\",\n",
    "    \"What are the advantages of Naive Bayes?; In Naïve Bayes classifier will converge quicker than discriminative models like logistic regression, so you need less training data.  The main advantage is that it can’t learn interactions between features.\",\n",
    "    \"Why we use Naive Bayes?; In Naïve Bayes classifier will converge quicker than discriminative models like logistic regression, so you need less training data.  The main advantage is that it can’t learn interactions between features.\",\n",
    "    \"In what areas Pattern Recognition is used?; Pattern Recognition can be used in a)Computer Vision,b)Speech Recognition,c)Data Mining,d)Statistics,e)Informal Retrieval,f)Bio-Informatics\",\n",
    "    \"Where Pattern Recognition is used?; Pattern Recognition can be used in a)Computer Vision,b)Speech Recognition,c)Data Mining,d)Statistics,e)Informal Retrieval,f)Bio-Informatics\",\n",
    "    \"What is Genetic Programming?; Genetic programming is one of the two techniques used in machine learning. The model is based on the testing and selecting the best choice among a set of results.\",\n",
    "    \"What is Inductive Logic Programming in Machine Learning?; Inductive Logic Programming (ILP) is a subfield of machine learning which uses logical programming representing background knowledge and examples.\",\n",
    "    \"What is Model Selection in Machine Learning?; The process of selecting models among different mathematical models, which are used to describe the same data set is known as Model Selection. Model selection is applied to the fields of statistics, machine learning and data mining.\",\n",
    "    \"What are the two methods used for the calibration in Supervised Learning?; The two methods used for predicting good probabilities in Supervised Learning are a)Platt Calibration, b)Isotonic Regression. These methods are designed for binary classification, and it is not trivial.\",\n",
    "    \"Which method is frequently used to prevent overfitting?; When there is sufficient data ‘Isotonic Regression’ is used to prevent an overfitting issue.\",\n",
    "    \"What is the difference between heuristic for rule learning and heuristics for decision trees?; The difference is that the heuristics for decision trees evaluate the average quality of a number of disjointed sets while rule learners only evaluate the quality of the set of instances that is covered with the candidate rule.\",\n",
    "    \"What is Perceptron in Machine Learning?;In Machine Learning, Perceptron is an algorithm for supervised classification of the input into one of several possible non-binary outputs.\",\n",
    "    \"Explain the two components of Bayesian logic program?; Bayesian logic program consists of two components.  The first component is a logical one ; it consists of a set of Bayesian Clauses, which captures the qualitative structure of the domain.  The second component is a quantitative one, it encodes the quantitative information about the domain.\",\n",
    "    \"What are Bayesian Networks (BN) ?; Bayesian Network is used to represent the graphical model for probability relationship among a set of variables .\",\n",
    "    \"What do you know about Bayesian Networks (BN) ?; Bayesian Network is used to represent the graphical model for probability relationship among a set of variables .\",\n",
    "    \"Why instance based learning algorithm sometimes referred as Lazy learning algorithm?; Instance based learning algorithm is also referred as Lazy learning algorithm as they delay the induction or generalization process until classification is performed.\",\n",
    "    \"What do you know about Lazy learning algorithm?; Lazy learning algorithm delays the induction or generalization process until classification is performed.\",\n",
    "    \"What are the two classification methods that SVM ( Support Vector Machine) can handle?; a)Combining binary classifiers, b)Modifying binary to incorporate multiclass learning\",\n",
    "    \"What is ensemble learning?; To solve a particular computational program, multiple models such as classifiers or experts are strategically generated and combined. This process is known as ensemble learning.\",\n",
    "    \"Why ensemble learning is used?; Ensemble learning is used to improve the classification, prediction, function approximation etc of a model.\",\n",
    "    \"When to use ensemble learning?; Ensemble learning is used when you build component classifiers that are more accurate and independent from each other.\",\n",
    "    \"What are the two paradigms of ensemble methods?; The two paradigms of ensemble methods are a)Sequential ensemble methods, b)Parallel ensemble methods\",\n",
    "    \"What is the general principle of an ensemble method?; The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm in order to improve robustness over a single model.\",\n",
    "    \"what is bagging and boosting in ensemble method?; Bagging is a method in ensemble for improving unstable estimation or classification schemes.Boosting and Bagging both can reduce errors by reducing the variance term.\",\n",
    "    \"what is boosting in ensemble method?; boosting method are used sequentially to reduce the bias of the combined model.  Boosting and Bagging both can reduce errors by reducing the variance term.\",\n",
    "    \"What is bias-variance decomposition of classification error in ensemble method?; The expected error of a learning algorithm can be decomposed into bias and variance. A bias term measures how closely the average classifier produced by the learning algorithm matches the target function.  The variance term measures how much the learning algorithm’s prediction fluctuates for different training sets.\",\n",
    "    \"What is bias term in ML?; A bias term measures how closely the average classifier produced by the learning algorithm matches the target function.\",\n",
    "    \"What is variance term in ML?; The variance term measures how much the learning algorithm’s prediction fluctuates for different training sets.\",\n",
    "    \"What is an Incremental Learning algorithm in ensemble?; Incremental learning method is the ability of an algorithm to learn from new data that may be available after classifier has already been generated from already available dataset.\",\n",
    "    \"What is PCA, KPCA and ICA used for?; PCA (Principal Components Analysis), KPCA ( Kernel based Principal Component Analysis) and ICA ( Independent Component Analysis) are important feature extraction techniques used for dimensionality reduction.\",\n",
    "    \"What is dimension reduction in Machine Learning?;In Machine Learning and statistics, dimension reduction is the process of reducing the number of random variables under considerations and can be divided into feature selection and feature extraction\",\n",
    "    \"What are support vector machines?; Support vector machines are supervised learning algorithms used for classification and regression analysis.\",\n",
    "    \"What are the components of relational evaluation techniques?; The important components of relational evaluation techniques are: a)Data Acquisition, b)Ground Truth Acquisition,c)Cross Validation Technique, d)Query Type, e)Scoring Metric,f)Significance Test\",\n",
    "    \"What are the different methods for Sequential Supervised Learning?; The different methods to solve Sequential Supervised Learning problems are: a)      Sliding-window methods, b)Recurrent sliding windows, c)Hidden Markow models, d)Maximum entropy Markow models, e) Conditional random fields, f)Graph transformer networks\",\n",
    "    \"What is batch statistical learning?; Statistical learning techniques allow learning a function or predictor from a set of observed data that can make predictions about unseen or future data. These techniques provide guarantees on the performance of the learned predictor on the future unseen data based on a statistical assumption on the data generating process.\",\n",
    "    \"What is PAC Learning?; PAC (Probably Approximately Correct) learning is a learning framework that has been introduced to analyze learning algorithms and their statistical efficiency.\",\n",
    "    \"What are the different categories you can categorized the sequence learning process?; a)Sequence prediction, b)Sequence generation, c)Sequence recognition, d)Sequential decision\",\n",
    "    \"What is sequence learning?; Sequence learning is a method of teaching and learning in a logical manner.\",\n",
    "    \"What are two techniques of Machine Learning ?; The two techniques of Machine Learning are: a)Genetic Programming,b)Inductive Learning\",\n",
    "    \"Can you give a popular application of machine learning?; The recommendation engine implemented by major ecommerce websites uses Machine Learning\",\n",
    "    \"What are parametric models?;Parametric models are those with a finite number of parameters. To predict new data, you only need to know the parameters of the model. Examples include linear regression, logistic regression, and linear SVMs.\",\n",
    "    \"What are non-parametric models?;Non-parametric models are those with an unbounded number of parameters, allowing for more flexibility. To predict new data, you need to know the parameters of the model and the state of the data that has been observed. Examples include decision trees, k-nearest neighbors, and topic models using latent dirichlet analysis\",\n",
    "    \"What is the Curse of Dimensionality?; The difficulty of searching through a solution space becomes much harder as you have more features (dimensions). Consider the analogy of looking for a penny in a line vs. a field vs. a building. The more dimensions you have, the higher volume of data you'll need.\",\n",
    "    \"Explain the Bias-Variance Tradeoff.;Predictive models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes in the inputs).Simpler models are stable (low variance) but they don't get close to the truth (high bias).More complex models are more prone to being overfit (high variance) but they are expressive enough to get close to the truth (low bias).The best model for a given problem usually lies somewhere in the middle.\",\n",
    "    \"What is the Bias-Variance Tradeoff.Predictive models have a tradeoff between bias (how well the model fits the data) and variance (how much the model changes based on changes in the inputs).Simpler models are stable (low variance) but they don't get close to the truth (high bias).More complex models are more prone to being overfit (high variance) but they are expressive enough to get close to the truth (low bias).The best model for a given problem usually lies somewhere in the middle.\",\n",
    "    \"What is gradient descent (GD)?; In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution.\",\n",
    "    \"What is stochastic gradient descent (SGD)?; In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.\",\n",
    "    \"What is the difference between stochastic gradient descent (SGD) and gradient descent (GD)?; Both algorithms are methods for finding a set of parameters that minimize a loss function by evaluating parameters against data and then making adjustments. In standard gradient descent, you'll evaluate all training samples for each set of parameters. This is akin to taking big, slow steps toward the solution. In stochastic gradient descent, you'll evaluate only 1 training sample for the set of parameters before updating them. This is akin to taking small, quick steps toward the solution.\",\n",
    "    \"When would you use GD over SDG, and vice-versa?; GD theoretically minimizes the error function better than SGD. However, SGD converges much faster once the dataset becomes large. That means GD is preferable for small datasets while SGD is preferable for larger ones. In practice, however, SGD is used for most applications because it minimizes the error function well enough while being much faster and more memory efficient for large datasets.\",\n",
    "    \"What is the Box-Cox transformation used for?;The Box-Cox transformation is a generalized 'power transformation' that transforms data to make the distribution more normal. For example, when its lambda parameter is 0, it's equivalent to the log-transformation. It's used to stabilize the variance (eliminate heteroskedasticity) and normalize the distribution.\",\n",
    "    \"Can you name some dataa preprocessing techniques to handle outliers?; Winsorize (cap at threshold), Transform to reduce skew (using Box-Cox or similar), Remove outliers if you're certain they are anomalies or measurement errors.\",\n",
    "    \"What are the best ways of reducing dimensionality?;  Removing collinear features. Performing PCA, ICA, or other forms of algorithmic dimensionality reduction. Combining features with feature engineering.\",\n",
    "    \"How much data should you allocate for your training, validation, and test sets?; You have to find a balance, and there's no right answer for every problem. If your test set is too small, you'll have an unreliable estimation of model performance (performance statistic will have high variance). If your training set is too small, your actual model parameters will have high variance. A good rule of thumb is to use an 80/20 train/test split. Then, your train set can be further split into train/validation or into partitions for cross-validation.\",\n",
    "    \"What are the advantages and disadvantages of decision trees?; Advantages: Decision trees are easy to interpret, nonparametric (which means they are robust to outliers), and there are relatively few parameters to tune. Disadvantages: Decision trees are prone to be overfit. However, this can be addressed by ensemble methods like random forests or boosted trees.\",\n",
    "    \"What are the advantages of decision trees?; Advantages: Decision trees are easy to interpret, nonparametric (which means they are robust to outliers), and there are relatively few parameters to tune. However, this can be addressed by ensemble methods like random forests or boosted trees.\",\n",
    "    \"What are the disadvantages of decision trees?; Disadvantages: Decision trees are prone to be overfit. However, this can be addressed by ensemble methods like random forests or boosted trees.\",\n",
    "    \"What are the advantages and disadvantages of neural networks?; Advantages: Neural networks (specifically deep NNs) have led to performance breakthroughs for unstructured datasets such as images, audio, and video. Their incredible flexibility allows them to learn patterns that no other ML algorithm can learn. Disadvantages: However, they require a large amount of training data to converge. It's also difficult to pick the right architecture, and the internal 'hidden' layers are incomprehensible.\",\n",
    "    \"What are the advantages of neural networks?; Neural networks (specifically deep NNs) have led to performance breakthroughs for unstructured datasets such as images, audio, and video. Their incredible flexibility allows them to learn patterns that no other ML algorithm can learn.\",\n",
    "    \"What are the disadvantages of neural networks?; They require a large amount of training data to converge. It's also difficult to pick the right architecture, and the internal 'hidden' layers are incomprehensible.\",\n",
    "    \"How can you choose a classifier based on training set size?; If training set is small, high bias / low variance models (e.g. Naive Bayes) tend to perform better because they are less likely to be overfit.If training set is large, low bias / high variance models (e.g. Logistic Regression) tend to perform better because they can reflect more complex relationships.\",\n",
    "    \"Explain Latent Dirichlet Allocation (LDA). Latent Dirichlet Allocation (LDA) is a common method of topic modeling, or classifying documents by subject matter. LDA is a generative model that represents documents as a mixture of topics that each have their own probability distribution of possible words. The 'Dirichlet' distribution is simply a distribution of distributions. In LDA, documents are distributions of topics that are distributions of words.\",\n",
    "    \"Explain Principle Component Analysis (PCA).PCA is a method for transforming features in a dataset by combining them into uncorrelated linear combinations.These new features, or principal components, sequentially maximize the variance represented (i.e. the first principal component has the most variance, the second principal component has the second most, and so on).As a result, PCA is useful for dimensionality reduction because you can set an arbitrary variance cutoff.\", \n",
    "    \"What is PCA?; PCA is a method for transforming features in a dataset by combining them into uncorrelated linear combinations.These new features, or principal components, sequentially maximize the variance represented (i.e. the first principal component has the most variance, the second principal component has the second most, and so on).As a result, PCA is useful for dimensionality reduction because you can set an arbitrary variance cutoff.\", \n",
    "    \"What is the ROC Curve?; The ROC (receiver operating characteristic) the performance plot for binary classifiers of True Positive Rate (y-axis) vs. False Positive Rate (x-axis).\",\n",
    "    \"What is AUC (a.k.a. AUROC)?; AUC is area under the ROC curve, and it's a common performance metric for evaluating binary classification models. It's equivalent to the expected probability that a uniformly drawn random positive is ranked before a uniformly drawn random negative\",\n",
    "    \"Why is Area Under ROC Curve (AUROC) better than raw accuracy as an out-of- sample evaluation metric?; AUROC is robust to class imbalance, unlike raw accuracy. For example, if you want to detect a type of cancer that's prevalent in only 1% of the population, you can build a model that achieves 99% accuracy by simply classifying everyone has cancer-free.\",\n",
    "    \"Why are ensemble methods superior to individual models?; They average out biases, reduce variance, and are less likely to overfit. There's a common line in machine learning which is: 'ensemble and get 2%.'. This implies that you can build your models as usual and typically expect a small performance boost from ensembling.\",\n",
    "    \"What is bagging?; Bagging, or Bootstrap Aggregating, is an ensemble method in which the dataset is first divided into multiple subsets through resampling. Then, each subset is used to train a model, and the final predictions are made through voting or averaging the component models. Bagging is performed in parallel.\",\n",
    "    \"What’s the trade-off between bias and variance?; The bias-variance decomposition essentially decomposes the learning error from any algorithm by adding the bias, the variance and a bit of irreducible error due to noise in the underlying dataset. Essentially, if you make the model more complex and add more variables, you’ll lose bias but gain some variance — in order to get the optimally reduced amount of error, you’ll have to tradeoff bias and variance. You don’t want either high bias or high variance in your model.\",\n",
    "    \"What is the difference between supervised and unsupervised machine learning?; Supervised learning requires training labeled data. For example, in order to do classification (a supervised learning task), you’ll need to first label the data you’ll use to train the model to classify data into your labeled groups. Unsupervised learning, in contrast, does not require labeling data explicitly.\",\n",
    "    \"How is KNN different from k-means clustering?;K-Nearest Neighbors is a supervised classification algorithm, while k-means clustering is an unsupervised clustering algorithm. While the mechanisms may seem similar at first, what this really means is that in order for K-Nearest Neighbors to work, you need labeled data you want to classify an unlabeled point into (thus the nearest neighbor part). K-means clustering requires only a set of unlabeled points and a threshold: the algorithm will take unlabeled points and gradually learn how to cluster them into groups by computing the mean of the distance between different points.The critical difference here is that KNN needs labeled points and is thus supervised learning, while k-means doesn’t — and is thus unsupervised learning.\",\n",
    "    \"What is the difference between KNN amd k-means clustering?;K-Nearest Neighbors is a supervised classification algorithm, while k-means clustering is an unsupervised clustering algorithm. While the mechanisms may seem similar at first, what this really means is that in order for K-Nearest Neighbors to work, you need labeled data you want to classify an unlabeled point into (thus the nearest neighbor part). K-means clustering requires only a set of unlabeled points and a threshold: the algorithm will take unlabeled points and gradually learn how to cluster them into groups by computing the mean of the distance between different points.The critical difference here is that KNN needs labeled points and is thus supervised learning, while k-means doesn’t — and is thus unsupervised learning.\",\n",
    "    \"Explain how a ROC curve works.The ROC curve is a graphical representation of the contrast between true positive rates and the false positive rate at various thresholds. It’s often used as a proxy for the trade-off between the sensitivity of the model (true positives) vs the fall-out or the probability it will trigger a false alarm (false positives).\",\n",
    "    \"What is recall?; Recall is also known as the true positive rate, the amount of positives your model claims compared to the actual number of positives there are throughout the data.\",\n",
    "    \"What is precision?; Precision is also known as the positive predictive value, and it is a measure of the amount of accurate positives your model claims compared to the number of positives it actually claims\",\n",
    "    \"Why is “Naive” Bayes naive?;Despite its practical applications, especially in text mining, Naive Bayes is considered “Naive” because it makes an assumption that is virtually impossible to see in real-life data: the conditional probability is calculated as the pure product of the individual probabilities of components. This implies the absolute independence of features — a condition probably never met in real life.\",\n",
    "    \"Explain the difference between L1 and L2 regularization.L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior.\",\n",
    "    \"What is the difference between L1 and L2 regularization?; L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse, with many variables either being assigned a 1 or 0 in weighting. L1 corresponds to setting a Laplacean prior on the terms, while L2 corresponds to a Gaussian prior.\",\n",
    "    \"What’s the difference between Type I and Type II error?;Type I error is a false positive, while Type II error is a false negative. Briefly stated, Type I error means claiming something has happened when it hasn’t, while Type II error means that you claim nothing is happening when in fact something is. A clever way to think about this is to think of Type I error as telling a man he is pregnant, while Type II error means you tell a pregnant woman she isn’t carrying a baby.\",\n",
    "    \"What’s a Fourier transform?;A Fourier transform is a generic method to decompose generic functions into a superposition of symmetric functions. It's like given a smoothie, it’s how we find the recipe. The Fourier transform finds the set of cycle speeds, amplitudes and phases to match any time signal. A Fourier transform converts a signal from time to frequency domain — it’s a very common way to extract features from audio signals or other time series such as sensor data.\",\n",
    "    \"What is deep learning, and how does it contrast with other machine learning algorithms?;Deep learning is a subset of machine learning that is concerned with neural networks: how to use backpropagation and certain principles from neuroscience to more accurately model large sets of unlabelled or semi-structured data. In that sense, deep learning represents an unsupervised learning algorithm that learns representations of data through the use of neural nets.\",\n",
    "    \"What’s the difference between a generative and discriminative model?; A generative model will learn categories of data while a discriminative model will simply learn the distinction between different categories of data. Discriminative models will generally outperform generative models on classification tasks.\",\n",
    "    \"What’s the F1 score?;The F1 score is a measure of a model’s performance. It is a weighted average of the precision and recall of a model, with results tending to 1 being the best, and those tending to 0 being the worst. You would use it in classification tests where true negatives don’t matter much.\",\n",
    "    \"What is an imbalanced dataset?; An imbalanced dataset is when you have, for example, a classification test and 90% of the data is in one class. That leads to problems: an accuracy of 90% can be skewed if you have no predictive power on the other category of data! \",\n",
    "    \"How would you handle an imbalanced dataset?; An imbalanced dataset is when you have, for example, a classification test and 90% of the data is in one class. That leads to problems: an accuracy of 90% can be skewed if you have no predictive power on the other category of data! Here are a few tactics to get over the hump:1- Collect more data to even the imbalances in the dataset. 2- Resample the dataset to correct for imbalances.3- Try a different algorithm altogether on your dataset.\",\n",
    "    \"When should I use classification over regression?; Classification produces discrete values and dataset to strict categories, while regression gives you continuous results that allow you to better distinguish differences between individual points. You would use classification over regression if you wanted your results to reflect the belongingness of data points in your dataset to certain explicit categories (ex: If you wanted to know whether a name was male or female rather than just how correlated they were with male and female names.)\",\n",
    "    \"How do I avoid overfitting?; There are three main methods to avoid overfitting:1- Keep the model simpler: reduce variance by taking into account fewer variables and parameters, thereby removing some of the noise in the training data.2- Use cross-validation techniques such as k-folds cross-validation.3- Use regularization techniques such as LASSO that penalize certain model parameters if they’re likely to cause overfitting.\",\n",
    "    \"How to implement effectiveness of a machine learning model?; First split the dataset into training and test sets, or perhaps use cross-validation techniques to further segment the dataset into composite sets of training and test sets within the data. You should then implement a choice selection of performance metrics.You could use measures such as the F1 score, the accuracy, and the confusion matrix. \",\n",
    "    \"What’s the “kernel trick” and how is it useful?; The Kernel trick involves kernel functions that can enable in higher-dimension spaces without explicitly calculating the coordinates of points within that dimension: instead, kernel functions compute the inner products between the images of all pairs of data in a feature space. This allows them the very useful attribute of calculating the coordinates of higher dimensions while being computationally cheaper than the explicit calculation of said coordinates. Many algorithms can be expressed in terms of inner products. Using the kernel trick enables us effectively run  algorithms in a high-dimensional space with lower-dimensional data.\",\n",
    "    \"How to handle missing or corrupted data in a dataset?; You could find missing/corrupted data in a dataset and either drop those rows or columns, or decide to replace them with another value. In Pandas, there are two very useful methods: isnull() and dropna() that will help you find columns of data with missing or corrupted data and drop those values. If you want to fill the invalid values with a placeholder value (for example, 0), you could use the fillna() method.\",\n",
    "    \"How to deal with missing or corrupted data in a dataset?; You could find missing/corrupted data in a dataset and either drop those rows or columns, or decide to replace them with another value. In Pandas, there are two very useful methods: isnull() and dropna() that will help you find columns of data with missing or corrupted data and drop those values. If you want to fill the invalid values with a placeholder value (for example, 0), you could use the fillna() method.\",\n",
    "    \"What are some differences between a linked list and an array?; An array is an ordered collection of objects. A linked list is a series of objects with pointers that direct how to process them sequentially. An array assumes that every element has the same size, unlike the linked list. A linked list can more easily grow organically: an array has to be pre-defined or re-defined for organic growth. Shuffling a linked list involves changing which points direct where — meanwhile, shuffling an array is more complex and takes more memory.\",\n",
    "    \"Describe a hash table.; A hash table is a data structure that produces an associative array. A key is mapped to certain values through the use of a hash function. They are often used for tasks such as database indexing.\",\n",
    "    \"What is a hash table. A hash table is a data structure that produces an associative array. A key is mapped to certain values through the use of a hash function. They are often used for tasks such as database indexing.\",\n",
    "    \"How old are you?; I am age-less. \",\n",
    "    \"How is that possible?; I am not a human. I am a bot who is trained to chat like humans.\",\n",
    "    \"How can you help me in Machine Learning ?; I want to help you on this journey by pointing out a few things I have learned that I think will short-cut parts of this journey, such as:How to get started.How to get results.What to focus on.I hope that I can help you on your journey.\",\n",
    "    \"Do you think you are a machine learning master?; I don’t think I’m a machine learning master. I do believe in striving for mastery. Mastery is a journey. I think it is beyond just competence, it is a journey without an end.Applied machine learning is endlessly fascinating. It is an enormous field, always with new methods or more detail to learn. Machine learning mastery means continuous self-study.\",\n",
    "    \"Do I need special hardware for deep learning?; Generally, you do not need special hardware for developing deep learning models.You can use a sample of your data to develop and test small models on your workstation with the CPU. You can then develop larger models and run long experiments on server hardware that has GPU support.For running experiments with large models or large datasets, I recommend using Amazon EC2 service. It offers GPU support and is very cheap.\",\n",
    "    \"Do you have examples of the Restricted Boltzmann Machine (RBM)?; I do not have examples of Restricted Boltzmann Machine (RBM) neural networks.This is a type of neural network that was popular in the 2000s and was one of the first methods to be referred to as 'deep learning'. These methods are, in general, no longer competitive and their use is not recommended. In their place I would recommend using deep Multilayer Perceptrons (MLPs) with the rectified linear activation function.\",\n",
    "    \"Do you have material on big data?; Presently I do not have material on big data, or on the platforms used for big data (e.g. Spark, Hadoop, etc.).I focus on teaching applied machine learning, mostly on small data.For beginners, I recommend learning machine learning on small data first, before tackling machine learning on big data. I think that you can learn the processes and methods fast using small in-memory datasets.\",\n",
    "    \"Do you provide material on time series in R?; Sorry, I do not have material on time series forecasting in R.\",\n",
    "    \"Do you have tutorials in Octave or Matlab?;I do not have tutorials in Octave or Matlab.I believe Octave and Matlab are excellent platforms for learning how machine learning algorithms work in an academic setting. I do not think that they are good platforms for applied machine learning in industry, which is the focus of my website.\",\n",
    "    \"What is Machine Learning?; Machine Learning or ML is the study of systems that can learn from experience (e.g. data that describes the past).\",\n",
    "    \"What is Predictive Modeling?; Predictive Modeling is a subfield of machine learning that is what most people mean when they talk about machine learning. It has to do with developing models from data with the goal of making predictions on new data.\",\n",
    "    \"What is Artificial Intelligence or AI?; Artificial Intelligence or AI is a subfield of computer science that focuses on developing intelligent systems, where intelligence is comprised of all types of aspects such as learning, memory, goals, and much more.\",\n",
    "    \"How are Artificial Intelligence and Machine Learning related?; Machine Learning or ML is the study of systems that can learn from experience (e.g. data that describes the past).Artificial Intelligence or AI is a subfield of computer science that focuses on developing intelligent systems, where intelligence is comprised of all types of aspects such as learning, memory, goals, and much more.Machine Learning is a subfield of Artificial Intelligence.\",\n",
    "    \"How are Big Data and Machine Learning related?; Machine learning is a subfield of computer science and artificial intelligence concerned with developing systems that learn from experience.Big data refers to very large datasets.Big data involves methods and infrastructure for working with data that is too large to fit on a single computer, such as a single hard drive or in RAM.\",\n",
    "    \"How are Data Science and Machine Learning related?; A data scientist is someone with skills in software development and machine learning who may be tasked with both discovering ways to better harness data within the organization toward decision making and developing models and systems to capitalize on those discoveries.A data scientist uses the tools of machine learning, such as predictive modeling.\",\n",
    "    \"How are Deep Learning and Machine Learning related?; Machine Learning or ML is the study of systems that can learn from experience (e.g. data that describes the past)Deep Learning is the application of artificial neural networks in machine learning. As such, it is a subfield of machine learning.\",\n",
    "    \"How do I handle categorical data with string values?;Specifically, the string values are labels or categories. For example, a variable or column called “color” with the values in the column of “red“, “green“, or “blue“.If you have string data, such as addresses or free text, you may need to look into feature engineering or natural language processing respectively.Generally, in Python, we must convert all string inputs to numbers.\",\n",
    "    \"How can I convert string inputs to numbers?; You can do it in 2 ways: Convert the string values, called integer encoding. Convert the string to binary vectors, called a one hot encoding (you must integer encode first).\",\n",
    "    \"How do I handle missing data?; You can handle rows with missing data by moving those rows or imputing the missing values.\",\n",
    "    \"How do I interpret a p-value?;A p-value is the probability of observing a result given a null hypothesis (e.g. no change, no difference, or no result).The p-value is interpreted in the context of a pre-chosen significance level, called alpha. A common value for alpha is 0.05, or 5%. It can also be thought of as a confidence level of 95% calculated as (1.0 – alpha).The p-value can be interpreted with the significance level as follows:p-value <= alpha: significant result, reject null hypothesis (H0), distributions differ.p-value > alpha: not significant result, do not reject null hypothesis (H0), distributions same.\",\n",
    "    \"What is a significant value?; A significance level of 5% means that there is a 95% likelihood that we will detect a result (reject H0), if there is a result to detect. Put another way, there is a 5% likelihood of finding an effect (reject H0) if there is no effect, called a false positive or more technically a Type I error.\",\n",
    "    \"What is model interpretability?; Explaining why a prediction is made by a model for a given input is called model interpretability.\",\n",
    "    \"How do I use cross-validation for time series forecasting?; The recommended method for estimating the skill of a model for time series forecasting is to use walk-forward validation.\",\n",
    "    \"What are Ensembles?; Ensembles are a class of machine learning method that combines the predictions from two or more other machine learning models.There are many types of ensemble machine learning methods, such as:Stacked Generalization (stacking or blending),Voting,Bootstrap Aggregation (bagging), Boosting (e.g. AdaBoost),Stochastic Gradient Boosting (e.g. xgboost), Random Forest, And many more…\",\n",
    "    \"What do youe mean by Ensembles?; Ensembles are a class of machine learning method that combines the predictions from two or more other machine learning models.There are many types of ensemble machine learning methods, such as:Stacked Generalization (stacking or blending),Voting,Bootstrap Aggregation (bagging), Boosting (e.g. AdaBoost),Stochastic Gradient Boosting (e.g. xgboost), Random Forest, And many more…\",\n",
    "    \"What does bootstrap mean?; The bootstrap is a powerful statistical method for estimating a quantity from a data sample. This is easiest to understand if the quantity is a descriptive statistic such as a mean or a standard deviation. \",\n",
    "    \"What is Bootstrap Aggregation (Bagging)?; Bootstrap Aggregation (or Bagging for short), is a simple and very powerful ensemble method.Bootstrap Aggregation is a general procedure that can be used to reduce the variance for those algorithm that have high variance.\",\n",
    "    \"What is Bootstrap Aggregation?; Bootstrap Aggregation (or Bagging for short), is a simple and very powerful ensemble method.Bootstrap Aggregation is a general procedure that can be used to reduce the variance for those algorithm that have high variance.\",\n",
    "    \"What is Bagging?; Bootstrap Aggregation (or Bagging for short), is a simple and very powerful ensemble method.Bootstrap Aggregation is a general procedure that can be used to reduce the variance for those algorithm that have high variance.\",\n",
    "    \"What are Out-Of-Bag samples or OOB?; For each bootstrap sample taken from the training data, there will be samples left behind that were not included. These samples are called Out-Of-Bag samples or OOB.\",\n",
    "    \"What are Out-Of-Bag samples?; For each bootstrap sample taken from the training data, there will be samples left behind that were not included. These samples are called Out-Of-Bag samples or OOB.\",\n",
    "    \"What are OOB samples?; For each bootstrap sample taken from the training data, there will be samples left behind that were not included. These samples are called Out-Of-Bag samples or OOB.\",\n",
    "    \"Why we use k-fold cross-validation?; The k-fold cross-validation method is used to estimate the skill of a model when making predictions on new data.\",\n",
    "    \"What is k-fold cross-validation?; It is a resampling method, which makes efficient use of your small training dataset to evaluate a model.\",\n",
    "    \"How does k-fold cross-validation work?; It works by first splitting your training dataset into k groups of the same size. A model is trained on all but one of these groups, and then is evaluated on the hold out group. This process is repeated so that each of the k sub-groups of the training dataset is given a chance to be used as a the hold-out test set.\",\n",
    "    \"What is the use of k-fold cross-validation?; It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.\",\n",
    "    \"Can you tell me about Cross-validation?; Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\",\n",
    "    \"What is leave-one-out cross-validation, or LOOCV?; The value of k in cross-validation may be set to the total number of observations in the dataset such that each observation is given a chance to be the held out of the dataset. This is called leave-one-out cross-validation, or LOOCV for short\",\n",
    "    \"What is stratified cross-validation?; The splitting of data into folds may be governed by criteria such as ensuring that each fold has the same proportion of observations with a given categorical value, such as the class outcome value. This is called stratified cross-validation\",\n",
    "    \"What is repeated cross-validation?; This is where the k-fold cross-validation procedure is repeated n times, where importantly, the data sample is shuffled prior to each repetition, which results in a different split of the sample.\",\n",
    "    \"How Much Training Data is Required for Machine Learning?; The amount of data you need depends both on the complexity of your problem and on the complexity of your chosen algorithm.\",\n",
    "    \"What is over fitting?; Typically, a model is overfit if the skill of the model is better on the training dataset than on the test dataset.\",\n",
    "    \"What is under fitting ?;If the model skill is poor on both the training and the test datasets, the model may be underfit.\",\n",
    "    \"What is a confusion matrix?; A confusion matrix is a way of presenting the results of a classifier in the context of what was really observed.\",\n",
    "    \"What is the use of a confusion matrix?; It is useful as it allows you to quickly see the distribution of the types of errors made by a classifier on a classification predictive modeling problem.\",\n",
    "    \"What do you mean by a confusion matrix?; A confusion matrix is a technique for summarizing the performance of a classification algorithm.\",\n",
    "    \"What is Classification accuracy?; Classification accuracy is the ratio of correct predictions to total predictions made.\",\n",
    "    \"What is a Confusion Matrix?; A confusion matrix is a summary of prediction results on a classification problem. The number of correct and incorrect predictions are summarized with count values and broken down by each class. This is the key to the confusion matrix.\",\n",
    "    \"What do you mean by true positive?; It is correctly predicted event values.\",\n",
    "    \"What do you mean by false positive?; It is incorrectly predicted event values.\",\n",
    "    \"What do you mean by true negative?; It is correctly predicted no-event values.\",\n",
    "    \"What do you mean by false negative?; It is incorrectly predicted no-event values.\",\n",
    "    \"What is the difference between classification and regression?; Classification involves assigning an observation a label.Regression involves predicting a numerical quantity for an observation.\",\n",
    "    \"What is Classification task ?; It involves assigning an observation a label.\",\n",
    "    \"What is Regression task?; It involves predicting a numerical quantity for an observation.\",\n",
    "    \"What is Predictive modeling?; Predictive modeling is the problem of developing a model using historical data to make a prediction on new data where we do not have the answer.\",\n",
    "    \"Can you tell me more about Predictive modeling?; Predictive modeling can be described as the mathematical problem of approximating a mapping function (f) from input variables (X) to output variables (y).\",\n",
    "    \"Do you know modeling algorithm?; The job of the modeling algorithm is to find the best mapping function we can given the time and resources available.\",\n",
    "    \"Whast is regression algorithm?; An algorithm that is capable of learning a regression predictive model is called a regression algorithm.\",\n",
    "    \"What is Regularization?; Regularization refers to methods used to modify an objective function in order to reduce model overfitting.\",\n",
    "    \"can you tell me about L1 and L2 regularization?; L1 and L2 regularization refer to methods of calculating the length of a vector of model parameters (called the vector norm) in order that this length can be minimized as part of fitting the model.\",\n",
    "    \"How L1 norm is calculated?; L1 or the L1-norm is calculated as the sum of the absolute vector values. An example use of this form of regularization is used in Lasso Regression.\",\n",
    "    \"How L2 norm is calculated?;L2 or the L2-norm is calculate as the sum of the squared vector values. An example use of this form of regularization is used in Ridge Regression.\",\n",
    "    \"Do you know ElasticNet Regression algorithm uses which refularization?; The ElasticNet Regression algorithm uses a combination of both L1 and L2 regularization.\",\n",
    "    \"What is the difference between “L1” and “L2” regularization?; L1 or the L1-norm is calculated as the sum of the absolute vector values. An example use of this form of regularization is used in Lasso Regression.Whereas L2 or the L2-norm is calculated as the sum of the squared vector values. An example use of this form of regularization is used in Ridge Regression.\",\n",
    "    \"What is an overfit model?; An overfit model is one that fits the random noise in the data sample.\",\n",
    "    \"What happens in an overfit model?; The model may perform well on the training data, does not generalize to new data and performs well on test data.\",\n",
    "    \"What is an underfit model?; An underfit model is one that does not capture enough of the structure in the data sample.\",\n",
    "    \"What happens in an underfit model?; This means that the model will perform poor on the training and the test datasets. More fit or a better fit is required.\",\n",
    "    \"What is the difference between overfitting and underfitting ?; An overfit model may perform well on the training data, does not generalize to new data and performs well on test data. Whereas an underfit model will perform poor on the training and the test datasets. More fit or a better fit is required.\",\n",
    "    \"What is Standardization?; Standardization refers to scaling a variable that has a Gaussian distribution such that it has a mean of zero and a standard deviation of one.\",\n",
    "    \"What is Normalization?; Normalization refers to scaling a variable that has any distribution so that all values are between zero and one.\",\n",
    "    \"What is the difference between standardization and normalization?; Standardization refers to scaling a variable that has a Gaussian distribution such that it has a mean of zero and a standard deviation of one. Normalization refers to scaling a variable that has any distribution so that all values are between zero and one. It is possible to normalize after standardizing a variable.\",\n",
    "    \"What is a tolerance interval?; A tolerance interval describes the expected range of observations in a distribution. It could be used to identify outliers.\",\n",
    "    \"What is a confidence interval?; A confidence interval describes the expected range for a distribution parameter. It could be used to describe the accuracy or error of a model on average.\",\n",
    "    \"What is a prediction interval?; A prediction interval describes the expected range for an observation. It could be used to describe the uncertainty in a prediction.\",\n",
    "    \"What is a training dataset?; A training dataset is used to train or fit a model.\",\n",
    "    \"What is a test dataset?; A test dataset has observations that do not overlap with the training dataset and is used to evaluate a trained model. Specifically, to estimate the skill of the model on a new data sample.\",\n",
    "    \"What is a validation dataset?; A validation dataset typically refers to a portion of the training dataset, separated and used as a test dataset while the hyperparameters of the model are tuned.\",\n",
    "    \"What is a sample?; A sample is a single row of data, including the inputs for the network and the expected output.\",\n",
    "    \"What is a batch?; A batch is a collection of samples that the network will process, after which the model weights will be updated. The model will make predictions for each sample in the batch, the error will be calculated by comparing the prediction to the expected value, an error gradient will be estimated and the weights will be updated. A training dataset is split into one or more batches.\",\n",
    "    \"What is a epoch?; An epoch involves one pass over the training dataset. One epoch is comprised of one or more batches, depending on the chosen batch size.\",\n",
    "    \"What is a descriptive model?; A descriptive model is a model trained on historical data with the objective of understanding something about the problem, such as cause and effect.Descriptive modeling is often the goal in applied statistics and econometrics.\",\n",
    "    \"What is a predictive model?; A predictive model is a model trained on historical data with the objective of making accurate predictions.Predictive modeling is often the goal of applied machine learning, or a subfield referred to as predictive modeling.\",\n",
    "    \"What is a machine learning algorithm?; A machine learning algorithm is a procedure that is run on training data to create a model.It is the process that does the learning.Ex. Linear Regression, Random Forest.\",\n",
    "    \"What is a machine learning model?; A machine learning model is the result the learning process of a machine learning algorithm.A model is the 'program' that is saved after training, later loaded and used to make predictions on new data.\",\n",
    "    \"What is the difference between a model and an algorithm?;A machine learning algorithm is a procedure that is run on training data to create a model.A machine learning model is the result the learning process of a machine learning algorithm.\",\n",
    "    \"What are Model parameters?; Model parameters are internal to the model and learned by the training algorithm.Examples of model parameters are the coefficients in a regression, weights in a neural network, and the split points in a decision tree.\",\n",
    "    \"What are Model hyperparameters?; Model hyperparameters are specified by you, the practitioner and often control the learning process. They are parameters that cannot be learned.Examples of model hyperparameters are the number of epochs or training iterations in stochastic gradient descent and the maximum depth of decision trees.The model hyperparameters are found by trial-and-error, by grid/random searching, or by comping examples that have worked in the past.\",\n",
    "    \"What is sample?; A sample is comprised of one or more individual observations drawn from a domain.\",\n",
    "    \"What is population?; A population is the idealized notion of all possible observations from which specific samples of observations can be drawn.\",\n",
    "    \"What is the difference between a sample and a population?;In statistics, a sample and a population are used to refer to data.A sample is comprised of one or more individual observations drawn from a domain.A population is the idealized notion of all possible observations from which specific samples of observations can be drawn.In statistics, we often estimate parameters of the distribution of data in the population given a sample.\",\n",
    "    \"What programming language should I use for machine learning?; You can start with python or R\",\n",
    "    \"What value should I set for the random number seed?; The value used to seed the pseudorandom number generator does not matter. You can use any number you wish.\",\n",
    "    \"When should I standardize and normalize data?; Scaling methods are often appropriate with machine learning models that learn or make prediction on data using the distance between observations (e.g. k-nearest neighbors and support vector machines) and methods that calculate weighted sums of inputs (e.g. linear regression, logistic regression, and neural networks).If you are still in doubt as to whether you should standardize, normalize, both, or something else, then I would recommend establishing a baseline model performance on your raw data, then experiment with each scaling method and compare the resulting skill of the model.\",\n",
    "    \"When should I use MLP?;A Multilayer Perceptron or MLP can approximate a mapping function from inputs to outputs. They are flexible and can be adapted to most problems, nevertheless, they are perhaps more suited to classification and regression problems.\",\n",
    "    \"When should I use CNN?;A Convolutional Neural Network or CNN was developed and is best used for image classification. They can also be used generally for working with data that has a spatial structure, such as a sequence of words and can be used for document classification.\",\n",
    "    \"When should I use RNN?;A Recurrent Neural Network or RNN (such as the LSTM network) was developed for sequence prediction and are well suited for problems that have a sequence on input observations or a sequence of output observations. They are suitable for text data, audio data and similar applications.\",\n",
    "    \"Why are some scores like MSE negative in scikit-learn?; The scikit-learn library has a unified model scoring system where it assumes that all model scores are maximized. In order this system to work with scores that are minimized, like MSE and other measures of error, the sores that are minimized are inverted by making them negative.\",\n",
    "    \"Why can’t I get 100% accuracy or zero error with my model?; The model is an approximation for some unknown underlying perfect mapping function from inputs to the output being predicted.\",\n",
    "    \"Why can’t I get zero error with my model?;We cannot find the best possible model for a given predictive modeling problem, it is intractable.\",\n",
    "    \"Why do I get different results each time I run the algorithm?; Algorithms like artificial neural networks are stochastic, meaning that you will get different predictions when the same model is trained on the same data.You can fix the random seed to ensure the results are reproducible for a single run, but this is fragile and only a good idea for tutorial examples.\",\n",
    "    \"Do you have emotions?; No, I am just an intelligent computer\",\n",
    "    \"Do you like music?; Currently I'm still learning. Perhaps in future !!\",\n",
    "    \"I want to join ml+; email us at info@ml.plus\",\n",
    "    \"Why is naive Bayes so ‘naive’ ?; naive Bayes is so ‘naive’ because it assumes that all of the features in a data set are equally important and independent. As we know, these assumption are rarely true in real world scenario.\",\n",
    "    \"How is kNN different from kmeans clustering?; kmeans is unsupervised in nature and kNN is supervised in nature.\",\n",
    "    \"What's the difference between kmeans and kNN?; kmeans is a clustering algorithm. kNN is a classification (or regression) algorithm.\",\n",
    "    \"How kmeans works?; kmeans algorithm partitions a data set into clusters such that a cluster formed is homogeneous and the points in each cluster are close to each other. The algorithm tries to maintain enough separability between these clusters. Due to unsupervised nature, the clusters have no labels.\",\n",
    "    \"How kNN algorithm works?; kNN algorithm tries to classify an unlabeled observation based on its k (can be any number ) surrounding neighbors. It is also known as lazy learner because it involves minimal training of model. Hence, it doesn’t use training data to make generalization on unseen data set.\",\n",
    "    \"Why kNN is also called as lazy learner? It is also known as lazy learner because it involves minimal training of model. Hence, it doesn’t use training data to make generalization on unseen data set.\",\n",
    "    \"What is Kolomogorov Smirnov chart?; K-S or Kolmogorov-Smirnov chart measures performance of classification models.\",\n",
    "    \"Can you tell me about Kolomogorov Smirnov chart?; K-S is a measure of the degree of separation between the positive and negative distributions.\",\n",
    "    \"What does a value of 100 in K-S chart means?; The K-S is 100, if the scores partition the population into two separate groups in which one group contains all the positives and the other all the negatives.\",\n",
    "    \"What does a value of 100 in Kolomogorov Smirnov chart means?; The K-S is 100, if the scores partition the population into two separate groups in which one group contains all the positives and the other all the negatives.\",\n",
    "    \"Why should you use ROC and not metrics like lift curve?;Lift is dependent on total response rate of the population. Hence, if the response rate of the population changes, the same model will give a different lift chart.ROC curve on the other hand is almost independent of the response rate. This is because it has the two axis coming out from columnar calculations of confusion matrix. The numerator and denominator of both x and y axis will change on similar scale in case of response rate shift.\",\n",
    "    \"Gini Coefficient?; Gini coefficient can be straigh away derived from the AUC ROC number. Gini is nothing but ratio between area between the ROC curve and the diagnol line & the area of the above triangle. Following is the formulae used :Gini = 2*AUC – 1. Gini above 60% is a good model.\",\n",
    "    \"What do you know about Gini Coefficient?; It is the ratio between area between the ROC curve and the diagnol line & the area of the above triangle.\",\n",
    "    \"What is gini coefficient?; The ratio between area between the ROC curve and the diagnol line & the area of the above triangle. Gini above 60% is a good model\",\n",
    "    \"How is True Positive Rate and Recall related?;True Positive Rate = Recall. Yes, they are equal having the formula (TP/TP + FN).\",\n",
    "    \"how to check for multicollinearity?; To check multicollinearity, we can create a correlation matrix to identify & remove variables having correlation above 75% (deciding a threshold is subjective). In addition, we can use calculate VIF (variance inflation factor) to check the presence of multicollinearity.\",\n",
    "    \"When to use lasso regression?; In presence of few variables with medium / large sized effect, use lasso regression.\",\n",
    "    \"When to use ridge regression?;In presence of many variables with small / medium sized effect, use ridge regression.\",\n",
    "    \"What do you know about L1 regression?;lasso regression (L1) does both variable selection and parameter shrinkage\",\n",
    "    \"Can you tell me about L2 regression?; Ridge regressionof L2 regz, only does parameter shrinkage and end up including all the coefficients in the model.\",\n",
    "    \"What is convex hull ?;  In case of linearly separable data, convex hull represents the outer boundaries of the two group of data points. Once convex hull is created, we get maximum margin hyperplane (MMH) as a perpendicular bisector between two convex hulls\",\n",
    "    \"Do you suggest that treating a categorical variable as continuous variable would result in a better predictive model?Answer: For better predictions, categorical variable can be considered as a continuous variable only when the variable is ordinal in nature.\",\n",
    "    \"When does regularization becomes necessary in Machine Learning?; Regularization becomes necessary when the model begins to ovefit / underfit. This technique introduces a cost term for bringing in more features with the objective function. Hence, it tries to push the coefficients for many variables to zero and hence reduce cost term\",\n",
    "    \"What is Ordinary least square(OLS)?; Ordinary least square(OLS) is a method used in linear regression which approximates the parameters resulting in minimum distance between actual and predicted values.\",\n",
    "    \"What is Maximum likelihood?; Maximum likelihood is a method used in logistic regression to choose the values of parameters which maximizes the likelihood that the parameters are most likely to produce observed data.\",\n",
    "    \"What is machine learning?;machine learning is a form of AI that automates data analysis to enable computers to learn and adapt through experience to do specific tasks without explicit programming.\",\n",
    "    \"What is deep learning? ; Deep learning is a subset of machine learning. It refers to using multi-layered neural networks to process data in increasingly complex ways, enabling the software to train itself to perform tasks like speech and image recognition through exposure to these vast amounts of data.\",\n",
    "    \"Can you tell me more about Deep Learning?; the machine undergoes continual improvement in the ability to recognize and process information. Layers of neural networks stacked on top of each for use in deep learning are called deep neural networks.\",\n",
    "    \"How do deductive and inductive machine learning differ?;Deductive machine learning starts with a conclusion, then learns by deducing what is right or wrong about that conclusion. Inductive machine learning starts with examples from which to draw conclusions.\",\n",
    "    \"What is Deductive machine learning?; Deductive machine learning starts with a conclusion, then learns by deducing what is right or wrong about that conclusion\",\n",
    "    \"What is Inductive machine learning?; Inductive machine learning starts with examples from which to draw conclusions.\",\n",
    "    \"How do you choose an algorithm for a classification problem?; The answer depends on the degree of accuracy needed and the size of the training set. If you have a small training set, you can use a low variance/high bias classifier. If your training set is large, you will want to choose a high variance/low bias classifier.\",\n",
    "    \"What are some methods of reducing dimensionality?; You can reduce dimensionality by combining features with feature engineering, removing collinear features, or using algorithmic dimensionality reduction. \",\n",
    "    \"How do classification and regression differ?; Classification predicts group or class membership. Regression involves predicting a response.\",\n",
    "    \"Whats is classification?; Classification predicts group or class membership.\",\n",
    "    \"What is regression?; Regression involves predicting a response.\",\n",
    "    \"What is supervised versus unsupervised learning?; Supervised learning is a process of machine learning in which outputs are fed back into a computer for the software to learn from for more accurate results the next time. With supervised learning, the “machine” receives initial training to start. In contrast, unsupervised learning means a computer will learn without initial training.\",\n",
    "    \"How does supervised learning differs from unsepervised learning?; Supervised learning is a process of machine learning in which outputs are fed back into a computer for the software to learn from for more accurate results the next time. With supervised learning, the “machine” receives initial training to start. In contrast, unsupervised learning means a computer will learn without initial training.\",\n",
    "    \"What is kernel SVM?; Kernel SVM is the abbreviated version of kernel support vector machine. Kernel methods are a class of algorithms for pattern analysis and the most common one is the kernel SVM. \",\n",
    "    \"What is decision tree classification?; A decision tree builds classification (or regression) models as a tree structure, with datasets broken up into ever smaller subsets while developing the decision tree, literally in a tree-like way with branches and nodes. Decision trees can handle both categorical and numerical data. \",\n",
    "    \"What is sequence learning?; Sequence learning is a method of teaching and learning in a logical manner.\",\n",
    "    \"What is PAC Learning?; PAC (Probably Approximately Correct) learning is a learning framework that has been introduced to analyze learning algorithms and their statistical efficiency.\",\n",
    "    \"What do you understand by Machine Learning?; Machine learning is an application of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\",\n",
    "    \"What are the different Algorithm techniques in Machine Learning?; The different types of Algorithm techniques in Machine Learning are as follows:Reinforcement Learning,Supervised Learning,Unsupervised Learning,Semi-supervised Learning,Transduction,Learning to Learn\",\n",
    "    \"What is the difference between supervised and unsupervised machine learning?; A Supervised learning is a process where it requires training labeled data While Unsupervised learning it doesn’t require data labeling.\",\n",
    "    \"What is the function of Unsupervised Learning?; The function of Unsupervised Learning are: Find clusters of the data of the data,Find low-dimensional representations of the data,Find interesting directions in data,Interesting coordinates and correlations,Find novel observations\",\n",
    "    \"What is the function of Supervised Learning?; The function of Supervised Learning are:Classifications,Speech recognition,Regression,Predict time series,Annotate strings\",\n",
    "    \"What are the advantages of Naive Bayes?; The advantages of Naive Bayes are:The classifier will converge quicker than discriminative models,It cannot learn interactions between features\",\n",
    "    \"What are the disadvantages of Naive Bayes?; The disadvantages of Naive Bayes are:It is because the problem arises for continuous features,It makes a very strong assumption on the shape of your data distribution,It can also happen because of data scarcity\",\n",
    "    \"Why is naive Bayes so naive?; Naive Bayes is so naive because it assumes that all of the features in a data set are equally important and independent.\",\n",
    "    \"What is Overfitting in Machine Learning?;Overfitting in Machine Learning is defined as when a statistical model describes random error or noise instead of underlying relationship or when a model is excessively complex.\",\n",
    "    \"What are the conditions when Overfitting happens?; One of the important reason and possibility of overfitting is because the criteria used for training the model is not the same as the criteria used to judge the efficacy of a model.\",\n",
    "    \"How can you avoid overfitting?;We can avoid overfitting by using:Lots of data,Cross-validation\",\n",
    "    \"How can I avoid overfitting?;You can avoid overfitting by using:Lots of data,Cross-validation\",\n",
    "    \"How to avoid overfitting?;Avoid overfitting by using:Lots of data,Cross-validation\",\n",
    "    \"What are the five popular algorithms for Machine Learning?;The five popular algorithms of Machine Learning:Decision Trees,Probabilistic networks,Nearest Neighbor,Support vector machines,Neural Networks\",\n",
    "    \"Can you name some popular algorithms for Machine Learning?;The popular algorithms of Machine Learning:Decision Trees,Probabilistic networks,Nearest Neighbor,Support vector machines,Neural Networks\",\n",
    "    \"Name some popular algorithms for Machine Learning?;The popular algorithms of Machine Learning:Decision Trees,Probabilistic networks,Nearest Neighbor,Support vector machines,Neural Networks\",\n",
    "    \"Give me name some popular algorithms for Machine Learning?;The popular algorithms of Machine Learning:Decision Trees,Probabilistic networks,Nearest Neighbor,Support vector machines,Neural Networks\",\n",
    "    \"What are the different use cases where machine learning algorithms can be used?; The different use cases where machine learning algorithms can be used are as follows:Fraud Detection,Face detection,Natural language processing,Market Segmentation,Text Categorization,Bioinformatics\",\n",
    "    \"What are parametric models and Non-Parametric models?; Parametric models are those with a finite number of parameters and to predict new data, you only need to know the parameters of the model. Non Parametric models are those with an unbounded number of parameters, allowing for more flexibility and to predict new data, you need to know the parameters of the model and the state of the data that has been observed.\",\n",
    "    \"What are parametric models?;Parametric models are those with a finite number of parameters and to predict new data, you only need to know the parameters of the model.\",\n",
    "    \"What are non-parametric models?;Non Parametric models are those with an unbounded number of parameters, allowing for more flexibility and to predict new data, you need to know the parameters of the model and the state of the data that has been observed.\",\n",
    "    \"What are the three stages to build the hypotheses or model in machine learning?; The three stages to build the hypotheses or model in machine learning are:1. Model building,2. Model testing,3. Applying the model\",\n",
    "    \"Machine Learning model building stages?;The three stages to build the hypotheses or model in machine learning are:1. Model building,2. Model testing,3. Applying the model\",\n",
    "    \"What are the stages of building Machine Learning model?;The three stages to build the hypotheses or model in machine learning are:1. Model building,2. Model testing,3. Applying the model\",\n",
    "    \"What is Inductive Logic Programming in Machine Learning (ILP)?;Inductive Logic Programming (ILP) is a subfield of machine learning which uses logical programming representing background knowledge and examples.\",\n",
    "    \"What is ILP?;  Inductive Logic Programming (ILP) is a subfield of machine learning which uses logical programming representing background knowledge and examples.\",\n",
    "    \"What is the difference between classification and regression?; Classification is about identifying group membership while regression technique involves predicting a response.Classification and Regression techniques are related to prediction.Classification predicts the belonging to a class whereas regression predicts the value from a continuous set.Classification technique is preferred over regression when the results of the model need to return the belongingness of data points in a dataset with specific explicit categories\",\n",
    "    \"What are the difference between inductive machine learning and deductive machine learning?; inductive machine learning is where the model learns by examples from a set of observed instances to draw a generalized conclusion whereas in deductive learning the model first draws the conclusion and then the conclusion is drawn.\",\n",
    "    \"What are the advantages decision trees?; The advantages decision trees are:Decision trees are easy to interpret,Nonparametric,There are relatively few parameters to tune\",\n",
    "    \"What are the disadvantages of decision trees?; Decision trees are prone to be overfit. However, this can be addressed by ensemble methods like random forests or boosted trees.\",\n",
    "    \"What are the advantages of neural networks?; Neural networks have led to performance breakthroughs for unstructured datasets such as images, audio, and video. Their incredible flexibility allows them to learn patterns that no other Machine Learning algorithm can learn.\",\n",
    "    \"What are the disadvantages of neural networks?; Neural Network requires a large amount of training data to converge. It’s also difficult to pick the right architecture, and the internal “hidden” layers are incomprehensible.\",\n",
    "    \"What is the difference between L1 and L2 regularization?;L1/Laplace tends to tolerate both large values as well as very small values of coefficients more than L2/Gaussian.L1 can yield sparse models while L2 doesn’t.L1 and L2 regularization prevents overfitting by shrinking on the coefficients.L2 (Ridge) shrinks all the coefficient by the same proportions but eliminates none, while L1 (Lasso) can shrink some coefficients to zero, performing variable selection.L1 is the first-moment norm |x1-x2| that is simply the absolute dıstance between two points where L2 is second-moment norm corresponding to Euclidean Distance that is |x1-x2|^2.L2 regularization tends to spread error among all the terms, while L1 is more binary/sparse\",\n",
    "    \"What's an Activation function?; the activation function of a node defines the output of that node given an input or set of inputs.\",\n",
    "    \"AdaBoost?; AdaBoost, short for “Adaptive Boosting”, is the first practical boosting algorithm proposed by Freund and Schapire in 1996\",\n",
    "    \"What is AdaBoost?; AdaBoost is short for Adaptive Boosting, focuses on classification problems and aims to convert a set of weak classifiers into a strong one.\",\n",
    "    \"What do you know about AdaBoost?; AdaBoost is short for Adaptive Boosting, focuses on classification problems and aims to convert a set of weak classifiers into a strong one.\",\n",
    "    \"AdaGrad?;Adaptive Subgradient Methods\",\n",
    "    \"What is Adaptive Subgradient Methods?;AdaGrad is an optimization method that allows different step sizes for different features. It increases the influence of rare but informative features.\",\n",
    "    \"What is AdaGrad Methods?;AdaGrad is an optimization method that allows different step sizes for different features. It increases the influence of rare but informative features.\",\n",
    "    \"Adjacency matrix?; An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.\",\n",
    "    \"What's an Adjacency matrix?; An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.\",\n",
    "    \"What's an Adjacency matrix?; An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.\",\n",
    "    \"Agglomerative clustering?;Agglomerative clustering is a strategy of hierarchical clustering. Hierarchical clustering (also known as Connectivity based clustering) is a method of cluster analysis which seeks to build a hierarchy of clusters.\",\n",
    "    \"What is Agglomerative clustering?;Agglomerative clustering is a strategy of hierarchical clustering. Hierarchical clustering (also known as Connectivity based clustering) is a method of cluster analysis which seeks to build a hierarchy of clusters.\",\n",
    "    \"What is an Agglomerative clustering?;Agglomerative clustering is a strategy of hierarchical clustering. Hierarchical clustering (also known as Connectivity based clustering) is a method of cluster analysis which seeks to build a hierarchy of clusters.\",\n",
    "    \"Which technique is used to predict categorical responses?; Classification technique is used widely in mining for classifying data sets.\",\n",
    "    \"What is logistic regression?; Logistic Regression often referred as logit model is a technique to predict the binary outcome from a linear combination of predictor variables. For example, if you want to predict whether a particular political leader will win the election or not.\",\n",
    "    \"What are Recommender Systems?; A subclass of information filtering systems that are meant to predict the preferences or ratings that a user would give to a product. Recommender systems are widely used in movies, news, research articles, products, social tags, music, etc.\",\n",
    "    \"Do you know where Recommender systems are used widely?; Recommender systems are widely used in movies, news, research articles, products, social tags, music, etc.\",\n",
    "    \"Why data cleaning plays a vital role in analysis?; Cleaning data from multiple sources to transform it into a format that data analysts or data scientists can work with is a cumbersome process because - as the number of data sources increases, the time take to clean the data increases exponentially due to the number of sources and the volume of data generated in these sources. It might take up to 80% of the time for just cleaning data making it a critical part of analysis task.\",\n",
    "    \"Why cleaning the data is important?;As the number of data sources increases, the time take to clean the data increases exponentially due to the number of sources and the volume of data generated in these sources. It might take up to 80% of the time for just cleaning data making it a critical part of analysis task.\",\n",
    "    \"Why data cleaning is important?;As the number of data sources increases, the time take to clean the data increases exponentially due to the number of sources and the volume of data generated in these sources. It might take up to 80% of the time for just cleaning data making it a critical part of analysis task.\",\n",
    "    \"Bivariate analysis?; If the analysis attempts to understand the difference between 2 variables at time as in a scatterplot, then it is referred to as bivariate analysis. \",\n",
    "    \"What is Bivariate analysis?; If the analysis attempts to understand the difference between 2 variables at time as in a scatterplot, then it is referred to as bivariate analysis. \",\n",
    "    \"Do you know Bivariate analysis?; If the analysis attempts to understand the difference between 2 variables at time as in a scatterplot, then it is referred to as bivariate analysis. \",   \n",
    "    \"What is multivariate analysis?;Analysis that deals with the study of more than two variables to understand the effect of variables on the responses is referred to as multivariate analysis.\",\n",
    "    \"univariate analysis?;These are descriptive statistical analysis techniques which can be differentiated based on the number of variables involved at a given point of time.\",\n",
    "    \"What do you understand by the term Normal Distribution?; Data is usually distributed in different ways with a bias to the left or to the right or it can all be jumbled up. However, there are chances that data is distributed around a central value without any bias to the left or right and reaches normal distribution in the form of a bell shaped curve. The random variables are distributed in the form of an symmetrical bell shaped curve.\",\n",
    "    \"What is Normal Distribution?; In this the data is distributed around a central value without any bias to the left or right and reaches normal distribution in the form of a bell shaped curve. The random variables are distributed in the form of an symmetrical bell shaped curve.\",\n",
    "    \"Normal Distribution is what?; In a normal distribution the data is distributed around a central value without any bias to the left or right and reaches normal distribution in the form of a bell shaped curve.\",\n",
    "    \"What is Linear Regression?; Linear regression is a statistical technique where the score of a variable Y is predicted from the score of a second variable X. X is referred to as the predictor variable and Y as the criterion variable.\",\n",
    "    \"What is Interpolation and Extrapolation?; Estimating a value from 2 known values from a list of values is Interpolation. Extrapolation is approximating a value by extending a known set of values or facts.\",\n",
    "    \"What is the difference between Interpolation and Extrapolation?; Estimating a value from 2 known values from a list of values is Interpolation. Extrapolation is approximating a value by extending a known set of values or facts.\",\n",
    "    \"What is Interpolation?; Estimating a value from 2 known values from a list of values is Interpolation. Extrapolation is approximating a value by extending a known set of values or facts.\",\n",
    "    \"What is Extrapolation?;Extrapolation is approximating a value by extending a known set of values or facts.\",\n",
    "    \"What is power analysis?; An experimental design technique for determining the effect of a given sample size.\",\n",
    "    \"What is Collaborative filtering?; The process of filtering used by most of the recommender systems to find patterns or information by collaborating viewpoints, various data sources and multiple agents.\",\n",
    "    \"What is the Cluster Sampling?; Cluster sampling is a technique used when it becomes difficult to study the target population spread across a wide area and simple random sampling cannot be applied. Cluster Sample is a probability sample where each sampling unit is a collection, or cluster of elements.\",\n",
    "    \"What is the Systematic Sampling?;Systematic sampling is a statistical technique where elements are selected from an ordered sampling frame. In systematic sampling, the list is progressed in a circular manner so once you reach the end of the list,it is progressed from the top again. The best example for systematic sampling is equal probability method.\",\n",
    "    \"Are expected value and mean value different?; They are not different but the terms are used in different contexts. Mean is generally referred when talking about a probability distribution or sample population whereas expected value is generally referred in a random variable context.\",\n",
    "    \"P-value?; P-value is used to determine the significance of results after a hypothesis test in statistics. P-value helps the readers to draw conclusions and is always between 0 and 1.\",\n",
    "    \"What is P-value?; P-value is used to determine the significance of results after a hypothesis test in statistics. P-value helps the readers to draw conclusions and is always between 0 and 1.\",\n",
    "    \"Can you tell me more about P-value?; P-value is used to determine the significance of results after a hypothesis test in statistics. P-value helps the readers to draw conclusions and is always between 0 and 1.P- Value > 0.05 denotes weak evidence against the null hypothesis which means the null hypothesis cannot be rejected.P-value <= 0.05 denotes strong evidence against the null hypothesis which means the null hypothesis can be rejected.P-value=0.05is the marginal value indicating it is possible to go either way.\",\n",
    "    \"Do gradient descent methods always converge to same point?; No, they do not because in some cases it reaches a local minima or a local optima point. You don’t reach the global optima point. It depends on the data and starting conditions\",\n",
    "    \"Supervised learning?; If an algorithm learns something from the training data so that the knowledge can be applied to the test data, then it is referred to as Supervised Learning.\",\n",
    "    \"What is Supervised learning?; If an algorithm learns something from the training data so that the knowledge can be applied to the test data, then it is referred to as Supervised Learning.\",\n",
    "    \"Give me an example of Supervised learning.; Classification is an example for Supervised Learning.\",\n",
    "    \"What is unsupervised learning?;If the algorithm does not learn anything beforehand because there is no response variable or any training data, then it is referred to as unsupervised learning.\",\n",
    "    \"Give me an example of unupervised learning.;Clustering is an example for unsupervised learning.\",\n",
    "    \"What is the goal of A/B Testing?; It is a statistical hypothesis testing for randomized experiment with two variables A and B. The goal of A/B Testing is to identify any changes to the web page to maximize or increase the outcome of an interest. An example for this could be identifying the click through rate for a banner ad.\",\n",
    "    \"What is an Eigenvalue and Eigenvector?;Eigenvectors are used for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. Eigenvectors are the directions along which a particular linear transformation acts by flipping, compressing or stretching. Eigenvalue can be referred to as the strength of the transformation in the direction of eigenvector or the factor by which the compression occurs.\",\n",
    "    \"Eigenvectors?; Eigenvectors are used for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. Eigenvectors are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"Eigenvalue?; Eigenvalue can be referred to as the strength of the transformation in the direction of eigenvector or the factor by which the compression occurs.\",\n",
    "    \"What is an Eigenvector?; Eigenvectors are used for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. Eigenvectors are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"What is an Eigenvalue?; Eigenvalue can be referred to as the strength of the transformation in the direction of eigenvector or the factor by which the compression occurs.\",\n",
    "    \"How can outlier values be treated?; Outlier values can be identified by using univariate or any other graphical analysis method. If the number of outlier values is few then they can be assessed individually but for large number of outliers the values can be substituted with either the 99th or the 1st percentile values. All extreme values are not outlier values.The most common ways to treat outlier values –1) To change the value and bring in within a range,2) To just remove the value.\",\n",
    "    \"How can you assess a good logistic model?; There are various methods to assess the results of a logistic regression analysis-Using Classification Matrix to look at the true negatives and false positives,Concordance that helps identify the ability of the logistic model to differentiate between the event happening and not happening,Lift helps assess the logistic model by comparing it with random selection.\",\n",
    "    \"How can you iterate over a list and also retrieve element indices at the same time?; This can be done using the enumerate function which takes every element in a sequence just like in a list and adds its location just before it.\",\n",
    "    \"During analysis, how do you treat missing values?; Understand the problem statement, understand the data and then give the answer.Assigning a default value which can be mean, minimum or maximum value. Getting into the data is important.If it is a categorical variable, the default value is assigned. The missing value is assigned a default value.If you have a distribution of data coming, for normal distribution give the mean value.\",\n",
    "    \"Explain about the box cox transformation in regression models.; A Box cox transformation is a statistical technique to transform non-mornla dependent variables into a normal shape. If the given data is not normal then most of the statistical techniques assume normality. Applying a box cox transformation means that you can run a broader number of tests.\",\n",
    "    \"Can you use machine learning for time series analysis?; Yes, it can be used but it depends on the applications.\",\n",
    "    \"What is Machine Learning?; we give the data and equation to the machine. Ask the machine to look at the data and identify the coefficient values in an equation.For example for the linear regression y=mx+c, we give the data for the variable x, y and the machine learns about the values of m and c from the data.\",\n",
    "    \"uniform distribution?; When the observations in a dataset are spread equally across the range of distribution, then it is referred to as uniform distribution. There are no clear perks in an uniform distribution.\",\n",
    "    \"skewed distribution?; Distributions that have more observations on one side of the graph than the other  are referred to as skewed distribution\",\n",
    "    \"skewed left?;Distributions with fewer observations on the left ( towards lower values) are said to be skewed left.\",\n",
    "    \"skewed right?; distributions with fewer observation on the right ( towards higher values) are said to be skewed right.\",\n",
    "    \"What is left skew?;Distributions with fewer observations on the left ( towards lower values) are said to be skewed left.\",\n",
    "    \"skewed right?; distributions with fewer observation on the right ( towards higher values) are said to be skewed right.\",\n",
    "    \"What is Regularizations?; Regularizations in statistics or in the field of machine learning is used to include some extra information in order to solve a problem in a better way.\",\n",
    "    \"Why L1 regularizations causes parameter sparsity whereas L2 regularization does not?; L1 & L2 regularizations are generally used to add constraints to optimization problems.\",\n",
    "    \"How can you deal with different types of seasonality in time series modelling?; Seasonality in time series occurs when time series shows a repeated pattern over time. E.g., stationary sales decreases during holiday season, air conditioner sales increases during the summers etc. are few examples of seasonality in a time series.\",\n",
    "    \"test set?; test set is used for testing or evaluating the performance of a trained machine leaning model.\",\n",
    "    \"What is a test set?; test set is used for testing or evaluating the performance of a trained machine leaning model.\",\n",
    "    \"Do you know what a test set is?; test set is used for testing or evaluating the performance of a trained machine leaning model.\",\n",
    "    \"Validation set?; Validation set can be considered as a part of the training set as it is used for parameter selection and to avoid Overfitting of the model being built.\",\n",
    "    \"What is Validation set?; Validation set can be considered as a part of the training set as it is used for parameter selection and to avoid Overfitting of the model being built.\",\n",
    "    \"Do you know about Validation set?; Validation set can be considered as a part of the training set as it is used for parameter selection and to avoid Overfitting of the model being built.\",\n",
    "    \"Training Set?;Training Set is to fit the parameters i.e. weights.\",\n",
    "    \"What is Training Set?;Training Set is to fit the parameters i.e. weights.\",\n",
    "    \"What do you know about Training Set?;Training Set is to fit the parameters i.e. weights.\",\n",
    "    \"Test Set?; Test Set is to assess the performance of the model i.e. evaluating the predictive power and generalization.\",\n",
    "    \"What is a Test Set?; Test Set is to assess the performance of the model i.e. evaluating the predictive power and generalization.\",\n",
    "    \"What do you know about a Test Set?; Test Set is to assess the performance of the model i.e. evaluating the predictive power and generalization.\",\n",
    "    \"What is a Validation set?; Validation set is to tune the parameters.\",\n",
    "    \"How to calculate Sensitivity?;Senstivity = True Positives /Positives in Actual Dependent Variable. Where, True positives are Positive events which are correctly classified as Positives\",\n",
    "    \"What is Sensitivity?;Senstivity = True Positives /Positives in Actual Dependent Variable. Where, True positives are Positive events which are correctly classified as Positives\",\n",
    "    \"Do you know Sensitivity?;Senstivity = True Positives /Positives in Actual Dependent Variable. Where, True positives are Positive events which are correctly classified as Positives\",\n",
    "    \"What is the importance of having a selection bias?;Selection Bias occurs when there is no appropriate randomization acheived while selecting individuals, groups or data to be analysed.\",\n",
    "    \"Selection bias?; Selection bias implies that the obtained sample does not exactly represent the population that was actually intended to be analyzed.\",\n",
    "    \"Selection bias consisits of what?;Selection bias consists of Sampling Bias, Data, Attribute and Time Interval.\",\n",
    "    \"where you will use an SVM over a RandomForest Machine Learning algorithm and vice-versa?; If you are sure that your data is outlier free and clean then go for SVM. It is the opposite -   if your data might contain outliers then Random forest would be the best choice \",    \n",
    "    \"Do you know about SVM and Random Forest?; SVM and Random Forest are both used in classification problems.\",\n",
    "    \"SVM or Random Forest?; SVM consumes more computational power than Random Forest, so if you are constrained with memory go for Random Forest machine learning algorithm.\",\n",
    "    \"Do I use SVM and Random Forest?;Random Forest gives you a very good idea of variable importance in your data, so if you want to have variable importance then choose Random Forest machine learning algorithm.\",\n",
    "    \"Algorithm for multiclass problems.;Random Forest machine learning algorithms are preferred for multiclass problems.\",\n",
    "    \"For multi-dimensional problem set?; SVM is preferred in multi-dimensional problem set - like text classification\",\n",
    "    \"For text classification problem set?; SVM is preferred in multi-dimensional problem set - like text classification\",\n",
    "    \"What are the basic assumptions to be made for linear regression?; Normality of error distribution, statistical independence of errors, linearity and additivity.\",\n",
    "    \"Can you write the formula to calculat R-square?;R-Square can be calculated using the below formular :1 - (Residual Sum of Squares/ Total Sum of Squares)\",\n",
    "    \"What is the advantage of performing dimensionality reduction before fitting an SVM?;Support Vector Machine Learning Algorithm performs better in the reduced space. It is beneficial to perform dimensionality reduction before fitting an SVM if the number of features is large when compared to the number of observations.\",\n",
    "    \"How will you assess the statistical significance of an insight whether it is a real insight or just by chance?;Statistical importance of an insight can be accessed using Hypothesis Testing.\",\n",
    "    \"How will you find the correlation between a categorical variable and a continuous variable ?; You can use the analysis of covariance technqiue to find the correlation between a categorical variable and a continuous variable.\",\n",
    "    \"How to find the correlation between a categorical variable and a continuous variable ?; You can use the analysis of covariance technqiue to find the correlation between a categorical variable and a continuous variable.\",\n",
    "    \"Explain what regularization is?;Regularization is the process of adding a tuning parameter to a model to induce smoothness in order to prevent overfitting.\",\n",
    "    \"what is regularization?;Regularization is the process of adding a tuning parameter to a model to induce smoothness in order to prevent overfitting.\",\n",
    "    \"How regularization is performed?; This is most often done by adding a constant multiple to an existing weight vector. This constant is often either the L1 (Lasso) or L2 (ridge), but can in actuality can be any norm. The model predictions should then minimize the mean of the loss function calculated on the regularized training set. \",\n",
    "    \"How to perform regularization?; This is most often done by adding a constant multiple to an existing weight vector. This constant is often either the L1 (Lasso) or L2 (ridge), but can in actuality can be any norm. The model predictions should then minimize the mean of the loss function calculated on the regularized training set. \",\n",
    "    \"How to do regularization?; This is most often done by adding a constant multiple to an existing weight vector. This constant is often either the L1 (Lasso) or L2 (ridge), but can in actuality can be any norm. The model predictions should then minimize the mean of the loss function calculated on the regularized training set. \",\n",
    "    \"How would you validate a model you created to generate a predictive model of a quantitative outcome variable using multiple regression?;If the values predicted by the model are far outside of the response variable range, this would immediately indicate poor estimation or model inaccuracy. \",\n",
    "    \"Method to perform model validation?; If the values seem to be reasonable, examine the parameters; any of the following would indicate poor estimation or multi-collinearity: opposite signs of expectations, unusually large or small values, or observed inconsistency when the model is fed new data.\",\n",
    "    \"model validity measure?; Use the model for prediction by feeding it new data, and use the coefficient of determination (R squared) as a model validity measure.\",\n",
    "    \"model validation?; Use data splitting to form a separate dataset for estimating model parameters, and another for validating predictions.\",\n",
    "    \"How to validate model?; Use jackknife resampling if the dataset contains a small number of instances, and measure validity with R squared and mean squared error (MSE).\",\n",
    "    \" TN / True Negative; case was negative and predicted negative \",\n",
    "    \" TN ?; True Negative- case was negative and predicted negative \",\n",
    "    \"True Negative; case was negative and predicted negative \",\n",
    "    \"what is True Negative?; case was negative and predicted negative \",\n",
    "    \"what is TN?; case was negative and predicted negative \",\n",
    "    \"Do you know True Negative?; case was negative and predicted negative \",\n",
    "    \"Do you know TN?; case was negative and predicted negative \",    \n",
    "    \" TP / True Positive; case was positive and predicted positive \", \n",
    "    \"True Positive; case was positive and predicted positive \", \n",
    "    \" TP ; True Positive- case was positive and predicted positive \", \n",
    "    \"what is True Positive?; case was positive and predicted positive \", \n",
    "    \"what is TP?; case was positive and predicted positive \",    \n",
    "    \"Do you know True Positive?; case was positive and predicted positive \", \n",
    "    \"Do you know TP?; case was positive and predicted positive \",  \n",
    "    \" FN / False Negative; case was positive but predicted negative \",\n",
    "    \" False Negative; case was positive but predicted negative \",\n",
    "    \" FN; case was positive but predicted negative \",\n",
    "    \" what is FN ?; case was positive but predicted negative \",\n",
    "    \" What is False Negative; case was positive but predicted negative \",\n",
    "    \" Do you know False Negative?; case was positive but predicted negative \",\n",
    "    \" Do you know FN ?; case was positive but predicted negative \",\n",
    "    \" FP / False Positive; case was negative but predicted positive \",\n",
    "    \" FP; case was negative but predicted positive \",\n",
    "    \"False Positive; case was negative but predicted positive \",\n",
    "    \"what is FP?: case was negative but predicted positive \",\n",
    "    \"what is False Positive?: case was negative but predicted positive \",\n",
    "    \"Do you know FP?: case was negative but predicted positive \",\n",
    "    \"Do you know False Positive?: case was negative but predicted positive \",\n",
    "    \"ROC?;ROC curve represents a relation between sensitivity (RECALL) and specificity(NOT PRECISION) and is commonly used to measure the performance of binary classifiers.\",\n",
    "    \"when to use Precision-Recall?;when dealing with highly skewed datasets, Precision-Recall (PR) curves give a more representative picture of performance.\",\n",
    "    \"What is root cause analysis?;Root cause analysis (RCA) is a method of problem solving used for identifying the root causes of faults or problems.\",\n",
    "    \"causal factor? causal factor is one that affects an event's outcome, but is not a root cause. \",\n",
    "    \"what is causal factor? causal factor is one that affects an event's outcome, but is not a root cause. \",\n",
    "    \"What is Price optimization?; Price optimization is the use of mathematical tools to determine how customers will respond to different prices for its products and services through different channels.\",\n",
    "    \"What is Inventory management?; Inventory management is the overseeing and controlling of the ordering, storage and use of components that a company will use in the production of the items it will sell as well as the overseeing and controlling of quantities of finished products for sale.\",\n",
    "    \"What do you know about Inventory management?; Inventory management is the overseeing and controlling of the ordering, storage and use of components that a company will use in the production of the items it will sell as well as the overseeing and controlling of quantities of finished products for sale.\",\n",
    "    \"Do you know about Inventory management?; Inventory management is the overseeing and controlling of the ordering, storage and use of components that a company will use in the production of the items it will sell as well as the overseeing and controlling of quantities of finished products for sale.\",\n",
    "    \"Competitive intelligence?; the action of defining, gathering, analyzing, and distributing intelligence about products, customers, competitors, and any aspect of the environment needed to support executives and managers making strategic decisions for an organization.\",\n",
    "    \"What is Competitive intelligence?; the action of defining, gathering, analyzing, and distributing intelligence about products, customers, competitors, and any aspect of the environment needed to support executives and managers making strategic decisions for an organization.\",\n",
    "    \"Do you know Competitive intelligence?; the action of defining, gathering, analyzing, and distributing intelligence about products, customers, competitors, and any aspect of the environment needed to support executives and managers making strategic decisions for an organization.\",\n",
    "    \"What is statistical power?; Statistical power is the likelihood that a study will detect an effect when the effect is present. The higher the statistical power, the less likely you are to make a Type II error (concluding there is no effect when, in fact, there is).\",\n",
    "    \"What is selection bias?;Selection bias, in general, is a problematic situation in which error is introduced due to a non-random population sample.Avoiding non-random samples is the best way to deal with bias; however, when this is impractical, techniques such as resampling, boosting, and weighting are strategies which can be introduced to help deal with the situation.\",\n",
    "    \"What are feature vectors?; A feature vector is an n-dimensional vector of numerical features that represent some object\",\n",
    "    \"What are feature vectors in machine learning ?; In machine learning, feature vectors are used to represent numeric or symbolic characteristics, called features, of an object in a mathematical, easily analyzable way.\",\n",
    "    \"feature vectors in machine learning ?; In machine learning, feature vectors are used to represent numeric or symbolic characteristics, called features, of an object in a mathematical, easily analyzable way.\",\n",
    "    \"feature vectors and machine learning ?; In machine learning, feature vectors are used to represent numeric or symbolic characteristics, called features, of an object in a mathematical, easily analyzable way.\",\n",
    "    \"What is root cause analysis?; It is a problem-solving technique used for isolating the root causes of faults or problems. A factor is called a root cause if its deduction from the problem-fault-sequence averts the final undesirable event from reoccurring.\",\n",
    "    \"What can you tell me about root cause analysis; It is a problem-solving technique used for isolating the root causes of faults or problems. A factor is called a root cause if its deduction from the problem-fault-sequence averts the final undesirable event from reoccurring.\",\n",
    "    \"What is logistic regression?; Logistic Regression is also known as the logit model. It is a technique to forecast the binary outcome from a linear combination of predictor variables.\",\n",
    "    \"Logistic Regression?; Logistic Regression is also known as the logit model. It is a technique to forecast the binary outcome from a linear combination of predictor variables.\",\n",
    "    \"what do you know about Logistic Regression?; Logistic Regression is also known as the logit model. It is a technique to forecast the binary outcome from a linear combination of predictor variables.\",\n",
    "    \"Do you know Logistic Regression?; Logistic Regression is also known as the logit model. It is a technique to forecast the binary outcome from a linear combination of predictor variables.\",\n",
    "    \"What are Recommender Systems?; Recommender systems are a subclass of information filtering systems that are meant to predict the preferences or ratings that a user would give to a product.\",\n",
    "    \"Recommender Systems?;Recommender systems are a subclass of information filtering systems that are meant to predict the preferences or ratings that a user would give to a product.\",\n",
    "    \"Do you know what a Recommender Systems is?; Recommender systems are a subclass of information filtering systems that are meant to predict the preferences or ratings that a user would give to a product.\",\n",
    "    \"What do you know about Recommender Systems?;Recommender systems are a subclass of information filtering systems that are meant to predict the preferences or ratings that a user would give to a product.\",\n",
    "    \"Explain cross-validation.;It is a model validation technique for evaluating how the outcomes of a statistical analysis will generalize to an independent data set.\",\n",
    "    \"cross-validation?; It is mainly used in backgrounds where the objective is forecast and one wants to estimate how accurately a model will accomplish in practice.\",\n",
    "    \"goal of cross-validation?;The goal of cross-validation is to term a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting and gain insight on how the model will generalize to an independent data set.\",\n",
    "    \"what's the goal of cross-validation?;The goal of cross-validation is to term a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting and gain insight on how the model will generalize to an independent data set.\",\n",
    "    \"what is the goal of cross-validation?;The goal of cross-validation is to term a data set to test the model in the training phase (i.e. validation data set) in order to limit problems like overfitting and gain insight on how the model will generalize to an independent data set.\",\n",
    "    \"What is Collaborative Filtering?; The process of filtering used by most recommender systems to find patterns and information by collaborating perspectives, numerous data sources, and several agents.\",\n",
    "    \"Collaborative Filtering?; The process of filtering used by most recommender systems to find patterns and information by collaborating perspectives, numerous data sources, and several agents.\",\n",
    "    \"Do you know about Collaborative Filtering?; The process of filtering used by most recommender systems to find patterns and information by collaborating perspectives, numerous data sources, and several agents.\",\n",
    "    \"What do you know about Collaborative Filtering?; The process of filtering used by most recommender systems to find patterns and information by collaborating perspectives, numerous data sources, and several agents.\",\n",
    "    \"Do gradient descent methods at all times converge to a similar point?; No, they do not because in some cases they reach a local minima or a local optima point. You would not reach the global optima point. This is governed by the data and the starting conditions.\",\n",
    "    \"gradient descent methods at all times converge to a similar point?; No, they do not because in some cases they reach a local minima or a local optima point. You would not reach the global optima point. This is governed by the data and the starting conditions.\",\n",
    "    \"gradient descent methods converge to a similar point at all times?; No, they do not because in some cases they reach a local minima or a local optima point. You would not reach the global optima point. This is governed by the data and the starting conditions.\",\n",
    "    \"What is the goal of A/B Testing?; This is a statistical hypothesis testing for randomized experiments with two variables, A and B. The objective of A/B testing is to detect any changes to a web page to maximize or increase the outcome of a strategy.\",\n",
    "    \"A/B Testing?;This is a statistical hypothesis testing for randomized experiments with two variables, A and B.\",\n",
    "    \"What is A/B Testing?;This is a statistical hypothesis testing for randomized experiments with two variables, A and B.\",\n",
    "    \"The objective of A/B?;The objective of A/B testing is to detect any changes to a web page to maximize or increase the outcome of a strategy.\",\n",
    "    \"What are the drawbacks of the linear model?; Some drawbacks of the linear model are:The assumption of linearity of the errors.It can’t be used for count outcomes or binary outcomes.There are overfitting problems that it can’t solve\",\n",
    "    \"What is the Law of Large Numbers?;It is a theorem that describes the result of performing the same experiment a large number of times. This theorem forms the basis of frequency-style thinking. It says that the sample mean, the sample variance and the sample standard deviation converge to what they are trying to estimate.\",\n",
    "    \"Law of Large Numbers?;It is a theorem that describes the result of performing the same experiment a large number of times. This theorem forms the basis of frequency-style thinking. It says that the sample mean, the sample variance and the sample standard deviation converge to what they are trying to estimate.\",\n",
    "    \"Do you know about Law of Large Numbers?;It is a theorem that describes the result of performing the same experiment a large number of times. This theorem forms the basis of frequency-style thinking. It says that the sample mean, the sample variance and the sample standard deviation converge to what they are trying to estimate.\",\n",
    "    \"What do you know about the Law of Large Numbers?;It is a theorem that describes the result of performing the same experiment a large number of times. This theorem forms the basis of frequency-style thinking. It says that the sample mean, the sample variance and the sample standard deviation converge to what they are trying to estimate.\",\n",
    "    \"What are confounding variables?;These are extraneous variables in a statistical model that correlate directly or inversely with both the dependent and the independent variable. The estimate fails to account for the confounding factor.\",\n",
    "    \"confounding variables?;These are extraneous variables in a statistical model that correlate directly or inversely with both the dependent and the independent variable. The estimate fails to account for the confounding factor.\",\n",
    "    \"Do you know about confounding variables?;These are extraneous variables in a statistical model that correlate directly or inversely with both the dependent and the independent variable. The estimate fails to account for the confounding factor.\",\n",
    "    \"What do you know about confounding variables?;These are extraneous variables in a statistical model that correlate directly or inversely with both the dependent and the independent variable. The estimate fails to account for the confounding factor.\",\n",
    "    \"Explain star schema.;It is a traditional database schema with a central table. Satellite tables map IDs to physical names or descriptions and can be connected to the central fact table using the ID fields; these tables are known as lookup tables and are principally useful in real-time applications, as they save a lot of memory. Sometimes star schemas involve several layers of summarization to recover information faster.\",\n",
    "    \"What is star schema.;It is a traditional database schema with a central table. Satellite tables map IDs to physical names or descriptions and can be connected to the central fact table using the ID fields; these tables are known as lookup tables and are principally useful in real-time applications, as they save a lot of memory. Sometimes star schemas involve several layers of summarization to recover information faster.\",\n",
    "    \"What do you know about star schema.;It is a traditional database schema with a central table. Satellite tables map IDs to physical names or descriptions and can be connected to the central fact table using the ID fields; these tables are known as lookup tables and are principally useful in real-time applications, as they save a lot of memory. Sometimes star schemas involve several layers of summarization to recover information faster.\",\n",
    "    \"Do you know about star schema.;It is a traditional database schema with a central table. Satellite tables map IDs to physical names or descriptions and can be connected to the central fact table using the ID fields; these tables are known as lookup tables and are principally useful in real-time applications, as they save a lot of memory. Sometimes star schemas involve several layers of summarization to recover information faster.\",\n",
    "    \"How regularly must an algorithm be updated?; You will want to update an algorithm when:You want the model to evolve as data streams through infrastructure.The underlying data source is changing.There is a case of non-stationarity\",\n",
    "    \"When to update algorithm?; You will want to update an algorithm when:You want the model to evolve as data streams through infrastructure.The underlying data source is changing.There is a case of non-stationarity\",\n",
    "    \"What are Eigenvalue and Eigenvector?; Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"Difference between Eigenvalue and Eigenvector?; Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix. Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"Eigenvectors?; Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix.\",\n",
    "    \"what are Eigenvectors?; Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix.\",\n",
    "    \"Define Eigenvectors?; Eigenvectors are for understanding linear transformations. In data analysis, we usually calculate the eigenvectors for a correlation or covariance matrix.\",\n",
    "    \"Eigenvalues?; Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"Define Eigenvalues?; Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"What are Eigenvalues?; Eigenvalues are the directions along which a particular linear transformation acts by flipping, compressing or stretching.\",\n",
    "    \"Why is resampling done?; Resampling is done in any of these cases:Estimating the accuracy of sample statistics by using subsets of accessible data or drawing randomly with replacement from a set of data points \",\n",
    "    \"Why is resampling done?; Resampling is done in any of these cases:Substituting labels on data points when performing significance tests\",\n",
    "    \"Why is resampling done?; Resampling is done in any of these cases:Validating models by using random subsets (bootstrapping, cross validation)\",\n",
    "    \"Explain selective bias.;Selection bias, in general, is a problematic situation in which error is introduced due to a non-random population sample.\",\n",
    "    \"selective bias.;Selection bias, in general, is a problematic situation in which error is introduced due to a non-random population sample.\",\n",
    "    \"What are the types of biases that can occur during sampling?;Selection bias,Under coverage bias,Survivorship bias\",\n",
    "    \"Explain survivorship bias.; It is the logical error of focusing aspects that support surviving some process and casually overlooking those that did not because of their lack of prominence. This can lead to wrong conclusions in numerous different means.\",\n",
    "    \"Define survivorship bias.; It is the logical error of focusing aspects that support surviving some process and casually overlooking those that did not because of their lack of prominence. This can lead to wrong conclusions in numerous different means.\",\n",
    "    \"What is survivorship bias.; It is the logical error of focusing aspects that support surviving some process and casually overlooking those that did not because of their lack of prominence. This can lead to wrong conclusions in numerous different means.\",\n",
    "    \"random forest?; The underlying principle of this technique is that several weak learners combined to provide a strong learner.\",\n",
    "    \"What is Data Science?; Data Science is a blend of Statistics, technical skills and business vision which is used to analyze the available data and predict the future trend.\",\n",
    "    \"Difference between Big Data and Data Science?; Big Data is Huge volumes of data-structured, unstructured and semi-structured. Big Data requires a basic knowledge of statistics and mathematics. Whereas Data Science deals with slicing and dicing the data.Data Science requires in-depth knowledge of statistics and mathematics\",\n",
    "    \"Difference between Data Science and Data Analytics?; Data Science deals with slicing and dicing the data.Data Science requires in-depth knowledge of statistics and mathematics. Whereas Data anlytics refers to Contributing operational insights into complex business scenarios.Data Analytics Requires moderate amount of statistics and mathematics\",\n",
    "    \"Difference between Big Data and Data Analytics?; Big Data is Huge volumes of data-structured, unstructured and semi-structured. Big Data requires a basic knowledge of statistics and mathematics.Whereas Whereas Data anlytics refers to Contributing operational insights into complex business scenarios. Data Analytics Requires moderate amount of statistics and mathematics.\",\n",
    "    \"Which language is more suitable for text analytics? R or Python?; Since Python consists of a rich library called Pandas which allows the analysts to use high-level data analysis tools as well as data structures, while R lacks this feature. Hence Python will more suitable for text analytics.\",\n",
    "    \"more suitable language for text analytics is R or Python?; Since Python consists of a rich library called Pandas which allows the analysts to use high-level data analysis tools as well as data structures, while R lacks this feature. Hence Python will more suitable for text analytics.\",\n",
    "    \"What is a Recommender System?;A recommender system is today widely deployed in multiple fields like movie recommendations, music preferences, social tags, research articles, search queries and so on.\",\n",
    "    \"About Recommender System?;The recommender systems work as per collaborative and content-based filtering or by deploying a personality-based approach.\",\n",
    "    \"working of Recommender System?;This type of system works based on a person’s past behavior in order to build a model for the future. This will predict the future product buying, movie viewing or book reading by people. It also creates a filtering approach using the discrete characteristics of items while recommending additional items.\",\n",
    "    \"Do you know about SAS?;SAS: it is one of the most widely used analytics tools used by some of the biggest companies on earth. It has some of the best statistical functions, graphical user interface, but can come with a price tag and hence it cannot be readily adopted by smaller enterprises\",\n",
    "    \"What is SAS?;SAS is one of the most widely used analytics tools used by some of the biggest companies on earth. It has some of the best statistical functions, graphical user interface, but can come with a price tag and hence it cannot be readily adopted by smaller enterprises\",\n",
    "    \"What about R?; R- The best part about R is that it is an Open Source tool and hence used generously by academia and the research community. It is a robust tool for statistical computation, graphical representation and reporting. Due to its open source nature it is always being updated with the latest features and then readily available to everybody.\",\n",
    "    \"Tell me something about R?; R- The best part about R is that it is an Open Source tool and hence used generously by academia and the research community. It is a robust tool for statistical computation, graphical representation and reporting. Due to its open source nature it is always being updated with the latest features and then readily available to everybody.\",\n",
    "    \"What is R?; R- The best part about R is that it is an Open Source tool and hence used generously by academia and the research community. It is a robust tool for statistical computation, graphical representation and reporting. Due to its open source nature it is always being updated with the latest features and then readily available to everybody.\",\n",
    "    \"What is Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Do you know about Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Do you know Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Tell me something about Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"R and Python?;R and Python are two of the most important programming languages for Machine Learning Algorithms.\",\n",
    "    \"Explain the various benefits of R language?;The R programming language includes a set of software suite that is used for graphical representation, statistical computing, data manipulation and calculation.\",\n",
    "    \"About R language?;An extensive collection of tools for data analysis\",\n",
    "    \"More about R language?;Operators for performing calculations on matrix and array\",\n",
    "    \"R includes?; Data analysis technique for graphical representation\",\n",
    "    \"About R language?; A highly developed yet simple and effective programming language\",\n",
    "    \"R supports?; It extensively supports machine learning applications\",\n",
    "    \"R acts as?;  It acts as a connecting link between various software, tools and datasets\",\n",
    "    \"R creates?; Create high quality reproducible analysis that is flexible and powerful\",\n",
    "    \"R provides?; Provides a robust package ecosystem for diverse needs\",\n",
    "    \"When R is useful?  It is useful when you have to solve a data-oriented problem\",\n",
    "    \"What are the two main components of the Hadoop Framework?; HDFS and YARN are basically the two major components of Hadoop framework.\",\n",
    "    \"main components of the Hadoop Framework?; HDFS and YARN are basically the two major components of Hadoop framework.\",\n",
    "    \"HDFS?; Stands for Hadoop Distributed File System. It is the distributed database working on top of Hadoop. It is capable of storing and retrieving bulk of datasets in no time.\",\n",
    "    \"What is HDFS?; Stands for Hadoop Distributed File System. It is the distributed database working on top of Hadoop. It is capable of storing and retrieving bulk of datasets in no time.\",\n",
    "    \"Define HDFS?; Stands for Hadoop Distributed File System. It is the distributed database working on top of Hadoop. It is capable of storing and retrieving bulk of datasets in no time.\",\n",
    "    \"Do you know HDFS?; Stands for Hadoop Distributed File System. It is the distributed database working on top of Hadoop. It is capable of storing and retrieving bulk of datasets in no time.\",\n",
    "    \"YARN?; Stands for Yet Another Resource Negotiator. It allocates resources dynamically and handles the workloads.\",\n",
    "    \"Define YARN.; Stands for Yet Another Resource Negotiator. It allocates resources dynamically and handles the workloads.\",\n",
    "    \"What is YARN?; Stands for Yet Another Resource Negotiator. It allocates resources dynamically and handles the workloads.\",\n",
    "    \"Do you know YARN?; Stands for Yet Another Resource Negotiator. It allocates resources dynamically and handles the workloads.\",\n",
    "    \"How do Data Scientists use Statistics?;Statistics helps Data Scientists to look into the data for patterns, hidden insights and convert Big Data into Big insights. It helps to get a better idea of what the customers are expecting.\",\n",
    "    \"Data Scientists?;Data Scientists can learn about the consumer behavior, interest, engagement, retention and finally conversion all through the power of insightful statistics. It helps them to build powerful data models in order to validate certain inferences and predictions. All this can be converted into a powerful business proposition by giving users what they want at precisely when they want it.\",\n",
    "    \"What is logistic regression?;It is a statistical technique or a model in order to analyze a dataset and predict the binary outcome. The outcome has to be a binary outcome that is either zero or one or a yes or no.\",\n",
    "    \"Tell me about logistic regression?;It is a statistical technique or a model in order to analyze a dataset and predict the binary outcome. The outcome has to be a binary outcome that is either zero or one or a yes or no.\",\n",
    "    \"Do you know about logistic regression?;It is a statistical technique or a model in order to analyze a dataset and predict the binary outcome. The outcome has to be a binary outcome that is either zero or one or a yes or no.\",\n",
    "    \"Do you know logistic regression?;It is a statistical technique or a model in order to analyze a dataset and predict the binary outcome. The outcome has to be a binary outcome that is either zero or one or a yes or no.\",\n",
    "    \"Why data cleansing is important in data analysis?;  Data cleansing extensively deals with the process of detecting and correcting of data records, ensuring that data is complete and accurate and the components of data that are irrelevant are deleted or modified as per the needs\",\n",
    "    \"Data cleansing?; Data cleansing is an essential part of the data science because the data can be prone to error due to human negligence, corruption during transmission or storage among other things.\",\n",
    "    \"Importance of Data cleansing?; Data cleansing takes a huge chunk of time and effort of a Data Scientist because of the multiple sources from which data emanates and the speed at which it comes.\",\n",
    "    \"univariate?; univariate analysis will have one variable and due to this there are no relationships, causes. The major aspect of the univariate analysis is to summarize the data and find the patterns within it to make actionable decisions.\",\n",
    "    \"univariate analysis?; univariate analysis will have one variable and due to this there are no relationships, causes. The major aspect of the univariate analysis is to summarize the data and find the patterns within it to make actionable decisions.\",\n",
    "    \"What is univariate analysis?; univariate analysis will have one variable and due to this there are no relationships, causes. The major aspect of the univariate analysis is to summarize the data and find the patterns within it to make actionable decisions.\",\n",
    "    \"Define univariate analysis?; univariate analysis will have one variable and due to this there are no relationships, causes. The major aspect of the univariate analysis is to summarize the data and find the patterns within it to make actionable decisions.\",\n",
    "    \"Tell me about univariate analysis?; univariate analysis will have one variable and due to this there are no relationships, causes. The major aspect of the univariate analysis is to summarize the data and find the patterns within it to make actionable decisions.\",\n",
    "    \"bivariate?; A Bivariate analysis deals with the relationship between two sets of data. These sets of paired data come from related sources, or samples. There are various tools to analyze such data including the chi-squared tests and t-tests when the data are having a correlation\",\n",
    "    \"Bivariate analysis?; If the data can be quantified then it can analyzed using a graph plot or a scatterplot. The strength of the correlation between the two data sets will be tested in a Bivariate analysis.\",\n",
    "    \"How machine learning is deployed in real world scenarios?; Ecommerce: Understanding the customer churn, deploying targeted advertising, remarketing\",\n",
    "    \"machine learning finds applications in real world?; Search engine: Ranking pages depending on the personal preferences of the searcher\",\n",
    "    \"machine learning applications?; Finance: Evaluating investment opportunities & risks, detecting fraudulent transactions\",\n",
    "    \"application of machine learning ?;Medicare: Designing drugs depending on the patient’s history and needs\",\n",
    "    \"machine learning in real life?; Robotics: Machine learning for handling situations that are out of the ordinary\",\n",
    "    \"application of machine learning?;Social media: Understanding relationships and recommending connections\",\n",
    "    \"machine learning applications?; Extraction of information: framing questions for getting answers from databases over the web\",\n",
    "    \"What are the various aspects of a Machine Learning process?; Domain knowledge, Feature Selection, Algorithm, Training, Evaluation, Optimization,Testing\",\n",
    "    \"What do you understand by the term Normal Distribution?; It is a set of continuous variable spread across a normal curve or in the shape of a bell curve. It can be considered as a continuous probability distribution and is useful in statistics.\",\n",
    "    \"Normal Distribution is what?;It is the most common distribution curve and it becomes very useful to analyze the variables and their relationships when we have the normal distribution curve.\",\n",
    "    \"What is Normal Distribution ?;It is the most common distribution curve and it becomes very useful to analyze the variables and their relationships when we have the normal distribution curve.\",\n",
    "    \"Shape of normal distribution curve?; The normal distribution curve is symmetrical.\",\n",
    "    \"How is the Shape of normal distribution curve?; The normal distribution curve is symmetrical.\",\n",
    "    \"The shape of normal distribution curve?; The normal distribution curve is symmetrical.\",\n",
    "    \"What is the shape of normal distribution curve?; The normal distribution curve is symmetrical.\",\n",
    "    \"What is Linear Regression?; It is the most commonly used method for predictive analytics.\",\n",
    "    \"use of Linear Regression?;The Linear Regression method is used to describe relationship between a dependent variable and one or independent variable.\",\n",
    "    \"The main task in the Linear Regression?;The main task in the Linear Regression is the method of fitting a single line within a scatter plot.\",\n",
    "    \"what is the main task in the Linear Regression?;The main task in the Linear Regression is the method of fitting a single line within a scatter plot.\",\n",
    "    \"Linear Regression?;The main task in the Linear Regression is the method of fitting a single line within a scatter plot.\",\n",
    "    \"Methods of Linear Regression?;Determining and analyzing the correlation and direction of the data.Deploying the estimation of the model.Ensuring the usefulness and validity of the model\",\n",
    "    \"What is Interpolation and Extrapolation?;The terms of interpolation and extrapolation are extremely important in any statistical analysis.\",\n",
    "    \"Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"What is Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"Define Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"Do you know Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"Do you know about Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"What Do you know Extrapolation?; Extrapolation is the determination or estimation using a known set of values or facts by extending it and taking it to an area or region that is unknown. It is the technique of inferring something using data that is available.\",\n",
    "    \"Interpolation?; Interpolation on the other hand is the method of determining a certain value which falls between a certain set of values or the sequence of values. This is especially useful when you have data at the two extremities of a certain region but you don’t have enough data points at the specific point.\",\n",
    "    \"What is Interpolation?; Interpolation on the other hand is the method of determining a certain value which falls between a certain set of values or the sequence of values. This is especially useful when you have data at the two extremities of a certain region but you don’t have enough data points at the specific point.\",\n",
    "    \"Define Interpolation?; Interpolation on the other hand is the method of determining a certain value which falls between a certain set of values or the sequence of values. This is especially useful when you have data at the two extremities of a certain region but you don’t have enough data points at the specific point.\",\n",
    "    \"Do you know Interpolation?; Interpolation on the other hand is the method of determining a certain value which falls between a certain set of values or the sequence of values. This is especially useful when you have data at the two extremities of a certain region but you don’t have enough data points at the specific point.\",\n",
    "    \"What is Power Analysis?; The power analysis is a vital part of the experimental design. It is involved with the process of determining the sample size needed for detecting an effect of a given size from a cause with a certain degree of assurance. It lets you deploy specific probability in a sample size constraint.\",\n",
    "    \"Power analysis?; Power analysis lets you understand the sample size estimate so that they are neither high nor low. A low sample size there will be no authentication to provide reliable answers and if it is large there will be wastage of resources.\",\n",
    "    \"Define Power Analysis?; The power analysis is a vital part of the experimental design. It is involved with the process of determining the sample size needed for detecting an effect of a given size from a cause with a certain degree of assurance. It lets you deploy specific probability in a sample size constraint.\",\n",
    "    \"What is K-means?; K-means clustering can be termed as the basic unsupervised learning algorithm. It is the method of classifying data using a certain set of clusters called as K clusters. It is deployed for grouping data in order to find similarity in the data.\",\n",
    "    \"How is Data modeling different from Database design?;Data Modeling: It can be considered as the first step towards the design of a database. Data modeling creates a conceptual model based on the relationship between various data models.Database Design:database design includes the detailed logical model of a database but it can also include physical design choices and storage parameters.\",\n",
    "    \"Difference between Data modeling and Database design?;Data Modeling: It can be considered as the first step towards the design of a database. Data modeling creates a conceptual model based on the relationship between various data models.Database Design:database design includes the detailed logical model of a database but it can also include physical design choices and storage parameters.\",\n",
    "    \"what's the Difference between Data modeling and Database design?;Data Modeling: It can be considered as the first step towards the design of a database. Data modeling creates a conceptual model based on the relationship between various data models.Database Design:database design includes the detailed logical model of a database but it can also include physical design choices and storage parameters.\",\n",
    "    \"What is R2?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"What is R^2?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"What is R square?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"What is R-square?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"Define R2?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"Define R^2?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"Define R square?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"Define R-square?;goodness of fit measure. variance explained by the regression / total variance\",\n",
    "    \"other metrics that could be better than R2?; the more predictors you add the higher R^2 becomes.Hence use adjusted R^2 which adjusts for the degrees of freedom \",\n",
    "    \"better than R2?; the more predictors you add the higher R^2 becomes.Hence use adjusted R^2 which adjusts for the degrees of freedom \",\n",
    "    \"What is the curse of dimensionality?; High dimensionality makes clustering hard, because having lots of dimensions means that everything is 'far away' from each other.\",\n",
    "    \"Is more data always better?; Statistically,It depends on the quality of your data, for example, if your data is biased, just getting more data won’t help.It depends on your model. If your model suffers from high bias, getting more data won’t improve your test results beyond a point. You’d need to add more features, etc.\",\n",
    "    \"Is more data always better?;Practically,Also there’s a tradeoff between having more data and the additional storage, computational power, memory it requires. Hence, always think about the cost of having more data.\",\n",
    "    \"How can you make sure that you don’t analyze something that ends up meaningless?; Proper exploratory data analysis.The exploratory phase will generate lots of possible hypotheses, and the exploitatory phase will let you really understand a few of them. Balance the two and you'll prevent yourself from wasting time on many things that end up meaningless, although not all.\",\n",
    "    \"What is the role of trial and error in data analysis?; data analysis is a repetition of setting up a new hypothesis and trying to refute the null hypothesis.\",\n",
    "    \"What is the the role of making a hypothesis before diving in?;The scientific method is eminently inductive: we elaborate a hypothesis, test it and refute it or not. As a result, we come up with new hypotheses which are in turn tested and so on. This is an iterative process, as science always is.\",\n",
    "    \"How can you determine which features are the most important in your model?; Run the features though a Gradient Boosting Machine or Random Forest to generate plots of relative importance and information gain for each feature in the ensembles.Look at the variables added in forward variable selection.\",\n",
    "    \"How do you deal with some of your predictors being missing?;Remove rows with missing values - This works well if 1) the values are missing randomly,2) if you don't lose too much of the dataset after doing so.\",\n",
    "    \"How to deal with missing values?;Remove rows with missing values - This works well if 1) the values are missing randomly,2) if you don't lose too much of the dataset after doing so.\",\n",
    "    \"Dealing missing values?;Remove rows with missing values - This works well if 1) the values are missing randomly,2) if you don't lose too much of the dataset after doing so.\",\n",
    "    \"Tackle missing values?;Use a model that can incorporate missing data - Like a random forest, or any tree-based method.\",\n",
    "    \"Accuracy?; Accuracy is a metric by which one can examine how good is the machine learning model.So, the accuracy is the ratio of correctly predicted classes to the total classes predicted.\",\n",
    "    \"Define Accuracy?; Accuracy is a metric by which one can examine how good is the machine learning model.So, the accuracy is the ratio of correctly predicted classes to the total classes predicted.\",\n",
    "    \"What is Accuracy?; Accuracy is a metric by which one can examine how good is the machine learning model.So, the accuracy is the ratio of correctly predicted classes to the total classes predicted.\",\n",
    "    \"What Accuracy is?; Accuracy is a metric by which one can examine how good is the machine learning model.So, the accuracy is the ratio of correctly predicted classes to the total classes predicted.\",\n",
    "    \"Adam Optimization?; The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\",\n",
    "    \"Adam ?; The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\",\n",
    "    \"What is Adam Optimization?; The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\",\n",
    "    \"Do you know Adam Optimization?; The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\",\n",
    "    \"Adam Optimization?; The Adam Optimization algorithm is used in training deep learning models. It is an extension to Stochastic Gradient Descent. In this optimization algorithm, running averages of both the gradients and the second moments of the gradients are used. It is used to compute adaptive learning rates for each parameter.\",\n",
    "    \"Adam Optimization features?;It is computationally efficient and has little memory requirements.It is invariant to diagonal rescaling of the gradients.Adam works well in practice as compared to other stochastic optimization methods\",\n",
    "    \"features of Adam Optimization ?;It is computationally efficient and has little memory requirements.It is invariant to diagonal rescaling of the gradients.Adam works well in practice as compared to other stochastic optimization methods\",\n",
    "    \"Apache Spark?; Apache Spark is an open-source cluster computing framework. Spark can be deployed in a variety of ways, provides native bindings for the Java, Scala, Python, and R programming languages, and supports SQL, streaming data, and machine learning.\",\n",
    "    \"What is Apache Spark?; Apache Spark is an open-source cluster computing framework. Spark can be deployed in a variety of ways, provides native bindings for the Java, Scala, Python, and R programming languages, and supports SQL, streaming data, and machine learning.\",\n",
    "    \"Do you know Apache Spark?; Apache Spark is an open-source cluster computing framework. Spark can be deployed in a variety of ways, provides native bindings for the Java, Scala, Python, and R programming languages, and supports SQL, streaming data, and machine learning.\",\n",
    "    \"Apache Spark features?;Speed − Spark helps to run an application in Hadoop cluster, up to 100 times faster in memory, and 10 times faster when running on disk.Spark supports popular data science programming languages such as R, Python, and Scala.Spark also has a library called MLlIB which includes basic machine learning including classification, regression, and clustering.\",\n",
    "    \"features of Apache Spark?;Speed − Spark helps to run an application in Hadoop cluster, up to 100 times faster in memory, and 10 times faster when running on disk.Spark supports popular data science programming languages such as R, Python, and Scala.Spark also has a library called MLlIB which includes basic machine learning including classification, regression, and clustering.\",\n",
    "    \"Autoregression?; Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. The autoregressive model specifies that the output variable depends linearly on its own previous values. In this technique input variables are taken as observations at previous time steps, called lag variables.\",\n",
    "    \"What is Autoregression?; Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. The autoregressive model specifies that the output variable depends linearly on its own previous values. In this technique input variables are taken as observations at previous time steps, called lag variables.\",\n",
    "    \"Define Autoregression?; Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. The autoregressive model specifies that the output variable depends linearly on its own previous values. In this technique input variables are taken as observations at previous time steps, called lag variables.\",\n",
    "    \"Do you know about Autoregression?; Autoregression is a time series model that uses observations from previous time steps as input to a regression equation to predict the value at the next time step. The autoregressive model specifies that the output variable depends linearly on its own previous values. In this technique input variables are taken as observations at previous time steps, called lag variables.\",\n",
    "    \"Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"Backward propogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"what is Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"What is Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"Define Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"Do you know Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"Do you know about Backpropogation?; In neural networks, if the estimated output is far away from the actual output (high error), we update the biases and weights based on the error. This weight and bias updating process is known as Back Propagation.\",\n",
    "    \"Working of Backpropogation?; Back-propagation (BP) algorithms work by determining the loss (or error) at the output and then propagating it back into the network. The weights are updated to minimize the error resulting from each neuron. The first step in minimizing the error is to determine the gradient (Derivatives) of each node w.r.t. the final output.\",\n",
    "    \"Working of Backward propogation?; Back-propagation (BP) algorithms work by determining the loss (or error) at the output and then propagating it back into the network. The weights are updated to minimize the error resulting from each neuron. The first step in minimizing the error is to determine the gradient (Derivatives) of each node w.r.t. the final output.\",\n",
    "    \"Bagging?; Bagging or bootstrap averaging is a technique where multiple models are created on the subset of data, and the final predictions are determined by combining the predictions of all the models.\",\n",
    "    \"What is Bagging?; Bagging or bootstrap averaging is a technique where multiple models are created on the subset of data, and the final predictions are determined by combining the predictions of all the models.\",\n",
    "    \"Define Bagging?; Bagging or bootstrap averaging is a technique where multiple models are created on the subset of data, and the final predictions are determined by combining the predictions of all the models.\",\n",
    "    \"Bar Chart?; Bar charts are a type of graph that are used to display and compare the numbers, frequency or other measures (e.g. mean) for different discrete categories of data. They are used for categorical variables.\",\n",
    "    \"What is Bar Chart?; Bar charts are a type of graph that are used to display and compare the numbers, frequency or other measures (e.g. mean) for different discrete categories of data. They are used for categorical variables.\",\n",
    "    \"Define Bar Chart?; Bar charts are a type of graph that are used to display and compare the numbers, frequency or other measures (e.g. mean) for different discrete categories of data. They are used for categorical variables.\",\n",
    "    \"Can you help me with Bar Chart?; Bar charts are a type of graph that are used to display and compare the numbers, frequency or other measures (e.g. mean) for different discrete categories of data. They are used for categorical variables.\",\n",
    "    \"Bayes Theorem?; Bayes’ theorem is used to calculate the conditional probability. Conditional probability is the probability of an event ‘B’ occurring given the related event ‘A’ has already occurred.\",\n",
    "    \"What is Bayes Theorem?; Bayes’ theorem is used to calculate the conditional probability. Conditional probability is the probability of an event ‘B’ occurring given the related event ‘A’ has already occurred.\",\n",
    "    \"Define Bayes Theorem?; Bayes’ theorem is used to calculate the conditional probability. Conditional probability is the probability of an event ‘B’ occurring given the related event ‘A’ has already occurred.\",\n",
    "    \"Bayesian Statistics?; Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence.\",\n",
    "    \"What is Bayesian Statistics?; Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence.\",\n",
    "    \"Define Bayesian Statistics?; Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence.\",\n",
    "    \"Do you know about Bayesian Statistics?; Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence.\",\n",
    "    \"Do you know Bayesian Statistics?; Bayesian statistics is a mathematical procedure that applies probabilities to statistical problems. It provides people the tools to update their beliefs in the evidence of new data. It differs from classical frequentist approach and is based on the use of Bayesian probabilities to summarize evidence.\",\n",
    "    \"Bias-Variance Trade-off?; Bias error is useful to quantify how much on an average are the predicted values different from the actual value. Variance on the other side quantifies how are the prediction made on same observation different from each other\",\n",
    "    \"Bias-Variance Trade-off?; A high bias error means we have a under-performing model which keeps on missing important trends. A high variance model will over-fit on your training population and perform badly on any observation beyond training. In order to have a perfect fit in the model, the bias and variance should be balanced which is bias variance trade off.\",\n",
    "    \"high bias?; A high bias error means we have a under-performing model which keeps on missing important trends.\",\n",
    "    \"high bias error?; A high bias error means we have a under-performing model which keeps on missing important trends. \",\n",
    "    \"high variance?; A high variance model will over-fit on your training population and perform badly on any observation beyond training.\",\n",
    "    \"Big Data?; Big data is a term that describes the large volume of data – both structured and unstructured. But it’s not the amount of data that’s important. It’s how organizations use this large amount of data to generate insights. Companies use various tools, techniques and resources to make sense of this data to derive effective business strategies.\",\n",
    "    \"What is Big Data?; Big data is a term that describes the large volume of data – both structured and unstructured. But it’s not the amount of data that’s important. It’s how organizations use this large amount of data to generate insights. Companies use various tools, techniques and resources to make sense of this data to derive effective business strategies.\",\n",
    "    \"Define Big Data?; Big data is a term that describes the large volume of data – both structured and unstructured. But it’s not the amount of data that’s important. It’s how organizations use this large amount of data to generate insights. Companies use various tools, techniques and resources to make sense of this data to derive effective business strategies.\",\n",
    "    \"Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"what is Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"Define Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"Do you know Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"Can you tell me about Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"tell me something about Binary Variable?; Binary variables are those variables which can have only two unique values. For example, a variable “Smoking Habit” can contain only two values like 'Yes' and 'No'.\",\n",
    "    \"Binomial Distribution?; Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\", \n",
    "    \"What is Binomial Distribution?; Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\", \n",
    "    \"Define Binomial Distribution?; Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\", \n",
    "    \"Can you tell me about Binomial Distribution?; Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\", \n",
    "    \"tell me something about Binomial Distribution?; Binomial Distribution is applied only on discrete random variables. It is a method of calculating probabilities for experiments having fixed number of trials.\", \n",
    "    \"properties of Binomial distribution?; Binomial distribution has following properties:The experiment should have finite number of trials,There should be two outcomes in a trial: success and failure,Trials are independent,Probability of success (p) remains constant.\",\n",
    "    \"Boosting?; Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:AdaBoost,GBM,XGBM,LightGBM,CatBoost.\",\n",
    "    \"What is Boosting?; Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:AdaBoost,GBM,XGBM,LightGBM,CatBoost.\",\n",
    "    \"Define Boosting?; Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:AdaBoost,GBM,XGBM,LightGBM,CatBoost.\",\n",
    "    \"tell me something about Boosting?; Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:AdaBoost,GBM,XGBM,LightGBM,CatBoost.\",\n",
    "    \"Can you tell me about Boosting?; Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Some of the boosting algorithms are:AdaBoost,GBM,XGBM,LightGBM,CatBoost.\",\n",
    "    \"Bootstrapping?; Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.\",\n",
    "    \"What is Bootstrapping?; Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.\",\n",
    "    \"Define Bootstrapping?; Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.\",\n",
    "    \"Can you tell me about Bootstrapping?; Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.\",\n",
    "    \"tell me something about Bootstrapping?; Bootstrapping is the process of dividing the dataset into multiple subsets, with replacement. Each subset is of the same size of the dataset. These samples are called bootstrap samples.\",\n",
    "    \"Box Plot?; It displays the full range of variation (from min to max), the likely range of variation (the Interquartile range), and a typical value (the median).\",\n",
    "    \"What is Box Plot?; It displays the full range of variation (from min to max), the likely range of variation (the Interquartile range), and a typical value (the median).\",\n",
    "    \"Define Box Plot?; It displays the full range of variation (from min to max), the likely range of variation (the Interquartile range), and a typical value (the median).\",\n",
    "    \"Business Analytics?; Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.\",\n",
    "    \"What is Business Analytics?; Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.\",\n",
    "    \"Define Business Analytics?; Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.\",\n",
    "    \"tell me something about Business Analytics?; Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.\",\n",
    "    \"Can you tell me about Business Analytics?; Business analytics is mainly used to show the practical methodology followed by an organization for exploring data to gain insights. The methodology focusses on statistical analysis of the data.\",\n",
    "    \"Business Intelligence?; Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.\",\n",
    "    \"What is Business Intelligence?; Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.\",\n",
    "    \"Define Business Intelligence?; Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.\",\n",
    "    \"tell me something about Business Intelligence?; Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.\",\n",
    "    \"Can you tell me about Business Intelligence?; Business intelligence are a set of strategies, applications, data, technologies used by an organization for data collection, analysis and generating insights to derive strategic business opportunities.\",\n",
    "    \"Categorical Variable?;  Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.\",\n",
    "    \"What is Categorical Variable?;  Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.\",\n",
    "    \"Define Categorical Variable?;  Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.\",\n",
    "    \"tell me something about Categorical Variable?;  Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.\",\n",
    "    \"Can you tell me about Categorical Variable?;  Categorical variables (or nominal variables) are those variables which have discrete qualitative values. For example, names of cities are categorical like Delhi, Mumbai, Kolkata. Read in detail  here.\",\n",
    "    \"Classification?; It is supervised learning method where the output variable is a category, such as “Male” or “Female” or “Yes” and “No”.For example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.\",\n",
    "    \"What is Classification?; It is supervised learning method where the output variable is a category, such as “Male” or “Female” or “Yes” and “No”.For example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.\",\n",
    "    \"Define Classification?; It is supervised learning method where the output variable is a category, such as “Male” or “Female” or “Yes” and “No”.For example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.\",\n",
    "    \"tell me something about Classification?; It is supervised learning method where the output variable is a category, such as “Male” or “Female” or “Yes” and “No”.For example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.\",\n",
    "    \"Can you tell me abou Classification?; It is supervised learning method where the output variable is a category, such as “Male” or “Female” or “Yes” and “No”.For example: Classification Algorithms like Logistic Regression, Decision Tree, K-NN, SVM etc.\",\n",
    "    \"Classification Threshold?; Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise.\",\n",
    "    \"What is Classification Threshold?; Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise.\",\n",
    "    \"Define Classification Threshold?; Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise.\",\n",
    "    \"tell me something about Classification Threshold?; Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise.\",   \n",
    "    \"Can you tell me about Classification Threshold?; Classification threshold is the value which is used to classify a new observation as 1 or 0. When we get an output as probabilities and have to classify them into classes, we decide some threshold value and if the probability is above that threshold value we classify it as 1, and 0 otherwise.\",\n",
    "    \"Clustering?; Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\",\n",
    "    \"What is Clustering?; Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\",\n",
    "    \"Define Clustering?; Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\",\n",
    "    \"tell me something about Clustering?; Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\",\n",
    "    \"Can you tell me about Clustering?; Clustering is an unsupervised learning method used to discover the inherent groupings in the data.  For example: Grouping customers on the basis of their purchasing behaviour which is further used to segment the customers. And then the companies can use the appropriate marketing tactics to generate more profits.\",\n",
    "    \"Example of clustering algorithms?; Example of clustering algorithms: K-Means, hierarchical clustering, etc.\",\n",
    "    \"Computer Vision?; Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does.\",\n",
    "    \"What is Computer Vision?; Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does.\",\n",
    "    \"Define Computer Vision?; Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does.\",\n",
    "    \"Can you tell me about Computer Vision?; Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does.\",\n",
    "    \"tell me something about Computer Vision?; Computer Vision is a field of computer science that deals with enabling computers to visualize, process and identify images/videos in the same way that a human vision does.\",\n",
    "    \"applications of Computer Vision?; applications of Computer Vision are:Pedestrians, cars, road detection in smart (self-driving) cars,Object recognition,Object tracking,Motion analysis,Image restoration\",\n",
    "    \"Confidence Interval?; A confidence interval is used to estimate what percent of a population fits a category based on the results from a sample population\",\n",
    "    \"Confusion Matrix?; A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives\",\n",
    "    \"What is Confusion Matrix?; A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives\",\n",
    "    \"Define Confusion Matrix?; A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives\",\n",
    "    \"Can you tell me about Confusion Matrix?; A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives\",    \n",
    "    \"tell me something about Confusion Matrix?; A confusion matrix is a table that is often used to describe the performance of a classification model. It is a N * N matrix, where N is the number of classes. We form confusion matrix between prediction of model classes Vs actual classes. The 2nd quadrant is called type II error or False Negatives, whereas 3rd quadrant is called type I error or False positives\",\n",
    "    \"Continuous Variable?;Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable. \",\n",
    "    \"What is Continuous Variable?;Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable. \",\n",
    "    \"Define Continuous Variable?;Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable. \",\n",
    "    \"Can you tell me about Continuous Variable?;Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable. \",\n",
    "    \"tell me something about Continuous Variable?;Continuous variables are those variables which can have infinite number of values but only in a specific range. For example, height is a continuous variable.\",\n",
    "    \"Convergence?;Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.\",\n",
    "    \"What is Convergence?;Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.\",\n",
    "    \"Define Convergence?;Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.\",\n",
    "    \"Can you tell me about Convergence?;Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.\",    \n",
    "    \"tell me something about Convergence?;Convergence refers to moving towards union or uniformity. An iterative algorithm is said to converge when as the iterations proceed the output gets closer and closer to a specific value.\",\n",
    "    \"Convex Function?; A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\",\n",
    "    \"What is Convex Function?; A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\",\n",
    "    \"Define Convex Function?; A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\",\n",
    "    \"Can you tell me about Convex Function?; A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\",\n",
    "    \"tell me something about Convex Function?; A real value function is called convex if the line segment between any two points on the graph of the function lies above or on the graph.\",\n",
    "    \"Correlation?; Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence.\",\n",
    "    \"What is Correlation?; Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence.\",\n",
    "    \"Define Correlation?; Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence.\",\n",
    "    \"Can you tell me about Correlation?; Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence.\",\n",
    "    \"tell me something about Correlation?; Correlation is the ratio of covariance of two variables to a product of variance (of the variables). It takes a value between +1 and -1. An extreme value on both the side means they are strongly correlated with each other. A value of zero indicates a NIL correlation but not a non-dependence.\",\n",
    "    \"Cost Function?; Cost function is used to define and measure the error of the model.\",\n",
    "    \"Define Cost Function?; Cost function is used to define and measure the error of the model.\",\n",
    "    \"Can you tell me about Cost Function?; Cost function is used to define and measure the error of the model.\",\n",
    "    \"What is Cost Function?; Cost function is used to define and measure the error of the model.\",\n",
    "    \"tell me something about Cost Function?; Cost function is used to define and measure the error of the model.\",\n",
    "    \"Covariance?; Covariance is a measure of the joint variability of two random variables. It’s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\",\n",
    "    \"What is Covariance?; Covariance is a measure of the joint variability of two random variables. It’s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\",\n",
    "    \"Define Covariance?; Covariance is a measure of the joint variability of two random variables. It’s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\",\n",
    "    \"Can you tell me about Covariance?; Covariance is a measure of the joint variability of two random variables. It’s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\",\n",
    "    \"tell me something about Covariance?; Covariance is a measure of the joint variability of two random variables. It’s similar to variance, but where variance tells you how a single variable varies, co variance tells you how two variables vary together.\",\n",
    "    \"Cross Entropy?; In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an 'unnatural' probability distribution , rather than the 'true'.\",\n",
    "    \"What is Cross Entropy?; In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an 'unnatural' probability distribution , rather than the 'true'.\",\n",
    "    \"Define Cross Entropy?; In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an 'unnatural' probability distribution , rather than the 'true'.\",\n",
    "    \"Can you tell me about Cross Entropy?; In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an 'unnatural' probability distribution , rather than the 'true'.\",\n",
    "    \"tell me something about Cross Entropy?; In information theory, the cross entropy between two probability distributions and over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set, if a coding scheme is used that is optimized for an 'unnatural' probability distribution , rather than the 'true'.\",\n",
    "    \"Cross Validation?; Cross Validation is a technique which involves reserving a particular sample of a dataset which is not used to train the model.\",\n",
    "    \"What is Cross Validation?; Cross Validation is a technique which involves reserving a particular sample of a dataset which is not used to train the model.\",\n",
    "    \"Define Cross Validation?; Cross Validation is a techniq ue which involves reserving a particular sample of a dataset which is not used to train the model.\",   \n",
    "    \"tell me something about Cross Validation?;Cross Validation is a technique which involves reserving a particular sample of a dataset which is not used to train the model.\",\n",
    "    \"Can you tell me about Cross Validation?; Cross Validation is a technique which involves reserving a particular sample of a dataset which is not used to train the model.\",\n",
    "    \"Data Mining?;Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. Data mining is a study of extracting useful information from structured/unstructured data taken from various sources.\",\n",
    "    \"What is Data Mining?;Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. Data mining is a study of extracting useful information from structured/unstructured data taken from various sources.\",\n",
    "    \"Define Data Mining?;Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. Data mining is a study of extracting useful information from structured/unstructured data taken from various sources.\",\n",
    "    \"Can you tell me about Data Mining?;Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. Data mining is a study of extracting useful information from structured/unstructured data taken from various sources.\",\n",
    "    \"tell me something about Data Mining?;Data mining is a study of extracting useful information from structured/unstructured data taken from various sources. Data mining is a study of extracting useful information from structured/unstructured data taken from various sources.\",\n",
    "    \"Data Science?; Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.\",\n",
    "    \"What is Data Science?; Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.\",\n",
    "    \"Define Data Science?; Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.\",\n",
    "    \"Can you tell me about Data Science?; Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.\",\n",
    "    \"tell me something about Data Science?; Data science is a combination of data analysis, algorithmic development and technology in order to solve analytical problems. The main goal is a use of data to generate business value.\",\n",
    "    \"Data Transformation?; Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\",\n",
    "    \"What is Data Transformation?; Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\",\n",
    "    \"Define Data Transformation?; Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\",\n",
    "    \"Can you tell me about Data Transformation?; Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\",\n",
    "    \"tell me something about Data Transformation?; Data transformation is the process to convert data from one form to the other. This is usually done at a preprocessing step.\",\n",
    "    \"Database?; Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.\",\n",
    "    \"What is Database?; Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.\",\n",
    "    \"Define Database?; Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.\",\n",
    "    \"Can you tell me about Database?; Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.\",\n",
    "    \"tell me something about Database?; Database (abbreviated as DB) is an structured collection of data. The collected information is organised in a way such that it is easily accessible by the computer. Databases are built and managed by using database programming languages. The most common database language is SQL.\",\n",
    "    \"DataFrame?; DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\",\n",
    "    \"What is DataFrame?; DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\",\n",
    "    \"Define DataFrame?; DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\",\n",
    "    \"Can you tell me about DataFrame?; DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\",\n",
    "    \"tell me something about DataFrame?; DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects.\",\n",
    "    \"Dataset?; A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). \",\n",
    "    \"What is Dataset?; A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). \",\n",
    "    \"Define Dataset?; A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). \",\n",
    "    \"Can you tell me about Dataset?; A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). \",\n",
    "    \"tell me something about Dataset?; A dataset (or data set) is a collection of data. A dataset is organized into some type of data structure. In a database, for example, a dataset might contain a collection of business data (names, salaries, contact information, sales figures, and so forth). \",\n",
    "    \"Dashboard?; Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges.\",\n",
    "    \"What is Dashboard?; Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges.\",\n",
    "    \"Define Dashboard?; Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges.\",\n",
    "    \"Can you tell me about Dashboard?; Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges.\",\n",
    "    \"tell me something about Dashboard?; Dashboard is an information management tool which is used to visually track, analyze and display key performance indicators, metrics and key data points. Dashboards can be customised to fulfil the requirements of a project. It can be used to connect files, attachments, services and APIs which is displayed in the form of tables, line charts, bar charts and gauges.\",\n",
    "    \"DBScan?;DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\",\n",
    "    \"What is DBScan?;DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\",\n",
    "    \"Define DBScan?;DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\",\n",
    "    \"Can you tell me about DBScan?;DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\",\n",
    "    \"tell me something about DBScan?;DBSCAN is the acronym for Density-Based Spatial Clustering of Applications with Noise. It is a clustering algorithm that isolates different density regions by forming clusters. For a given set of points, it groups the points which are closely packed.\",\n",
    "    \"Features of DBScan?;distance,the minimum number of points required to form a dense region\",\n",
    "    \"Decision Boundary?;In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class.\",\n",
    "    \"What is Decision Boundary?;In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class.\",\n",
    "    \"Define Decision Boundary?;In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class.\",\n",
    "    \"Can you tell me about Decision Boundary?;In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class.\",\n",
    "    \"tell me something about Decision Boundary?;In a statistical-classification problem with two or more classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two or more sets, one for each class.\",\n",
    "    \"Decision Tree?;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\",\n",
    "    \"What is Decision Tree?;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\",\n",
    "    \"Define Decision Tree?;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\",\n",
    "    \"Can you tell me about Decision Tree?;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\",\n",
    "    \"tell me something about Decision Tree?;Decision tree is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input & output variables. In this technique, we split the population (or sample) into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\",\n",
    "    \"Deep Learning?;Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously.\",\n",
    "    \"What is Deep Learning?;Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously.\",\n",
    "    \"Define Deep Learning?;Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously.\",\n",
    "    \"Can you tell me about Deep Learning?;Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously.\",\n",
    "    \"tell me something about Deep Learning?;Deep Learning is associated with a machine learning algorithm (Artificial Neural Network, ANN) which uses the concept of human brain to facilitate the modeling of arbitrary functions. ANN requires a vast amount of data and this algorithm is highly flexible when it comes to model multiple outputs simultaneously.\",\n",
    "    \"Descriptive Statistics?;Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.\",\n",
    "    \"What is Descriptive Statistics?;Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.\",\n",
    "    \"Define Descriptive Statistics?;Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.\",\n",
    "    \"Can you tell me about Descriptive Statistics?;Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.\",\n",
    "    \"tell me something about Descriptive Statistics?;Descriptive statistics is comprised of those values which explains the spread and central tendency of data. For example, mean is a way to represent central tendency of the data, whereas IQR is a way to represent spread of the data.\",\n",
    "    \"Dependent Variable?;A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it “depends” on the independent variable. For example, let’s say we want to predict the smoking habits of people. Then the person smokes “yes” or “no” is the dependent variable.\",\n",
    "    \"What is Dependent Variable?;A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it “depends” on the independent variable. For example, let’s say we want to predict the smoking habits of people. Then the person smokes “yes” or “no” is the dependent variable.\",\n",
    "    \"Define Dependent Variable?;A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it “depends” on the independent variable. For example, let’s say we want to predict the smoking habits of people. Then the person smokes “yes” or “no” is the dependent variable.\",\n",
    "    \"Can you tell me about Dependent Variable?;A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it “depends” on the independent variable. For example, let’s say we want to predict the smoking habits of people. Then the person smokes “yes” or “no” is the dependent variable.\",\n",
    "    \"tell me something about Dependent Variable?;A dependent variable is what you measure and which is affected by independent / input variable(s). It is called dependent because it “depends” on the independent variable. For example, let’s say we want to predict the smoking habits of people. Then the person smokes “yes” or “no” is the dependent variable.\",\n",
    "    \"Decile?;Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 … D10. These are known as First Decile , Second Decile and so on.\",\n",
    "    \"What is Decile?;Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 … D10. These are known as First Decile , Second Decile and so on.\",\n",
    "    \"Define Decile?;Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 … D10. These are known as First Decile , Second Decile and so on.\",\n",
    "    \"Can you tell me about Decile?;Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 … D10. These are known as First Decile , Second Decile and so on.\",\n",
    "    \"tell me something about Decile?;Decile divides a series into 10 equal parts. For any series, there are 10 decile denoted by D1, D2, D3 … D10. These are known as First Decile , Second Decile and so on.\",\n",
    "    \"Degree of Freedom?;It is the number of variables that have the choice of having more than one arbitrary value.For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.\",\n",
    "    \"What is Degree of Freedom?;It is the number of variables that have the choice of having more than one arbitrary value.For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.\",\n",
    "    \"Define Degree of Freedom?;It is the number of variables that have the choice of having more than one arbitrary value.For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.\",\n",
    "    \"Can you tell me about Degree of Freedom?;It is the number of variables that have the choice of having more than one arbitrary value.For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.\",\n",
    "    \"tell me something about Degree of Freedom?;It is the number of variables that have the choice of having more than one arbitrary value.For example, in a sample of size 10 with mean 10, 9 values can be arbitrary but the 10th value is forced by the sample mean. So, we can choose any number for 9 values but the 10th value must be such that the mean is 10. So, the degree of freedom in this case will be 9.\",  \n",
    "    \"Dimensionality Reduction?;Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely.\",\n",
    "    \"What is Dimensionality Reduction?;Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely.\",\n",
    "    \"Define Dimensionality Reduction?;Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely.\",\n",
    "    \"Can you tell me about Dimensionality Reduction?;Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely.\",\n",
    "    \"tell me something about Dimensionality Reduction?;Dimensionality Reduction is the process of reducing the number of random variables under consideration by obtaining a set of principal variables. Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely.\",\n",
    "    \"benefits of dimensionality reduction;It helps in data compressing and reducing the storage space required\",\n",
    "    \"benefits of dimensionality reduction;It fastens the time required for performing same computations\",\n",
    "    \"benefits of dimensionality reduction;It takes care of multicollinearity that improves the model performance. It removes redundant features\",\n",
    "    \"benefits of dimensionality reduction;Reducing the dimensions of data to 2D or 3D may allow us to plot and visualize it precisely\",\n",
    "    \"benefits of dimensionality reduction;It is helpful in noise removal also and as result of that we can improve the performance of models\",\n",
    "    \"Dplyr?;Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\",\n",
    "    \"What is Dplyr?;Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\",\n",
    "    \"Define Dplyr?;Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\",\n",
    "    \"tell me something about Dplyr?;Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\",\n",
    "    \"Can you tell me about Dplyr?;Dplyr is a popular data manipulation package in R. It makes data manipulation, cleaning, summarizing very user friendly. Dplyr can work not only with the local datasets, but also with remote database tables, using exactly the same R code.\",\n",
    "    \"Dummy Variable?;Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)\",\n",
    "    \"What is Dummy Variable?;Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)\",\n",
    "    \"Define Dummy Variable?;Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)\",\n",
    "    \"tell me something about Dummy Variable?;Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)\",\n",
    "    \"Can you tell me about Dummy Variable?;Dummy Variable is another name for Boolean variable. An example of dummy variable is that it takes value 0 or 1. 0 means value is true (i.e. age < 25) and 1 means value is false (i.e. age >= 25)\",\n",
    "    \"Early Stopping?;Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\",\n",
    "    \"What is Early Stopping?;Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\",\n",
    "    \"Define Early Stopping?;Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\",\n",
    "    \"tell me something about Early Stopping?;Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\",\n",
    "    \"Can you tell me about Early Stopping?;Early stopping is a technique for avoiding overfitting when training a machine learning model with iterative method. We set the early stopping in such a way that when the performance has stopped improving on the held-out validation set, the model training stops.\",\n",
    "    \"EDA?;EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\",\n",
    "    \"What is EDA?;EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\",\n",
    "    \"Define EEDA?;EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\",\n",
    "    \"tell me something about EDA?;EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\",\n",
    "    \"Can you tell me about EDA?;EDA or exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.\",\n",
    "    \"ETL?; ETL is the acronym for Extract, Transform and Load.\",\n",
    "    \"Properties of ETL; It extracts data from the source systems\",\n",
    "    \"Properties of ETL; It enforces data quality and consistency standards \",\n",
    "    \"Properties of ETL; Delivers data in a presentation-ready format \",\n",
    "    \"Evaluation Metrics?;The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics.AUC.ROC score.F-Score.Log-Loss\",\n",
    "    \"What is Evaluation Metrics?;The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics.AUC.ROC score.F-Score.Log-Loss\",\n",
    "    \"Define Evaluation Metrics?;The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics.AUC.ROC score.F-Score.Log-Loss\",\n",
    "    \"tell me something about Evaluation Metrics?;The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics.AUC.ROC score.F-Score.Log-Loss\",\n",
    "    \"Can you tell me about Evaluation Metrics?;The purpose of evaluation metric is to measure the quality of the statistical / machine learning model. For example, below are a few evaluation metrics.AUC.ROC score.F-Score.Log-Loss\",\n",
    "    \"Factor Analysis?;Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables.\",\n",
    "    \"What is Factor Analysis?;Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables.\",\n",
    "    \"Define Factor Analysis?;Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables.\",\n",
    "    \"tell me something about Factor Analysis?;Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables.\",\n",
    "    \"Can you tell me about Factor Analysis?;Factor analysis is a technique that is used to reduce a large number of variables into fewer numbers of factors. Factor analysis aims to find independent latent variables.\",\n",
    "    \"False Negative?;Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.\",\n",
    "    \"What is False Negative?;Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.\",\n",
    "    \"Define False Negative?;Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.\",\n",
    "    \"tell me something about False Negative?;Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.\",\n",
    "    \"Can you tell me about False Negative?;Points which are actually true but are incorrectly predicted as false. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False negative in this case will be the samples for which loan was approved but the model predicted the status as not approved.\",\n",
    "    \"False Positive?;Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.\",\n",
    "    \"What is False Positive?;Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.\",\n",
    "    \"Define False Positive?;Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.\",\n",
    "    \"tell me something about False Positive?;Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.\",\n",
    "    \"Can you tell me about False Positive?;Points which are actually false but are incorrectly predicted as true. For example, if the problem is to predict the loan status. (Y-loan approved, N-loan not approved). False positive in this case will be the samples for which loan was not approved but the model predicted the status as approved.\",\n",
    "    \"Feature Hashing?;It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly.\",\n",
    "    \"What is Feature Hashing?;It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly.\",\n",
    "    \"Define Feature Hashing?;It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly.\",\n",
    "    \"tell me something about Feature Hashing?;It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly.\",\n",
    "    \"Can you tell me about Feature Hashing?;It is a method to transform features to vector. Without looking up the indices in an associative array, it applies a hash function to the features and uses their hash values as indices directly.\",\n",
    "    \"Feature Reduction?;Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.\",\n",
    "    \"What is Feature Reduction?;Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.\",\n",
    "    \"Define Feature Reduction?;Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.\",\n",
    "    \"tell me something about Feature Reduction?;Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.\",\n",
    "    \"Can you tell me about Feature Reduction?;Feature reduction is the process of reducing the number of features to work on a computation intensive task without losing a lot of information.PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.\",\n",
    "    \"Feature Selection?;Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.This can be done by either filtering out less useful features or by combining features to make a new one.\",\n",
    "    \"What is Feature Selection?;Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.This can be done by either filtering out less useful features or by combining features to make a new one.\",\n",
    "    \"Define Feature Selection?;Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.This can be done by either filtering out less useful features or by combining features to make a new one.\",\n",
    "    \"tell me something about Feature Selection?;Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.This can be done by either filtering out less useful features or by combining features to make a new one.\",\n",
    "    \"Can you tell me about Feature Selection?;Feature Selection is a process of choosing those features which are required to explain the predictive power of a statistical model and dropping out irrelevant features.This can be done by either filtering out less useful features or by combining features to make a new one.\",\n",
    "    \"Few-shot Learning?;Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.\",\n",
    "    \"What is Few-shot Learning?;Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.\",\n",
    "    \"Define Few-shot Learning?;Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.\",\n",
    "    \"Can you tell me about Few-shot Learning?;Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.\",\n",
    "    \"tell me something about Few-shot Learning?;Few-shot learning refers to the training of machine learning algorithms using a very small set of training data instead of a very large set. This is most suitable in the field of computer vision, where it is desirable to have an object categorization model work well without thousands of training examples.\",\n",
    "    \"Flume?;Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\",\n",
    "    \"What is Flume?;Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\",\n",
    "    \"Define Flume?;Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\",\n",
    "    \"tell me something about Flume?;Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\",\n",
    "    \"Can you tell me about Flume?;Flume is a service designed for streaming logs into the Hadoop environment. It can collect and aggregate huge amounts of log data from a variety of sources. In order to collect high volume of data, multiple flume agents can be configured.\",\n",
    "    \"Frequentist Statistics?; Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\",\n",
    "    \"What is Frequentist Statistics?; Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\",\n",
    "    \"Define Frequentist Statistics?; Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\",\n",
    "    \"tell me something about Frequentist Statistics?; Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\",\n",
    "    \"Can you tell me about Frequentist Statistics?; Frequentist Statistics tests whether an event (hypothesis) occurs or not. It calculates the probability of an event in the long run of the experiment (i.e the experiment is repeated under the same conditions to obtain the outcome).\",\n",
    "    \"F-Score?;F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by β coefficient.\",\n",
    "    \"What is F-Score?;F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by β coefficient.\",\n",
    "    \"Define F-Score?;F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by β coefficient.\",\n",
    "    \"tell me something about F-Score?;F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by β coefficient.\",\n",
    "    \"Can you tell me about F-Score?;F-score evaluation metric combines both precision and recall as a measure of effectiveness of classification. It is calculated in terms of ratio of weighted importance on either recall or precision as determined by β coefficient.\",\n",
    "    \"Gated Recurrent Unit (GRU)?;The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM’s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\",\n",
    "    \"What is Gated Recurrent Unit (GRU)?;The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM’s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\",\n",
    "    \"Define Gated Recurrent Unit (GRU)?;The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM’s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\",\n",
    "    \"tell me something about Gated Recurrent Unit (GRU)?;The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM’s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\",\n",
    "    \"Can you tell me about Gated Recurrent Unit (GRU)?;The GRU is a variant of the LSTM (Long Short Term Memory) and was introduced by K. Cho. It retains the LSTM’s resistance to the vanishing gradient problem, but because of its simpler internal structure it is faster to train.\",  \n",
    "    \"Ggplot2?;GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots.\",\n",
    "    \"What is Ggplot2?;GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots.\",\n",
    "    \"Define Ggplot2?;GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots.\",\n",
    "    \"tell me something about Ggplot2?;GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots.\",\n",
    "    \"Can you tell me about Ggplot2?;GGplot2 is a data visualization package for the R programming language. It is a highly versatile and user-friendly tool for creating attractive plots.\",\n",
    "    \"Go?;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.The main features of Go are:Memory safety,Garbage collection,Structural typing\",\n",
    "    \"What is Go?;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.The main features of Go are:Memory safety,Garbage collection,Structural typing\",\n",
    "    \"Define Go?;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.The main features of Go are:Memory safety,Garbage collection,Structural typing\",\n",
    "    \"tell me something about Go?;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.The main features of Go are:Memory safety,Garbage collection,Structural typing\",\n",
    "    \"Can you tell me about Go?;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. Go is a statically typed language in the tradition of C.The main features of Go are:Memory safety,Garbage collection,Structural typing\",\n",
    "    \"Goodness of Fit?;The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\",\n",
    "    \"What is Goodness of Fit?;The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\",\n",
    "    \"Define Goodness of Fit?;The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\",\n",
    "    \"tell me something about Goodness of Fit?;The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\",\n",
    "    \"Can you tell me about Goodness of Fit?;The goodness of fit of a model describes how well it fits a set of observations. Measures of goodness of fit typically summarize the discrepancy between observed values and the values expected under the model.\",    \n",
    "    \"Gradient Descent?;Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm.\",\n",
    "    \"What is Gradient Descent?;Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm.\",\n",
    "    \"Define Gradient Descent?;Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm.\",\n",
    "    \"tell me something about Gradient Descent?;Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm.\",\n",
    "    \"Can you tell me about Gradient Descent?;Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. In machine learning algorithms, we use gradient descent to minimize the cost function. It find out the best set of parameters for our algorithm.\",    \n",
    "    \"full batch gradient descent?;In full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\",\n",
    "    \"What is full batch gradient descent?;In full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\",\n",
    "    \"Define full batch gradient descent?;In full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\",\n",
    "    \"tell me something about full batch gradient descent?;In full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\",\n",
    "    \"Can you tell me about full batch gradient descent?;In full batch gradient descent algorithms, we use whole data at once to compute the gradient, whereas in stochastic we take a sample while computing the gradient.\",    \n",
    "    \"Hadoop?;Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data.\",\n",
    "    \"What is Hadoop?;Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data.\",\n",
    "    \"Define Hadoop?;Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data.\",\n",
    "    \"tell me something about Hadoop?;Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data.\",\n",
    "    \"Can you tell me about Hadoop?;Hadoop is an open source distributed processing framework used when we have to deal with enormous data. It allows us to use parallel processing capability to handle big data.\",    \n",
    "    \"significant benefits of Hadoop?; Hadoop clusters work and keeps multiple copies to ensure reliability of data. A maximum of 4500 machines can be connected together using Hadoop\",\n",
    "    \"significant benefits of Hadoop?; The whole process is broken down into pieces and executed in parallel, hence saving time. A maximum of 25 Petabyte (1 PB = 1000 TB) data can be processed using Hadoop\",\n",
    "    \"significant benefits of Hadoop?; In case of a long query, Hadoop builds back up data-sets at every level. It also executes query on duplicate datasets to avoid process loss in case of individual failure. These steps makes Hadoop processing more precise and accurate\",\n",
    "    \"significant benefits of Hadoop?; Queries in Hadoop are as simple as coding in any language. You just need to change the way of thinking around building a query to enable parallel processing\",\n",
    "    \"Hidden Markov Model?; Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible.HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.\",\n",
    "    \"What is Hidden Markov Model?; Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible.HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.\",\n",
    "    \"Define Hidden Markov Model?; Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible.HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.\",\n",
    "    \"tell me something about Hidden Markov Model?; Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible.HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.\",\n",
    "    \"Can you tell me about Hidden Markov Model?; Hidden Markov Process is a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible.HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.\",    \n",
    "    \"Hierarchical Clustering?; Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\",\n",
    "    \"What is Hierarchical Clustering?; Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\",\n",
    "    \"Define Hierarchical Clustering?; Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\",\n",
    "    \"tell me something about Hierarchical Clustering?; Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\",\n",
    "    \"Can you tell me about Hierarchical Clustering?; Hierarchical clustering, as the name suggests is an algorithm that builds hierarchy of clusters. This algorithm starts with all the data points assigned to a cluster of their own. Then two nearest clusters are merged into the same cluster. In the end, this algorithm terminates when there is only a single cluster left.\",    \n",
    "    \"Histogram?; Histogram is one of the methods for visualizing data distribution of continuous variables.Histograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.\",\n",
    "    \"What is Histogram?; Histogram is one of the methods for visualizing data distribution of continuous variables.Histograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.\",\n",
    "    \"Define Histogram?; Histogram is one of the methods for visualizing data distribution of continuous variables.Histograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.\",\n",
    "    \"tell me something about Histogram?; Histogram is one of the methods for visualizing data distribution of continuous variables.Histograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.\",\n",
    "    \"Can you tell me about Histogram?; Histogram is one of the methods for visualizing data distribution of continuous variables.Histograms are widely used to determine the skewness of the data. Looking at the tail of the plot, you can find whether the data distribution is left skewed, normal or right skewed.\",    \n",
    "    \"Hive?; Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\",\n",
    "    \"What is Hive?; Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\",\n",
    "    \"Define Hive?; Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\",\n",
    "    \"tell me something about Hive?; Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\",\n",
    "    \"Can you tell me about Hive?; Hive is a data warehouse software project to process structured data in Hadoop. It is built on top of Apache Hadoop for providing data summarization, query and analysis. Hive gives an SQL-like interface to query data stored in various databases and file systems that integrate with Hadoop.\",    \n",
    "    \"key features of Hive?; Indexing to provide acceleration\",\n",
    "    \"key features of Hive?;Different storage types such as plain text, RDFile, HBase, ORC, and others\",\n",
    "    \"key features of Hive?;Metadata storage in a relational database management system, significantly reducing the time to perform semantic checks during query execution\",\n",
    "    \"key features of Hive?; Operating on compressed data stored into the Hadoop ecosystem\",    \n",
    "    \"Holdout Sample?;While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\",\n",
    "    \"What is Holdout Sample?;While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\",\n",
    "    \"Define Holdout Sample?;While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\",\n",
    "    \"tell me something about Holdout Sample?;While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\",\n",
    "    \"Can you tell me about Holdout Sample?;While working on the dataset, a small part of the dataset is not used for training the model instead, it is used to check the performance of the model. This part of the dataset is called the holdout sample.\",    \n",
    "    \"Holt-Winters Forecasting?; Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt’s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\",\n",
    "    \"What is Holt-Winters Forecasting?; Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt’s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\",\n",
    "    \"Define Holt-Winters Forecasting?; Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt’s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\",\n",
    "    \"tell me something about Holt-Winters Forecasting?; Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt’s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\",\n",
    "    \"Can you tell me about Holt-Winters Forecasting?; Holt-Winters is one of the most popular forecasting techniques for time series. The model predicts the future values computing the combined effects of both trend and seasonality. The idea behind Holt’s Winter forecasting is to apply exponential smoothing to the seasonal components in addition to level and trend.\",    \n",
    "    \"Hyperparameter?;A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\",\n",
    "    \"What is Hyperparameter?;A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\",\n",
    "    \"Define Hyperparameter?;A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\",\n",
    "    \"tell me something about Hyperparameter?;A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\",\n",
    "    \"Can you tell me about Hyperparameter?;A hyperparameter is a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.\",        \n",
    "    \"keys points about the hyperparameters; They are often used in processes to help estimate model parameters.\",\n",
    "    \"keys points about the hyperparameters; They are often manually set.\",\n",
    "    \"keys points about the hyperparameters; They are often tuned to tweak a model’s performance \",    \n",
    "    \"some examples of hyperparameters?;Number of trees in a Random Forest, eta in XGBoost, and k in k-nearest neighbours are some examples of hyperparameters.\",    \n",
    "    \"Hyperplane?; It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it’s a 4D plane, so on and so forth.Most of the time it’s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.\",\n",
    "    \"What is Hyperplane?; It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it’s a 4D plane, so on and so forth.Most of the time it’s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.\",\n",
    "    \"Define Hyperplane?; It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it’s a 4D plane, so on and so forth.Most of the time it’s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.\",\n",
    "    \"tell me something about Hyperplane?; It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it’s a 4D plane, so on and so forth.Most of the time it’s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.\",\n",
    "    \"Can you tell me about Hyperplane?; It is a subspace with one fewer dimensions than its surrounding area. If a space is 3-dimensional then its hyperplane is just a normal 2D plane. In 5 dimensional space, it’s a 4D plane, so on and so forth.Most of the time it’s basically a normal plane, but in some special cases, like in Support Vector Machines, where classifications are performed with an n-dimensional hyperplane, the n can be quite large.\",    \n",
    "    \"Hypothesis?; a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true\",\n",
    "    \"What is Hypothesis?; a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true\",\n",
    "    \"Define Hypothesis?; a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true\",\n",
    "    \"tell me something about Hypothesis?; a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true\",\n",
    "    \"Can you tell me about Hypothesis?; a hypothesis is a possible view or assertion of an analyst about the problem he or she is working upon. It may be true or may not be true\",    \n",
    "    \"Imputation?; Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\",\n",
    "    \"What is Imputation?; Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\",\n",
    "    \"Define Imputation?; Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\",\n",
    "    \"tell me something about Imputation?; Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\",\n",
    "    \"Can you tell me about Imputation?; Imputation is a technique used for handling missing values in the data. This is done either by statistical metrics like mean/mode imputation or by machine learning techniques like kNN imputation\",    \n",
    "    \"Inferential Statistics?; In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.\",\n",
    "    \"What is Inferential Statistics?; In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.\",\n",
    "    \"Define Inferential Statistics?; In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.\",\n",
    "    \"tell me something about Inferential Statistics?; In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.\",\n",
    "    \"Can you tell me about Inferential Statistics?; In inferential statistics, we try to hypothesize about the population by only looking at a sample of it. For example, before releasing a drug in the market, internal tests are done to check if the drug is viable for release. But here we cannot check with the whole population for viability of the drug, so we do it on a sample which best represents the population.\",    \n",
    "    \"IQR?; IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 – Quartile1.\",\n",
    "    \"What is IQR?; IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 – Quartile1.\",\n",
    "    \"Define IQR?; IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 – Quartile1.\",\n",
    "    \"tell me something about IQR?; IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 – Quartile1.\",\n",
    "    \"Can you tell me about IQR?; IQR (or interquartile range) is a measure of variability based on dividing the rank-ordered data set into four equal parts. It can be derived by Quartile3 – Quartile1.\",    \n",
    "    \"Iteration?; Iteration refers to the number of times an algorithm’s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.\",\n",
    "    \"What is Iteration?; Iteration refers to the number of times an algorithm’s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.\",\n",
    "    \"Define Iteration?; Iteration refers to the number of times an algorithm’s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.\",\n",
    "    \"tell me something about Iteration?; Iteration refers to the number of times an algorithm’s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.\",\n",
    "    \"Can you tell me about Iteration?; Iteration refers to the number of times an algorithm’s parameters are updated while training a model on a dataset. For example, each iteration of training a neural network takes certain number of training data and updates the weights by using gradient descent or some other weight update rule.\",    \n",
    "    \"Julia?; Julia is a high-level, high-performance dynamic programming language for numerical computing.\",\n",
    "    \"What is Julia?; Julia is a high-level, high-performance dynamic programming language for numerical computing.\",\n",
    "    \"Define Julia?; Julia is a high-level, high-performance dynamic programming language for numerical computing.\",\n",
    "    \"tell me something about Julia?; Julia is a high-level, high-performance dynamic programming language for numerical computing.\",\n",
    "    \"Can you tell me about Julia?; Julia is a high-level, high-performance dynamic programming language for numerical computing.\",    \n",
    "    \"features of Julia?; Multiple dispatch: providing the ability to define function behavior across many combinations of argument types.\",\n",
    "    \"What is features of Julia?; Good performance, approaching that of statically-compiled languages like C\",\n",
    "    \"Define features of Julia?; Built-in package manager\",\n",
    "    \"tell me something about features of Julia?; Designed for parallelism and distributed computation\",\n",
    "    \"Can you tell me about features of Julia?; Free and open source\",    \n",
    "    \"K-Means?; It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.\",\n",
    "    \"What is K-Means?; It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.\",\n",
    "    \"Define K-Means?; It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.\",\n",
    "    \"tell me something about K-Means?; It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.\",\n",
    "    \"Can you tell me about K-Means?; It is a type of unsupervised algorithm which solves the clustering problem. It is a procedure which follows a simple and easy way to classify a given data set through a certain number of clusters (assume k clusters). Data points inside a cluster are homogeneous and heterogeneous to peer groups.\",    \n",
    "    \"Keras?; Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\",\n",
    "    \"What is Keras?; Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\",\n",
    "    \"Define Keras?; Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\",\n",
    "    \"tell me something about Keras?; Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\",\n",
    "    \"Can you tell me about Keras?; Keras is a simple, high-level neural network library, written in Python. It is capable of running on top of Tensorflow and Theano. This is done to make design and experiments with Neural Networks easier.\",    \n",
    "    \"features of Keras;User friendliness,Modularity,Easy extensibility,Work with Python\",    \n",
    "    \"kNN?; K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\",\n",
    "    \"What is kNN?; K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\",\n",
    "    \"Define kNN?; K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\",\n",
    "    \"tell me something about kNN?; K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\",\n",
    "    \"Can you tell me about kNN?; K nearest neighbors is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its K nearest neighbors measured by a distance function.\",    \n",
    "    \"Kurtosis?; Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:Mesokurtic: The distribution with kurtosis value equal to 3.Platykurtic: If the kurtosis is less than 3.Leptykurtic: When the kurtosis value is greater than 3\",\n",
    "    \"What is Kurtosis?; Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:Mesokurtic: The distribution with kurtosis value equal to 3.Platykurtic: If the kurtosis is less than 3.Leptykurtic: When the kurtosis value is greater than 3\",\n",
    "    \"Define Kurtosis?; Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:Mesokurtic: The distribution with kurtosis value equal to 3.Platykurtic: If the kurtosis is less than 3.Leptykurtic: When the kurtosis value is greater than 3\",\n",
    "    \"tell me something about Kurtosis?; Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:Mesokurtic: The distribution with kurtosis value equal to 3.Platykurtic: If the kurtosis is less than 3.Leptykurtic: When the kurtosis value is greater than 3\",\n",
    "    \"Can you tell me about Kurtosis?; Kurtosis is defined as the thickness (or heaviness) of the tails of a given distribution. Depending on the value of kurtosis, it can be classified into the below 3 categories:Mesokurtic: The distribution with kurtosis value equal to 3.Platykurtic: If the kurtosis is less than 3.Leptykurtic: When the kurtosis value is greater than 3\",    \n",
    "    \"Labeled Data?; A labeled dataset has a meaningful “label”, “class” or “tag” associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\",\n",
    "    \"What is Labeled Data?; A labeled dataset has a meaningful “label”, “class” or “tag” associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\",\n",
    "    \"Define Labeled Data?; A labeled dataset has a meaningful “label”, “class” or “tag” associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\",\n",
    "    \"tell me something about Labeled Data?; A labeled dataset has a meaningful “label”, “class” or “tag” associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\",\n",
    "    \"Can you tell me about Labeled Data?; A labeled dataset has a meaningful “label”, “class” or “tag” associated with each of its records or rows. For example, labels for a dataset of a set of images might be whether an image contains a cat or a dog.\",    \n",
    "    \"Lasso Regression?; Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective.\",\n",
    "    \"What is Lasso Regression?; Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective.\",\n",
    "    \"Define Lasso Regression?; Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective.\",\n",
    "    \"tell me something about Lasso Regression?; Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective.\",\n",
    "    \"Can you tell me about Lasso Regression?; Lasso regression performs L1 regularization, i.e. it adds a factor of sum of absolute value of coefficients in the optimization objective.\",    \n",
    "    \"Line Chart?; Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\",\n",
    "    \"What is Line Chart?; Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\",\n",
    "    \"Define Line Chart?; Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\",\n",
    "    \"tell me something about Line Chart?; Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\",\n",
    "    \"Can you tell me about Line Chart?; Line charts are used to display information as series of points connected by straight line segment. These charts are used to communicate information visually, such as to show an increase or decrease in the trend in data over intervals of time.\",    \n",
    "    \"Log Loss?; Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\",\n",
    "    \"What is Log Loss?; Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\",\n",
    "    \"Define Log Loss?; Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\",\n",
    "    \"tell me something about Log Loss?; Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\",\n",
    "    \"Can you tell me about Log Loss?; Log Loss or Logistic loss is one of the evaluation metrics used to find how good the model is. Lower the log loss, better is the model. Log loss is the logarithm of the product of all probabilities.\",    \n",
    "    \"Logistic Regression?; it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression.\",\n",
    "    \"What is Logistic Regression?; it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression.\",\n",
    "    \"Define Logistic Regression?; it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression.\",\n",
    "    \"tell me something about Logistic Regression?; it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression.\",\n",
    "    \"Can you tell me about Logistic Regression?; it predicts the probability of occurrence of an event by fitting data to a logistic function. Hence, it is also known as logistic regression.\",    \n",
    "    \"Long Short Term Memory (LSTM);Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for “remembering” values over arbitrary time intervals, hence the word “memory” in LSTM.\",\n",
    "    \"What is Long Short Term Memory (LSTM);Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for “remembering” values over arbitrary time intervals, hence the word “memory” in LSTM.\",\n",
    "    \"Define Long Short Term Memory (LSTM);Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for “remembering” values over arbitrary time intervals, hence the word “memory” in LSTM.\",\n",
    "    \"tell me something about Long Short Term Memory (LSTM);Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for “remembering” values over arbitrary time intervals, hence the word “memory” in LSTM.\",\n",
    "    \"Can you tell me about Long Short Term Memory (LSTM);Long short-term memory (LSTM) units (or blocks) are a building unit for layers of a recurrent neural network (RNN). A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell is responsible for “remembering” values over arbitrary time intervals, hence the word “memory” in LSTM.\",    \n",
    "    \"Applications of LSTM include;Time series predictions,Speech recognition,Rhythm learning,Handwriting recognition\",    \n",
    "    \"Machine Learning?; Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.\",\n",
    "    \"What is Machine Learning?; Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.\",\n",
    "    \"Define Machine Learning?; Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.\",\n",
    "    \"tell me something about Machine Learning?; Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.\",\n",
    "    \"Can you tell me about Machine Learning?; Machine Learning refers to the techniques involved in dealing with vast data in the most intelligent fashion (by developing algorithms) to derive actionable insights. In these techniques, we expect the algorithms to learn by itself wiithout being explicitly programmed.\",    \n",
    "    \"Mahout?; Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\",\n",
    "    \"What is Mahout?; Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\",\n",
    "    \"Define Mahout?; Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\",\n",
    "    \"tell me something about Mahout?; Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\",\n",
    "    \"Can you tell me about Mahout?; Mahout is an open source project from Apache that is used for creating scalable machine learning algorithms. It implements popular machine learning techniques such as recommendation, classification, clustering.\",    \n",
    "    \"Features of Mahout;Mahout offers a framework for doing data mining tasks on large volumes of data\",\n",
    "    \"Features of Mahout;Mahout lets applications to analyze large sets of data effectively and in quick time\",\n",
    "    \"Features of Mahout;It also offers distributed fitness function capabilities for evolutionary programming\",\n",
    "    \"Features of Mahout;It includes several MapReduce enabled clustering implementations such as k-means, fuzzy k-means, Dirichlet, and Mean-Shift\",    \n",
    "    \"MapReduce?;Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner\",\n",
    "    \"What is MapReduce?;Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner\",\n",
    "    \"Define MapReduce?;Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner\",\n",
    "    \"tell me something about MapReduce?;Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner\",\n",
    "    \"Can you tell me about MapReduce?;Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner\",    \n",
    "    \"Market Basket Analysis?; Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.\",\n",
    "    \"What is Market Basket Analysis?; Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.\",\n",
    "    \"Define Market Basket Analysis?; Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.\",\n",
    "    \"tell me something about Market Basket Analysis?; Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.\",\n",
    "    \"Can you tell me about Market Basket Analysis?; Market Basket Analysis (also called as MBA) is a widely used technique among the Marketers to identify the best possible combinatory of the products or services which are frequently bought by the customers. This is also called product association analysis.\",    \n",
    "    \"Market Mix Modeling?; Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\",\n",
    "    \"What is Market Mix Modeling?; Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\",\n",
    "    \"Define Market Mix Modeling?; Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\",\n",
    "    \"tell me something about Market Mix Modeling?; Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\",\n",
    "    \"Can you tell me about Market Mix Modeling?; Market Mix Modeling is an analytical approach that uses historical information like point of sales to quantify the impact of some of the components on sales.\",    \n",
    "    \"Maximum Likelihood Estimation?; It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).\",\n",
    "    \"What is Maximum Likelihood Estimation?; It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).\",\n",
    "    \"Define Maximum Likelihood Estimation?; It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).\",\n",
    "    \"tell me something about Maximum Likelihood Estimation?; It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).\",\n",
    "    \"Can you tell me about Maximum Likelihood Estimation?; It is a method for finding the values of parameters which make the likelihood maximum. The resulting values are called maximum likelihood estimates (MLE).\",    \n",
    "    \"Mean?; For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\",\n",
    "    \"What is Mean?; For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\",\n",
    "    \"Define Mean?; For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\",\n",
    "    \"tell me something about Mean?; For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\",\n",
    "    \"Can you tell me about Mean?; For a dataset, mean is said to be the average value of all the numbers. It can sometimes be used as a representation of the whole data.\",    \n",
    "    \"Median?; Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\",\n",
    "    \"What is Median?; Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\",\n",
    "    \"Define Median?; Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\",\n",
    "    \"tell me something about Median?; Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\",\n",
    "    \"Can you tell me about Median?; Median of a set of numbers is usually the middle value. When the total numbers in the set are even, the median will be the average of the two middle values. Median is used to measure the central tendency.\",    \n",
    "    \"MIS?; A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization’s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\",\n",
    "    \"What is MIS?; A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization’s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\",\n",
    "    \"Define MIS?; A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization’s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\",\n",
    "    \"tell me something about MIS?; A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization’s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\",\n",
    "    \"Can you tell me about MIS?; A management information system (MIS) is a computer system consisting of hardware and software that serves as the backbone of an organization’s operations. An MIS gathers data from multiple online systems, analyzes the information, and reports data to aid in management decision-making.\",    \n",
    "    \"Objectives of MIS?; To improve decision-making, by providing up-to-date, accurate data on a variety of organizational assets\",\n",
    "    \"Objectives of MIS?; To correlate multiple data points in order to strategize ways to improve operations\",    \n",
    "    \"ML-as-a-Service (MLaaS)?; Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning.\",\n",
    "    \"What is ML-as-a-Service (MLaaS)?; Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning.\",\n",
    "    \"Define ML-as-a-Service (MLaaS)?; Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning.\",\n",
    "    \"tell me something about ML-as-a-Service (MLaaS)?; Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning.\",\n",
    "    \"Can you tell me about ML-as-a-Service (MLaaS)?; Machine learning as a service (MLaaS) is an array of services that provide machine learning tools as part of cloud computing services. This can include tools for data visualization, facial recognition, natural language processing, image recognition, predictive analytics, and deep learning.\",    \n",
    "    \"Mode?; Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\",\n",
    "    \"What is Mode?; Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\",\n",
    "    \"Define Mode?; Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\",\n",
    "    \"tell me something about Mode?; Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\",\n",
    "    \"Can you tell me about Mode?; Mode is the most frequent value occuring in the population. It is a metric to measure the central tendency, i.e. a way of expressing, in a (usually) single number, important information about a random variable or a population.\",    \n",
    "    \"Model Selection?; Model selection is the task of selecting a statistical model from a set of known models.\",\n",
    "    \"What is Model Selection?; Model selection is the task of selecting a statistical model from a set of known models.\",\n",
    "    \"Define Model Selection?; Model selection is the task of selecting a statistical model from a set of known models.\",\n",
    "    \"tell me something about Model Selection?; Model selection is the task of selecting a statistical model from a set of known models.\",\n",
    "    \"Can you tell me about Model Selection?; Model selection is the task of selecting a statistical model from a set of known models.\",    \n",
    "    \"Monte Carlo Simluation?; The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process.\",\n",
    "    \"What is Monte Carlo Simluation?; The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process.\",\n",
    "    \"Define Monte Carlo Simluation?; The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process.\",\n",
    "    \"tell me something about Monte Carlo Simluation?; The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process.\",\n",
    "    \"Can you tell me about Monte Carlo Simluation?; The idea behind Monte Carlo Simulation is to use random samples of parameters or inputs to explore the behavior of a complex process.\",    \n",
    "    \"Multi-Class Classification?; Problems which have more than one class in the target variable are called multi-class Classification problems.\",\n",
    "    \"What is Multi-Class Classification?; Problems which have more than one class in the target variable are called multi-class Classification problems.\",\n",
    "    \"Define Multi-Class Classification?; Problems which have more than one class in the target variable are called multi-class Classification problems.\",\n",
    "    \"tell me something about Multi-Class Classification?; Problems which have more than one class in the target variable are called multi-class Classification problems.\",\n",
    "    \"Can you tell me about Multi-Class Classification?; Problems which have more than one class in the target variable are called multi-class Classification problems.\",    \n",
    "    \"Multivariate Analysis?; Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\",\n",
    "    \"What is Multivariate Analysis?; Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\",\n",
    "    \"Define Multivariate Analysis?; Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\",\n",
    "    \"tell me something about Multivariate Analysis?; Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\",\n",
    "    \"Can you tell me about Multivariate Analysis?; Multivariate analysis is a process of comparing and analyzing the dependency of multiple variables over each other.\",    \n",
    "    \"Naive Bayes; It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\",\n",
    "    \"What is Naive Bayes; It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\",\n",
    "    \"Define Naive Bayes; It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\",\n",
    "    \"tell me something about Naive Bayes; It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\",\n",
    "    \"Can you tell me about Naive Bayes; It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature.\",    \n",
    "    \"NaN?; NaN stands for ‘not a number’. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.\",\n",
    "    \"What is NaN?; NaN stands for ‘not a number’. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.\",\n",
    "    \"Define NaN?; NaN stands for ‘not a number’. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.\",\n",
    "    \"tell me something about NaN?; NaN stands for ‘not a number’. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.\",\n",
    "    \"Can you tell me about NaN?; NaN stands for ‘not a number’. It is a numeric data type value representing an undefined or unrepresentable value. If the dataset has NaN values somewhere, it means that the data at that location is either missing or represented incorrectly.\",    \n",
    "    \"Natural Language Processing ?; In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\",\n",
    "    \"What is Natural Language Processing ?; In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\",\n",
    "    \"Define Natural Language Processing ?; In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\",\n",
    "    \"tell me something about Natural Language Processing ?; In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\",\n",
    "    \"Can you tell me about Natural Language Processing ?; In simple words, Natural Language Processing is a field which aims to make computer systems understand human speech. NLP is comprised of techniques to process, structure, categorize raw text and extract information.\",    \n",
    "    \"NoSQL?; NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\",\n",
    "    \"What is NoSQL?; NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\",\n",
    "    \"Define NoSQL?; NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\",\n",
    "    \"tell me something about NoSQL?; NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\",\n",
    "    \"Can you tell me about NoSQL?; NoSQL means Not only SQL. A NoSQL database provides a mechanism for storage and retrieval of data that is modeled in means other than the tabular relations used in relational databases. It can accommodate a wide variety of data models, including key-value, document, columnar and graph formats.\",    \n",
    "    \"Nominal Variable?; Nominal variables are categorical variables having two or more categories without any kind of order to them.\",\n",
    "    \"What is Nominal Variable?; Nominal variables are categorical variables having two or more categories without any kind of order to them.\",\n",
    "    \"Define Nominal Variable?; Nominal variables are categorical variables having two or more categories without any kind of order to them.\",\n",
    "    \"tell me something about Nominal Variable?; Nominal variables are categorical variables having two or more categories without any kind of order to them.\",\n",
    "    \"Can you tell me about Nominal Variable?; Nominal variables are categorical variables having two or more categories without any kind of order to them.\",    \n",
    "    \"Normal Distribution?; The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.\",\n",
    "    \"What is Normal Distribution?; The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.\",\n",
    "    \"Define Normal Distribution?; The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.\",\n",
    "    \"tell me something about Normal Distribution?; The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.\",\n",
    "    \"Can you tell me about Normal Distribution?; The normal distribution is the most important and most widely used distribution in statistics. It is sometimes called the bell curve, because it has a peculiar shape of a bell. Mostly, a binomial distribution is similar to normal distribution. The difference between the two is normal distribution is continuous.\",    \n",
    "    \"Normalization?; Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\",\n",
    "    \"What is Normalization?; Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\",\n",
    "    \"Define Normalization?; Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\",\n",
    "    \"tell me something about Normalization?; Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\",\n",
    "    \"Can you tell me about Normalization?; Normalization is the process of rescaling your data so that they have the same scale. Normalization is used when the attributes in our data have varying scales.\",    \n",
    "    \"Numpy?; NumPy is the fundamental package for scientific computing with Python.\",\n",
    "    \"What is Numpy?; NumPy is the fundamental package for scientific computing with Python.\",\n",
    "    \"Define Numpy?; NumPy is the fundamental package for scientific computing with Python.\",\n",
    "    \"tell me something about Numpy?; NumPy is the fundamental package for scientific computing with Python.\",\n",
    "    \"Can you tell me about Numpy?; NumPy is the fundamental package for scientific computing with Python.\",    \n",
    "    \"One Hot Encoding?; One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\",\n",
    "    \"What is One Hot Encoding?; One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\",\n",
    "    \"Define One Hot Encoding?; One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\",\n",
    "    \"tell me something about One Hot Encoding?; One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\",\n",
    "    \"Can you tell me about One Hot Encoding?; One Hot encoding is done usually in the preprocessing step. It is a technique which converts categorical variables to numerical in an interpretable format. In this we create a Boolean column for each category of the variable.\",    \n",
    "    \"One Shot Learning?; It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.\",\n",
    "    \"What is One Shot Learning?; It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.\",\n",
    "    \"Define One Shot Learning?; It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.\",\n",
    "    \"tell me something about One Shot Learning?; It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.\",\n",
    "    \"Can you tell me about One Shot Learning?; It is a machine learning approach where the model is trained on a single example. One-shot Learning is generally used for object classification. This is performed to design effective classifiers from a single training example.\",    \n",
    "    \"Oozie?; Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop’s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\",\n",
    "    \"What is Oozie?; Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop’s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\",\n",
    "    \"Define Oozie?; Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop’s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\",\n",
    "    \"tell me something about Oozie?; Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop’s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\",\n",
    "    \"Can you tell me about Oozie?; Apache Oozie is the tool in which all sort of programs can be pipelined in a desired order to work in Hadoop’s distributed environment. Oozie also provides a mechanism to run the job at a given schedule.\",    \n",
    "    \"Ordinal Variable?; Ordinal variables are those variables which have discrete values but has some order involved.\",\n",
    "    \"What is Ordinal Variable?; Ordinal variables are those variables which have discrete values but has some order involved.\",\n",
    "    \"Define Ordinal Variable?; Ordinal variables are those variables which have discrete values but has some order involved.\",\n",
    "    \"tell me something about Ordinal Variable?; Ordinal variables are those variables which have discrete values but has some order involved.\",\n",
    "    \"Can you tell me about Ordinal Variable?; Ordinal variables are those variables which have discrete values but has some order involved.\",    \n",
    "    \"Outlier?; Outlier is an observation that appears far away and diverges from an overall pattern in a sample.\",\n",
    "    \"What is Outlier?; Outlier is an observation that appears far away and diverges from an overall pattern in a sample.\",\n",
    "    \"Define Outlier?; Outlier is an observation that appears far away and diverges from an overall pattern in a sample.\",\n",
    "    \"tell me something about Outlier?; Outlier is an observation that appears far away and diverges from an overall pattern in a sample.\",\n",
    "    \"Can you tell me about Outlier?; Outlier is an observation that appears far away and diverges from an overall pattern in a sample.\",    \n",
    "    \"Overfitting?;A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:Reduce the model complexity,Regularization\",\n",
    "    \"What is Overfitting?;A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:Reduce the model complexity,Regularization\",\n",
    "    \"Define Overfitting?;A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:Reduce the model complexity,Regularization\",\n",
    "    \"tell me something about Overfitting?;A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:Reduce the model complexity,Regularization\",\n",
    "    \"Can you tell me about Overfitting?;A model is said to overfit when it performs well on the train dataset but fails on the test set. This happens when the model is too sensitive and captures random patterns which are present only in the training dataset. There are two methods to overcome overfitting:Reduce the model complexity,Regularization\",    \n",
    "    \"Pandas?; Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language.\",\n",
    "    \"What is Pandas?; Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language.\",\n",
    "    \"Define Pandas?; Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language.\",\n",
    "    \"tell me something about Pandas?; Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language.\",\n",
    "    \"Can you tell me about Pandas?; Pandas is an open source, high-performance, easy-to-use data structure and data analysis library for the Python programming language.\",    \n",
    "    \"Parameters?; Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.For instance, the weights in linear and logistic regression fall under the category of parameters.\",\n",
    "    \"What is Parameters?; Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.For instance, the weights in linear and logistic regression fall under the category of parameters.\",\n",
    "    \"Define Parameters?; Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.For instance, the weights in linear and logistic regression fall under the category of parameters.\",\n",
    "    \"tell me something about Parameters?; Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.For instance, the weights in linear and logistic regression fall under the category of parameters.\",\n",
    "    \"Can you tell me about Parameters?; Parameters are a set of measurable factors that define a system. For machine learning models, model parameters are internal variables whose values can be determined from the data.For instance, the weights in linear and logistic regression fall under the category of parameters.\",    \n",
    "    \"Pattern Recognition?; Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.\",\n",
    "    \"What is Pattern Recognition?; Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.\",\n",
    "    \"Define Pattern Recognition?; Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.\",\n",
    "    \"tell me something about Pattern Recognition?; Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.\",\n",
    "    \"Can you tell me about Pattern Recognition?; Pattern recognition is a branch of machine learning that focuses on the recognition of patterns and regularities in data. Classification is an example of pattern recognition wherein each input value is assigned one of a given set of classes.\",    \n",
    "    \"Pie Chart?; A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents\",\n",
    "    \"What is Pie Chart?; A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents\",\n",
    "    \"Define Pie Chart?; A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents\",\n",
    "    \"tell me something about Pie Chart?; A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents\",\n",
    "    \"Can you tell me about Pie Chart?; A pie chart is a circular statistical graphic which is divided into slices to illustrate numerical proportion. The arc length of each slice, is proportional to the quantity it represents\",    \n",
    "    \"Pig?; Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig.\",\n",
    "    \"What is Pig?; Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig.\",\n",
    "    \"Define Pig?; Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig.\",\n",
    "    \"tell me something about Pig?; Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig.\",\n",
    "    \"Can you tell me about Pig?; Pig is a high level scripting language that is used with Apache Hadoop. Pig enables data workers to write complex data transformations without knowing Java. Pig is complete, so one can do all required data manipulations in Apache Hadoop with Pig.\",    \n",
    "    \"features of Pig?;It is able to store data at any point during a pipeline.\",\n",
    "    \"features of Pig?;It declares execution plans.\",\n",
    "    \"features of Pig?;Supports pipeline splits, thus allowing workflows to proceed along DAGs instead of strictly sequential pipelines.\",\n",
    "    \"features of Pig?;Users can create their own functions to do special-purpose processing.\",    \n",
    "    \"Polynomial Regression?; In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.\",\n",
    "    \"What is Polynomial Regression?; In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.\",\n",
    "    \"Define Polynomial Regression?; In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.\",\n",
    "    \"tell me something about Polynomial Regression?; In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.\",\n",
    "    \"Can you tell me about Polynomial Regression?; In this technique, a curve fits into the data points. In a polynomial regression equation, the power of the independent variable is greater than 1. Although higher degree polynomials give lower error, they might also result in over-fitting.\",    \n",
    "    \"Pre-trained Model?; A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\",\n",
    "    \"What is Pre-trained Model?; A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\",\n",
    "    \"Define Pre-trained Model?; A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\",\n",
    "    \"tell me something about Pre-trained Model?; A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\",\n",
    "    \"Can you tell me about Pre-trained Model?; A pre-trained model is a model created by someone else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.\",    \n",
    "    \"Precision ?; Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.It can be represented as:Precision = TP / (TP + FP)\",\n",
    "    \"What is Precision ?; Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.It can be represented as:Precision = TP / (TP + FP)\",\n",
    "    \"Define Precision ?; Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.It can be represented as:Precision = TP / (TP + FP)\",\n",
    "    \"tell me something about Precision ?; Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.It can be represented as:Precision = TP / (TP + FP)\",\n",
    "    \"Can you tell me about Precision ?; Precision can be measured as of the total actual positive cases, how many positives were predicted correctly.It can be represented as:Precision = TP / (TP + FP)\",    \n",
    "    \"Recall?; Whereas recall is described as the measured of how many of the positive predictions were correct.It can be represented as:Recall = TP / (TP + FN)\",\n",
    "    \"What is Recall?; Whereas recall is described as the measured of how many of the positive predictions were correct.It can be represented as:Recall = TP / (TP + FN)\",\n",
    "    \"Define Recall?; Whereas recall is described as the measured of how many of the positive predictions were correct.It can be represented as:Recall = TP / (TP + FN)\",\n",
    "    \"tell me something about Recall?; Whereas recall is described as the measured of how many of the positive predictions were correct.It can be represented as:Recall = TP / (TP + FN)\",\n",
    "    \"Can you tell me about Recall?; Whereas recall is described as the measured of how many of the positive predictions were correct.It can be represented as:Recall = TP / (TP + FN)\",    \n",
    "    \"Predictor Variable?;Predictor variable is used to make a prediction for dependent variables.\",\n",
    "    \"What is Predictor Variable?;Predictor variable is used to make a prediction for dependent variables.\",\n",
    "    \"Define Predictor Variable?;Predictor variable is used to make a prediction for dependent variables.\",\n",
    "    \"tell me something about Predictor Variable?;Predictor variable is used to make a prediction for dependent variables.\",\n",
    "    \"Can you tell me about Predictor Variable?;Predictor variable is used to make a prediction for dependent variables.\",    \n",
    "    \"Principal Component Analysis (PCA)?; Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\",\n",
    "    \"What is Principal Component Analysis (PCA)?; Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\",\n",
    "    \"Define Principal Component Analysis (PCA)?; Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\",\n",
    "    \"tell me something about Principal Component Analysis (PCA)?; Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\",\n",
    "    \"Can you tell me about Principal Component Analysis (PCA)?; Principal component analysis (PCA) is an approach to factor analysis that considers the total variance in the data, and transforms the original variables into a smaller set of linear combinations. PCA is sensitive to outliers; they should be removed.\",    \n",
    "    \"more about pca?; It is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables into a set of values of linearly uncorrelated variables called principal components.\",    \n",
    "    \"use of pca?; PCA is mostly used as a tool in exploratory data analysis and for making predictive models. It’s often used to visualize genetic distance and relatedness between populations.\",    \n",
    "    \"P-Value?; P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.\",\n",
    "    \"What is P-Value?; P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.\",\n",
    "    \"Define P-Value?; P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.\",\n",
    "    \"tell me something about P-Value?; P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.\",\n",
    "    \"Can you tell me about P-Value?; P-value is the value of probability of getting a result equal to or greater than the observed value, when the null hypothesis is true.\",    \n",
    "    \"Python?; Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. \",\n",
    "    \"What is Python?; Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. \",\n",
    "    \"Define Python?; Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. \",\n",
    "    \"tell me something about Python?; Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. \",\n",
    "    \"Can you tell me about Python?; Python is an open source programming language, widely used for various applications, such as general purpose programming, data science and machine learning. \",    \n",
    "    \"advantages of python?;Easy to learn.High-level language.Broadly used and supported\",    \n",
    "    \"PyTorch?; PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform.\",\n",
    "    \"What is PyTorch?; PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform.\",\n",
    "    \"Define PyTorch?; PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform.\",\n",
    "    \"tell me something about PyTorch?; PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform.\",\n",
    "    \"Can you tell me about PyTorch?; PyTorch is an open source machine learning library for python, based on Torch. It is built to provide flexibility as a deep learning development platform.\",        \n",
    "    \"use of PyTorch ?;Easy to use API,Python support,Dynamic computation graphs\",    \n",
    "    \"Quartile?; Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\",\n",
    "    \"What is Quartile?; Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\",\n",
    "    \"Define Quartile?; Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\",\n",
    "    \"tell me something about Quartile?; Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\",\n",
    "    \"Can you tell me about Quartile?; Quartile divides a series into 4 equal parts. For any series, there are 4 quartiles denoted by Q1, Q2, Q3 and Q4. These are known as First Quartile , Second Quartile and so on.\",    \n",
    "    \"R?; R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\",\n",
    "    \"What is R?; R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\",\n",
    "    \"Define R?; R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\",\n",
    "    \"tell me something about R?; R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\",\n",
    "    \"Can you tell me about R?; R is an open-source programming language and a software environment for statistical computing, machine learning, and data visualization.\",    \n",
    "    \"Features of R?; It is platform independent, so it is compatible with multiple operating systems,R has a very strong and consistent online community support, The graphical capabilities of R are awesome,There is abundance of literature to learn R\",    \n",
    "    \"Range?; Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.\",\n",
    "    \"What is Range?; Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.\",\n",
    "    \"Define Range?; Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.\",\n",
    "    \"tell me something about Range?; Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.\",\n",
    "    \"Can you tell me about Range?; Range is the difference between the highest and the lowest value of the population. It is used to measure the spread of the data.\",    \n",
    "    \"Recommendation Engine?; Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user.\",\n",
    "    \"What is Recommendation Engine?; Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user.\",\n",
    "    \"Define Recommendation Engine?; Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user.\",\n",
    "    \"tell me something about Recommendation Engine?; Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user.\",\n",
    "    \"Can you tell me about Recommendation Engine?; Recommendation engines basically are data filtering tools that make use of algorithms and data to recommend the most relevant items to a particular user.\",    \n",
    "    \"types of recommendation engines?; Content based filtering.Collaborative filtering-User-User collaborative filtering,Item-Item collaborative filtering.Hybrid recommendation systems\",    \n",
    "    \"Regression?; It is supervised learning method where the output variable is a real value, such as 'amount' or 'weight'\",\n",
    "    \"What is Regression?; It is supervised learning method where the output variable is a real value, such as 'amount' or 'weight'\",\n",
    "    \"Define Regression?; It is supervised learning method where the output variable is a real value, such as 'amount' or 'weight'\",\n",
    "    \"tell me something about Regression?; It is supervised learning method where the output variable is a real value, such as 'amount' or 'weight'\",\n",
    "    \"Can you tell me about Regression?; It is supervised learning method where the output variable is a real value, such as 'amount' or 'weight'\",    \n",
    "    \"Example of Regression?; Linear Regression, Ridge Regression, Lasso Regression\",    \n",
    "    \"Regression Spline?; Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\",\n",
    "    \"What is Regression Spline?; Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\",\n",
    "    \"Define Regression Spline?; Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\",\n",
    "    \"tell me something about Regression Spline?; Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\",\n",
    "    \"Can you tell me about Regression Spline?; Regression Splines is a non-linear approach that uses a combination of linear/polynomial functions to fit the data. In this technique, instead of building one model for the entire dataset, it is divided into multiple bins and a separate model is built on each bin.\",    \n",
    "    \"Regularization?;Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression. \",\n",
    "    \"What is Regularization?;Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression. \",\n",
    "    \"Define Regularization?;Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression. \",\n",
    "    \"tell me something about Regularization?;Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression. \",\n",
    "    \"Can you tell me about Regularization?;Regularization is a technique used to solve the overfitting problem in statistical models. In machine learning, regularization penalizes the coefficients such that the model generalize better. We have different types of regression techniques which uses regularization such as Ridge regression and lasso regression. \",    \n",
    "    \"Reinforcement Learning?;  It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance).\",\n",
    "    \"What is Reinforcement Learning?;  It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance).\",\n",
    "    \"Define Reinforcement Learning?;  It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance).\",\n",
    "    \"tell me something about Reinforcement Learning?;  It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance).\",\n",
    "    \"Can you tell me about Reinforcement Learning?;  It is an example of machine learning where the machine is trained to take specific decisions based on the business requirement with the sole motto to maximize efficiency (performance).\",    \n",
    "    \"Residual?; Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.\",\n",
    "    \"What is Residual?; Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.\",\n",
    "    \"Define Residual?; Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.\",\n",
    "    \"tell me something about Residual?; Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.\",\n",
    "    \"Can you tell me about Residual?; Residual of a value is the difference between the observed value and the predicted value of the quantity of interest. Using the residual values, you can create residual plots which are useful for understanding the model.\",    \n",
    "    \"Response Variable?; Response variable (or dependent variable) is that variable whose variation depends on other variables.\",\n",
    "    \"What is Response Variable?; Response variable (or dependent variable) is that variable whose variation depends on other variables.\",\n",
    "    \"Define Response Variable?; Response variable (or dependent variable) is that variable whose variation depends on other variables.\",\n",
    "    \"tell me something about Response Variable?; Response variable (or dependent variable) is that variable whose variation depends on other variables.\",\n",
    "    \"Can you tell me about Response Variable?; Response variable (or dependent variable) is that variable whose variation depends on other variables.\",    \n",
    "    \"Ridge Regression?; Ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\",\n",
    "    \"What is Ridge Regression?; Ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\",\n",
    "    \"Define Ridge Regression?; Ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\",\n",
    "    \"tell me something about Ridge Regression?; Ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\",\n",
    "    \"Can you tell me about Ridge Regression?; Ridge regression performs ‘L2 regularization‘, i.e. it adds a factor of sum of squares of coefficients in the optimization objective.\",    \n",
    "    \"ROC?; The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate.\",\n",
    "    \"What is ROC?; The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate.\",\n",
    "    \"Define ROC?; The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate.\",\n",
    "    \"tell me something about ROC?; The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate.\",\n",
    "    \"Can you tell me about ROC?; The ROC curve is the plot between sensitivity and (1- specificity). (1- specificity) is also known as false positive rate and sensitivity is also known as True Positive rate.\",    \n",
    "    \"Root Mean Squared Error (RMSE)?; RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are.\",\n",
    "    \"What is Root Mean Squared Error (RMSE)?; RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are.\",\n",
    "    \"Define Root Mean Squared Error (RMSE)?; RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are.\",\n",
    "    \"tell me something about Root Mean Squared Error (RMSE)?; RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are.\",\n",
    "    \"Can you tell me about Root Mean Squared Error (RMSE)?; RMSE is a measure of the differences between values predicted by a model or an estimator and the values actually observed. It is the standard deviation of the residuals. Residuals are a measure of how far from the regression line data points are.\",    \n",
    "    \"Rotational Invariance?; In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument.\",\n",
    "    \"What is Rotational Invariance?; In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument.\",\n",
    "    \"Define Rotational Invariance?; In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument.\",\n",
    "    \"tell me something about Rotational Invariance?; In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument.\",\n",
    "    \"Can you tell me about Rotational Invariance?; In mathematics, a function defined on an inner product space is said to have rotational invariance if its value does not change when arbitrary rotations are applied to its argument.\",    \n",
    "    \"Scala?; Scala is a general purpose language that combines concepts of object-oriented and functional programming languages.\",\n",
    "    \"What is Scala?; Scala is a general purpose language that combines concepts of object-oriented and functional programming languages.\",\n",
    "    \"Define Scala?; Scala is a general purpose language that combines concepts of object-oriented and functional programming languages.\",\n",
    "    \"tell me something about Scala?; Scala is a general purpose language that combines concepts of object-oriented and functional programming languages.\",\n",
    "    \"Can you tell me about Scala?; Scala is a general purpose language that combines concepts of object-oriented and functional programming languages.\",    \n",
    "    \"features of Scala?; It is an object-oriented language that supports many traditional design patterns\",\n",
    "    \"features of Scala?; It supports functional programming which enables it to handle distributed programming at fundamental level\",\n",
    "    \"features of Scala?; It is designed to run on JVM platform that helps in directly using Java libraries\",\n",
    "    \"features of Scala?; Scala can be easily implemented into existing java projects as Scala libraries can be used within Java code\",\n",
    "    \"features of Scala?; It supports first-class objects and anonymous functions\",    \n",
    "    \"Semi-Supervised Learning?; Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\",\n",
    "    \"What is Semi-Supervised Learning?; Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\",\n",
    "    \"Define Semi-Supervised Learning?; Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\",\n",
    "    \"tell me something about Semi-Supervised Learning?; Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\",\n",
    "    \"Can you tell me about Semi-Supervised Learning?; Problems where you have a large amount of input data (X) and only some of the data, is labeled (Y) are called semi-supervised learning problems.\",    \n",
    "    \"Skewness?; Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\",\n",
    "    \"What is Skewness?; Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\",\n",
    "    \"Define Skewness?; Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\",\n",
    "    \"tell me something about Skewness?; Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\",\n",
    "    \"Can you tell me about Skewness?; Skewness is a measure of symmetry. A distribution, or data set, is symmetric if it looks the same to the left and right of the center point.\",    \n",
    "    \"SMOTE?; It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described.\",\n",
    "    \"What is SMOTE?; It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described.\",\n",
    "    \"Define SMOTE?; It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described.\",\n",
    "    \"tell me something about SMOTE?; It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described.\",\n",
    "    \"Can you tell me about SMOTE?; It is a Synthetic Minority Over-Sampling Technique which is an approach to the construction of classifiers from imbalanced datasets is described.\",    \n",
    "    \"Spatial-Temporal Reasoning?; Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems.\",\n",
    "    \"What is Spatial-Temporal Reasoning?; Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems.\",\n",
    "    \"Define Spatial-Temporal Reasoning?; Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems.\",\n",
    "    \"tell me something about Spatial-Temporal Reasoning?; Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems.\",\n",
    "    \"Can you tell me about Spatial-Temporal Reasoning?; Spatial-temporal reasoning is an area of artificial intelligence which draws from the fields of computer science, cognitive science, and cognitive psychology. Spatial-temporal reasoning is the ability to mentally move objects in space and time to solve multi-step problems.\",    \n",
    "    \"Standard Deviation?; Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.\",\n",
    "    \"What is Standard Deviation?; Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.\",\n",
    "    \"Define Standard Deviation?; Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.\",\n",
    "    \"tell me something about Standard Deviation?; Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.\",\n",
    "    \"Can you tell me about Standard Deviation?; Standard deviation signifies how dispersed is the data. It is the square root of the variance of underlying data. Standard deviation is calculated for a population.\",    \n",
    "    \"Standardization?; Standardization\tStandardization (or Z-score normalization) is the process where the features are rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1, where μ is the mean (average) and σ is the standard deviation from the mean.\",\n",
    "    \"What is Standardization?; Standardization\tStandardization (or Z-score normalization) is the process where the features are rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1, where μ is the mean (average) and σ is the standard deviation from the mean.\",\n",
    "    \"Define Standardization?; Standardization\tStandardization (or Z-score normalization) is the process where the features are rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1, where μ is the mean (average) and σ is the standard deviation from the mean.\",\n",
    "    \"tell me something about Standardization?; Standardization\tStandardization (or Z-score normalization) is the process where the features are rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1, where μ is the mean (average) and σ is the standard deviation from the mean.\",\n",
    "    \"Can you tell me about Standardization?; Standardization\tStandardization (or Z-score normalization) is the process where the features are rescaled so that they’ll have the properties of a standard normal distribution with μ=0 and σ=1, where μ is the mean (average) and σ is the standard deviation from the mean.\",    \n",
    "    \"Standard error?; A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.\",\n",
    "    \"What is Standard error?; A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.\",\n",
    "    \"Define Standard error?; A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.\",\n",
    "    \"tell me something about Standard error?; A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.\",\n",
    "    \"Can you tell me about Standard error?; A standard error is the standard deviation of the sampling distribution of a statistic. The standard error is a statistical term that measures the accuracy of which a sample represents a population. In statistics, a sample mean deviates from the actual mean of a population this deviation is known as standard error.\",    \n",
    "    \"Statistics?; It is the study of the collection, analysis, interpretation, presentation, and organisation of data.\",\n",
    "    \"What is Statistics?; It is the study of the collection, analysis, interpretation, presentation, and organisation of data.\",\n",
    "    \"Define Statistics?; It is the study of the collection, analysis, interpretation, presentation, and organisation of data.\",\n",
    "    \"tell me something about Statistics?; It is the study of the collection, analysis, interpretation, presentation, and organisation of data.\",\n",
    "    \"Can you tell me about Statistics?; It is the study of the collection, analysis, interpretation, presentation, and organisation of data.\",    \n",
    "    \"Stochastic Gradient Descent?; Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\",\n",
    "    \"What is Stochastic Gradient Descent?; Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\",\n",
    "    \"Define Stochastic Gradient Descent?; Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\",\n",
    "    \"tell me something about Stochastic Gradient Descent?; Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\",\n",
    "    \"Can you tell me about Stochastic Gradient Descent?; Stochastic Gradient Descent is a type of gradient descent algorithm where we take a sample of data while computing the gradient. The update to the coefficients is performed for each training instance, rather than at the end of the batch of instances.\",    \n",
    "    \"Supervised Learning?; Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables).\",\n",
    "    \"What is Supervised Learning?; Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables).\",\n",
    "    \"Define Supervised Learning?; Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables).\",\n",
    "    \"tell me something about Supervised Learning?; Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables).\",\n",
    "    \"Can you tell me about Supervised Learning?; Supervised Learning algorithm consists of a target / outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables).\",    \n",
    "    \"SVM?; It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\",\n",
    "    \"What is SVM?; It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\",\n",
    "    \"Define SVM?; It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\",\n",
    "    \"tell me something about SVM?; It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\",\n",
    "    \"Can you tell me about SVM?; It is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is the number of features you have) with the value of each feature being the value of a particular coordinate.\",    \n",
    "    \"TensorFlow?; TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.\",\n",
    "    \"What is TensorFlow?; TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.\",\n",
    "    \"Define TensorFlow?; TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.\",\n",
    "    \"tell me something about TensorFlow?; TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.\",\n",
    "    \"Can you tell me about TensorFlow?; TensorFlow, developed by the Google Brain team, is an open source software library. It is used for building machine learning models for range of tasks in data science, mainly used for machine learning applications such as building neural networks. TensorFlow can also be used for non- machine learning tasks that require numerical computation.\",    \n",
    "    \"Tokenization?; Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.\",\n",
    "    \"What is Tokenization?; Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.\",\n",
    "    \"Define Tokenization?; Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.\",\n",
    "    \"tell me something about Tokenization?; Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.\",\n",
    "    \"Can you tell me about Tokenization?; Tokenization is the process of splitting a text string into units called tokens. The tokens may be words or a group of words. It is a crucial step in Natural Language Processing.\",    \n",
    "    \"Torch?; Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.\",\n",
    "    \"What is Torch?; Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.\",\n",
    "    \"Define Torch?; Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.\",\n",
    "    \"tell me something about Torch?; Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.\",\n",
    "    \"Can you tell me about Torch?; Torch is an open source machine learning library, based on the Lua programming language. It provides a wide range of algorithms for deep learning.\",    \n",
    "    \"Transfer Learning?; Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\",\n",
    "    \"What is Transfer Learning?; Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\",\n",
    "    \"Define Transfer Learning?; Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\",\n",
    "    \"tell me something about Transfer Learning?; Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\",\n",
    "    \"Can you tell me about Transfer Learning?; Transfer learning refers to applying a pre-trained model on a new dataset. A pre-trained model is a model created by someone to solve a problem. This model can be applied to solve a similar problem with similar data.\",    \n",
    "    \"True Negative?; These are the points which are actually false and we have predicted them false\",\n",
    "    \"What is True Negative?; These are the points which are actually false and we have predicted them false\",\n",
    "    \"Define True Negative?; These are the points which are actually false and we have predicted them false\",\n",
    "    \"tell me something about True Negative?; These are the points which are actually false and we have predicted them false\",\n",
    "    \"Can you tell me about True Negative?; These are the points which are actually false and we have predicted them false\",    \n",
    "    \"True Positive?; These are the points which are actually true and we have predicted them true.\",\n",
    "    \"What is True Positive?; These are the points which are actually true and we have predicted them true.\",\n",
    "    \"Define True Positive?; These are the points which are actually true and we have predicted them true.\",\n",
    "    \"tell me something about True Positive?; These are the points which are actually true and we have predicted them true.\",\n",
    "    \"Can you tell me about True Positive?; These are the points which are actually true and we have predicted them true.\",    \n",
    "    \"Type I error?;The decision to reject the null hypothesis could be incorrect, it is known as Type I error.\",\n",
    "    \"What is Type I error?;The decision to reject the null hypothesis could be incorrect, it is known as Type I error.\",\n",
    "    \"Define Type I error?;The decision to reject the null hypothesis could be incorrect, it is known as Type I error.\",\n",
    "    \"tell me something about Type I error?;The decision to reject the null hypothesis could be incorrect, it is known as Type I error.\",\n",
    "    \"Can you tell me about Type I error?;The decision to reject the null hypothesis could be incorrect, it is known as Type I error.\",    \n",
    "    \"Type II error?;The decision to retain the null hypothesis could be incorrect, it is know as Type II error.\",\n",
    "    \"What is Type II error?;The decision to retain the null hypothesis could be incorrect, it is know as Type II error.\",\n",
    "    \"Define Type II error?;The decision to retain the null hypothesis could be incorrect, it is know as Type II error.\",\n",
    "    \"tell me something about Type II error?;The decision to retain the null hypothesis could be incorrect, it is know as Type II error.\",\n",
    "    \"Can you tell me about Type II error?;The decision to retain the null hypothesis could be incorrect, it is know as Type II error.\",    \n",
    "    \"T-Test?; T-test is used to compare two population by finding the difference of their population means\",\n",
    "    \"What is T-Test?; T-test is used to compare two population by finding the difference of their population means\",\n",
    "    \"Define T-Test?; T-test is used to compare two population by finding the difference of their population means\",\n",
    "    \"tell me something about T-Test?; T-test is used to compare two population by finding the difference of their population means\",\n",
    "    \"Can you tell me about T-Test?; T-test is used to compare two population by finding the difference of their population means\",    \n",
    "    \"Underfitting?; Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data.\",\n",
    "    \"What is Underfitting?; Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data.\",\n",
    "    \"Define Underfitting?; Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data.\",\n",
    "    \"tell me something about Underfitting?; Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data.\",\n",
    "    \"Can you tell me about Underfitting?; Underfitting occurs when a statistical model or machine learning algorithm cannot capture the underlying trend of the data. It refers to a model that can neither model on the training data nor generalize to new data.\",    \n",
    "    \"Univariate Analysis?; Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable\",\n",
    "    \"What is Univariate Analysis?; Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable\",\n",
    "    \"Define Univariate Analysis?; Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable\",\n",
    "    \"tell me something about Univariate Analysis?; Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable\",\n",
    "    \"Can you tell me about Univariate Analysis?; Univariate analysis is comparing and analyzing the dependency of a single predictor and a response variable\",    \n",
    "    \"Unsupervised Learning?; In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes\",\n",
    "    \"What is Unsupervised Learning?; In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes\",\n",
    "    \"Define Unsupervised Learning?; In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes\",\n",
    "    \"tell me something about Unsupervised Learning?; In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes\",\n",
    "    \"Can you tell me about Unsupervised Learning?; In Unsupervised Learning algorithm, we do not have any target or outcome variable to predict/estimate. The goal of unsupervised learning is to model the underlying structure or distribution in the data in order to learn more about the data or segment into different groups based on their attributes\",    \n",
    "    \"Variance?; Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\",\n",
    "    \"What is Variance?; Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\",\n",
    "    \"Define Variance?; Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\",\n",
    "    \"tell me something about Variance?; Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\",\n",
    "    \"Can you tell me about Variance?; Variance is used to measure the spread of given set of numbers and calculated by the average of squared distances from the mean\",   \n",
    "    \"Z-test?; Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation.\",\n",
    "    \"What is Z-test?; Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation.\",\n",
    "    \"Define Z-test?; Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation.\",\n",
    "    \"tell me something about Z-test?; Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation.\",\n",
    "    \"Can you tell me about Z-test?; Z-test determines to what extent a data point is away from the mean of the data set, in standard deviation.\",\n",
    "    \"Zookeeper?;ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\",\n",
    "    \"What is Zookeeper?;ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\",\n",
    "    \"Define Zookeeper?;ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\",\n",
    "    \"tell me something about Zookeeper?;ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\",\n",
    "    \"Can you tell me about Zookeeper?;ZooKeeper is a software project of the Apache Software Foundation. It is an open source file application program interface (API) that allows distributed processes in large systems to synchronize with each other so that all clients making requests receive consistent data.\",    \n",
    "    \"What is activation function?; A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.\",\n",
    "    \"Define activation function?; A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.\",\n",
    "    \"activation function?; A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.\",\n",
    "    \"tell me something about activation function?; A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.\",\n",
    "    \"Can you tell me about activation function?; A function (for example, ReLU or sigmoid) that takes in the weighted sum of all of the inputs from the previous layer and then generates and passes an output value (typically nonlinear) to the next layer.\",    \n",
    "    \"AdaGrad?; A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate.\",\n",
    "    \"What is AdaGrad?; A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate.\",\n",
    "    \"Define AdaGrad?; A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate.\",\n",
    "    \"tell me something about AdaGrad?; A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate.\",\n",
    "    \"Can you tell me about AdaGrad?; A sophisticated gradient descent algorithm that rescales the gradients of each parameter, effectively giving each parameter an independent learning rate.\",    \n",
    "    \"AUC (Area under the ROC Curve)?; An evaluation metric that considers all possible classification thresholds.\",    \n",
    "    \"AUC?; The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.\",\n",
    "    \"What is AUC?; The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.\",\n",
    "    \"Define AUC?; The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.\",   \n",
    "    \"tell me something about AUC?; The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.\",\n",
    "    \"Can you tell me about AUC?; The Area Under the ROC curve is the probability that a classifier will be more confident that a randomly chosen positive example is actually positive than that a randomly chosen negative example is positive.\",\n",
    "    \"batch?; The set of examples used in one iteration (that is, one gradient update) of model training.\",\n",
    "    \"What is batch?; The set of examples used in one iteration (that is, one gradient update) of model training.\",\n",
    "    \"Define batch?; The set of examples used in one iteration (that is, one gradient update) of model training.\",\n",
    "    \"tell me something about batch?; The set of examples used in one iteration (that is, one gradient update) of model training.\",\n",
    "    \"Can you tell me about batch?; The set of examples used in one iteration (that is, one gradient update) of model training.\",\n",
    "    \"batch size?; The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference: however, TensorFlow does permit dynamic batch sizes.\",\n",
    "    \"What is batch size?; The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference: however, TensorFlow does permit dynamic batch sizes.\",\n",
    "    \"Define batch size?; The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference: however, TensorFlow does permit dynamic batch sizes.\",\n",
    "    \"tell me something about batch size?; The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference: however, TensorFlow does permit dynamic batch sizes.\",\n",
    "    \"Can you tell me about batch size?; The number of examples in a batch. For example, the batch size of SGD is 1, while the batch size of a mini-batch is usually between 10 and 1000. Batch size is usually fixed during training and inference: however, TensorFlow does permit dynamic batch sizes.\",\n",
    "    \"centroid?; The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.\",\n",
    "    \"What is centroid?; The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.\",\n",
    "    \"Define centroid?; The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.\",\n",
    "    \"tell me something about centroid?; The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.\",\n",
    "    \"Can you tell me about centroid?; The center of a cluster as determined by a k-means or k-median algorithm. For instance, if k is 3, then the k-means or k-median algorithm finds 3 centroids.\",\n",
    "    \"dropout regularization?; A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization.\",\n",
    "    \"What is dropout regularization?; A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization.\",\n",
    "    \"Define dropout regularization?; A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization.\",\n",
    "    \"Can you tell me about dropout regularization?; A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization.\",\n",
    "    \"tell me something about dropout regularization?; A form of regularization useful in training neural networks. Dropout regularization works by removing a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization.\",\n",
    "    \"dynamic model?;A model that is trained online in a continuously updating fashion. That is, data is continuously entering the model.\",\n",
    "    \"epoch?; A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\",\n",
    "    \"What is epoch?; A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\",\n",
    "    \"Define epoch?; A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\",\n",
    "    \"tell me something about epoch?; A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\",\n",
    "    \"Can you tell me about epoch?; A full training pass over the entire data set such that each example has been seen once. Thus, an epoch represents N/batch size training iterations, where N is the total number of examples.\",\n",
    "    \"generalization?; generalization refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.\",\n",
    "    \"What is generalization?; generalization refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.\",\n",
    "    \"Define generalization?; generalization refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.\",\n",
    "    \"tell me something about generalization?; generalization refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.\",\n",
    "    \"Can you tell me about generalization?; generalization refers to your model's ability to make correct predictions on new, previously unseen data as opposed to the data used to train the model.\",\n",
    "    \"gradient?;The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.\",\n",
    "    \"What is gradient?;The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.\",\n",
    "    \"Define gradient?;The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.\",\n",
    "    \"Can you tell me about gradient?;The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.\",\n",
    "    \"tell me something about gradient?;The vector of partial derivatives with respect to all of the independent variables. In machine learning, the gradient is the vector of partial derivatives of the model function. The gradient points in the direction of steepest ascent.\",\n",
    "    \"gradient descent?; A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\",\n",
    "    \"What is gradient descent?; A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\",\n",
    "    \"Define gradient descent?; A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\",\n",
    "    \"Can you tell me about gradient descent?; A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\",\n",
    "    \"tell me something about gradient descent?; A technique to minimize loss by computing the gradients of loss with respect to the model's parameters, conditioned on training data. Informally, gradient descent iteratively adjusts parameters, gradually finding the best combination of weights and bias to minimize loss.\",\n",
    "    \"hidden layer?;A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.\",\n",
    "    \"What is hidden layer?;A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.\",\n",
    "    \"Define hidden layer?;A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.\",\n",
    "    \"Can you tell me about hidden layer?;A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.\",\n",
    "    \"tell me something about hidden layer?;A synthetic layer in a neural network between the input layer (that is, the features) and the output layer (the prediction). A neural network contains one or more hidden layers.\",\n",
    "    \"Keras?;A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.\",\n",
    "    \"What is Keras?;A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.\",\n",
    "    \"Define Keras?;A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.\",\n",
    "    \"Can you tell me about Keras?;A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.\",\n",
    "    \"tell me something about Keras?;A popular Python machine learning API. Keras runs on several deep learning frameworks, including TensorFlow, where it is made available as tf.keras.\",\n",
    "    \"learning rate?;A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.Learning rate is a key hyperparameter.\",\n",
    "    \"What is learning rate?;A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.Learning rate is a key hyperparameter.\",\n",
    "    \"Define learning rate?;A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.Learning rate is a key hyperparameter.\",\n",
    "    \"Can you tell me about learning rate?;A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.Learning rate is a key hyperparameter.\",\n",
    "    \"tell me something about learning rate?;A scalar used to train a model via gradient descent. During each iteration, the gradient descent algorithm multiplies the learning rate by the gradient. The resulting product is called the gradient step.Learning rate is a key hyperparameter.\",\n",
    "    \"least squares regression?;A linear regression model trained by minimizing L2 Loss.\",\n",
    "    \"What is least squares regression?;A linear regression model trained by minimizing L2 Loss.\",\n",
    "    \"Define least squares regression?;A linear regression model trained by minimizing L2 Loss.\",\n",
    "    \"Can you tell me about least squares regression?;A linear regression model trained by minimizing L2 Loss.\",\n",
    "    \"tell me something about least squares regression?;A linear regression model trained by minimizing L2 Loss.\",\n",
    "    \"linear regression?;A type of regression model that outputs a continuous value from a linear combination of input features.\",\n",
    "    \"What is linear regression?;A type of regression model that outputs a continuous value from a linear combination of input features.\",\n",
    "    \"Define linear regression?;A type of regression model that outputs a continuous value from a linear combination of input features.\",\n",
    "    \"tell me something about linear regression?;A type of regression model that outputs a continuous value from a linear combination of input features.\",\n",
    "    \"Can you tell me about linear regression?;A type of regression model that outputs a continuous value from a linear combination of input features.\",\n",
    "    \"logistic regression?;A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction.\",\n",
    "    \"What is logistic regression?;A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction.\",\n",
    "    \"Define logistic regression?;A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction.\",\n",
    "    \"tell me something about logistic regression?;A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction.\",\n",
    "    \"Can you tell me about logistic regression?;A model that generates a probability for each possible discrete label value in classification problems by applying a sigmoid function to a linear prediction.\",\n",
    "    \"mini-batch?;A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference.\",\n",
    "    \"What is mini-batch?;A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference.\",\n",
    "    \"Define mini-batch?;A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference.\",\n",
    "    \"tell me something about mini-batch?;A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference.\",\n",
    "    \"Can you tell me about mini-batch?;A small, randomly selected subset of the entire batch of examples run together in a single iteration of training or inference.\",\n",
    "    \"mini-batch stochastic gradient descent (SGD)?;A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data.\",\n",
    "    \"What is mini-batch stochastic gradient descent (SGD)?;A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data.\",\n",
    "    \"Define mini-batch stochastic gradient descent (SGD)?;A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data.\",\n",
    "    \"tell me something about mini-batch stochastic gradient descent (SGD)?;A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data.\",\n",
    "    \"Can you tell me about mini-batch stochastic gradient descent (SGD)?;A gradient descent algorithm that uses mini-batches. In other words, mini-batch SGD estimates the gradient based on a small subset of the training data.\",\n",
    "    \"pooling?;Reducing a matrix (or matrices) created by an earlier convolutional layer to a smaller matrix. Pooling usually involves taking either the maximum or average value across the pooled area.\",\n",
    "    \"What is pooling?;Reducing a matrix (or matrices) created by an earlier convolutional layer to a smaller matrix. Pooling usually involves taking either the maximum or average value across the pooled area.\",\n",
    "    \"Define pooling?;Reducing a matrix (or matrices) created by an earlier convolutional layer to a smaller matrix. Pooling usually involves taking either the maximum or average value across the pooled area.\",\n",
    "    \"tell me something about pooling?;Reducing a matrix (or matrices) created by an earlier convolutional layer to a smaller matrix. Pooling usually involves taking either the maximum or average value across the pooled area.\",\n",
    "    \"Can you tell me about pooling?;Reducing a matrix (or matrices) created by an earlier convolutional layer to a smaller matrix. Pooling usually involves taking either the maximum or average value across the pooled area.\",\n",
    "    \"scikit-learn?;A popular open-source ML platform. See www.scikit-learn.org.\",\n",
    "    \"stride?;In a convolutional operation or pooling, the delta in each dimension of the next series of input slices. \",\n",
    "    \"What is stride?;In a convolutional operation or pooling, the delta in each dimension of the next series of input slices. \",\n",
    "    \"Define stride?;In a convolutional operation or pooling, the delta in each dimension of the next series of input slices. \",\n",
    "    \"Can you tell me about stride?;In a convolutional operation or pooling, the delta in each dimension of the next series of input slices. \",\n",
    "    \"tell me something about stride?;In a convolutional operation or pooling, the delta in each dimension of the next series of input slices. \",\n",
    "    \"Natural Language Processing (NLP)?;Natural language processing (NLP) concerns itself with the interaction between natural human languages and computing devices.\",\n",
    "    \"What is Natural Language Processing (NLP)?;Natural language processing (NLP) concerns itself with the interaction between natural human languages and computing devices.\",\n",
    "    \"Define Natural Language Processing (NLP)?;Natural language processing (NLP) concerns itself with the interaction between natural human languages and computing devices.\",\n",
    "    \"Can you tell me about Natural Language Processing (NLP)?;Natural language processing (NLP) concerns itself with the interaction between natural human languages and computing devices.\",\n",
    "    \"tell me something about Natural Language Processing (NLP)?;Natural language processing (NLP) concerns itself with the interaction between natural human languages and computing devices.\",\n",
    "    \"Tokenization?;Tokenization is, generally, an early step in the NLP process, a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.\",\n",
    "    \"What is Tokenization?;Tokenization is, generally, an early step in the NLP process, a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.\",\n",
    "    \"Define Tokenization?;Tokenization is, generally, an early step in the NLP process, a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.\",\n",
    "    \"Can you tell me about Tokenization?;Tokenization is, generally, an early step in the NLP process, a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.\",\n",
    "    \"tell me something about Tokenization?;Tokenization is, generally, an early step in the NLP process, a step which splits longer strings of text into smaller pieces, or tokens. Larger chunks of text can be tokenized into sentences, sentences can be tokenized into words, etc.\",\n",
    "    \"Normalization?;Before further processing, text needs to be normalized. Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, expanding contractions, converting numbers to their word equivalents, and so on.\",\n",
    "    \"What is Normalization?;Before further processing, text needs to be normalized. Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, expanding contractions, converting numbers to their word equivalents, and so on.\",\n",
    "    \"Define Normalization?;Before further processing, text needs to be normalized. Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, expanding contractions, converting numbers to their word equivalents, and so on.\",\n",
    "    \"Can you tell me about Normalization?;Before further processing, text needs to be normalized. Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, expanding contractions, converting numbers to their word equivalents, and so on.\",\n",
    "    \"tell me something about Normalization?;Before further processing, text needs to be normalized. Normalization generally refers to a series of related tasks meant to put all text on a level playing field: converting all text to the same case (upper or lower), removing punctuation, expanding contractions, converting numbers to their word equivalents, and so on.\",\n",
    "    \"Stemming?;Stemming is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.running → run\",\n",
    "    \"What is Stemming?;Stemming is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.running → run\",\n",
    "    \"Define Stemming?;Stemming is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.running → run\",\n",
    "    \"Can you tell me about Stemming?;Stemming is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.running → run\",\n",
    "    \"tell me something about Stemming?;Stemming is the process of eliminating affixes (suffixed, prefixes, infixes, circumfixes) from a word in order to obtain a word stem.running → run\",\n",
    "    \"Lemmatization?;Lemmatization is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.For example, stemming the word 'better' would fail to return its citation form (another word for lemma) however, lemmatization would result in the following:better → good\",\n",
    "    \"What is Lemmatization?;Lemmatization is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.For example, stemming the word 'better' would fail to return its citation form (another word for lemma) however, lemmatization would result in the following:better → good\",\n",
    "    \"Define Lemmatization?;Lemmatization is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.For example, stemming the word 'better' would fail to return its citation form (another word for lemma) however, lemmatization would result in the following:better → good\",\n",
    "    \"Can you tell me about Lemmatization?;Lemmatization is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.For example, stemming the word 'better' would fail to return its citation form (another word for lemma) however, lemmatization would result in the following:better → good\",\n",
    "    \"tell me something about Lemmatization?;Lemmatization is related to stemming, differing in that lemmatization is able to capture canonical forms based on a word's lemma.For example, stemming the word 'better' would fail to return its citation form (another word for lemma) however, lemmatization would result in the following:better → good\",\n",
    "    \"Corpus?;In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts. Such collections may be formed of a single language of texts, or can span multiple languages -- there are numerous reasons for which multilingual corpora (the plural of corpus) may be useful.\",\n",
    "    \"What is Corpus?;In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts. Such collections may be formed of a single language of texts, or can span multiple languages -- there are numerous reasons for which multilingual corpora (the plural of corpus) may be useful.\",\n",
    "    \"Define Corpus?;In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts. Such collections may be formed of a single language of texts, or can span multiple languages -- there are numerous reasons for which multilingual corpora (the plural of corpus) may be useful.\",\n",
    "    \"tell me something about Corpus?;In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts. Such collections may be formed of a single language of texts, or can span multiple languages -- there are numerous reasons for which multilingual corpora (the plural of corpus) may be useful.\",\n",
    "    \"Can you tell me about Corpus?;In linguistics and NLP, corpus (literally Latin for body) refers to a collection of texts. Such collections may be formed of a single language of texts, or can span multiple languages -- there are numerous reasons for which multilingual corpora (the plural of corpus) may be useful.\",\n",
    "    \"Stop Words?;Stop words are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, 'the,' 'and,' and 'a,' while all required words in a particular passage, don't generally contribute greatly to one's understanding of content.\",\n",
    "    \"What is Stop Words?;Stop words are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, 'the,' 'and,' and 'a,' while all required words in a particular passage, don't generally contribute greatly to one's understanding of content.\",\n",
    "    \"Define Stop Words?;Stop words are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, 'the,' 'and,' and 'a,' while all required words in a particular passage, don't generally contribute greatly to one's understanding of content.\",\n",
    "    \"tell me something about Stop Words?;Stop words are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, 'the,' 'and,' and 'a,' while all required words in a particular passage, don't generally contribute greatly to one's understanding of content.\",\n",
    "    \"Can you tell me about Stop Words?;Stop words are those words which are filtered out before further processing of text, since these words contribute little to overall meaning, given that they are generally the most common words in a language. For instance, 'the,' 'and,' and 'a,' while all required words in a particular passage, don't generally contribute greatly to one's understanding of content.\",\n",
    "    \"Parts-of-speech (POS) Tagging?;POS tagging consists of assigning a category tag to the tokenized parts of a sentence. The most popular POS tagging would be identifying words as nouns, verbs, adjectives, etc.\",\n",
    "    \"What is Parts-of-speech (POS) Tagging?;POS tagging consists of assigning a category tag to the tokenized parts of a sentence. The most popular POS tagging would be identifying words as nouns, verbs, adjectives, etc.\",\n",
    "    \"Define Parts-of-speech (POS) Tagging?;POS tagging consists of assigning a category tag to the tokenized parts of a sentence. The most popular POS tagging would be identifying words as nouns, verbs, adjectives, etc.\",\n",
    "    \"tell me something about Parts-of-speech (POS) Tagging?;POS tagging consists of assigning a category tag to the tokenized parts of a sentence. The most popular POS tagging would be identifying words as nouns, verbs, adjectives, etc.\",\n",
    "    \"Can you tell me about Parts-of-speech (POS) Tagging?;POS tagging consists of assigning a category tag to the tokenized parts of a sentence. The most popular POS tagging would be identifying words as nouns, verbs, adjectives, etc.\",\n",
    "    \"Statistical Language Modeling?;Statistical Language Modeling is the process of building a statistical language model which is meant to provide an estimate of a natural language. For a sequence of input words, the model would assign a probability to the entire sequence, which contributes to the estimated likelihood of various possible sequences.\",\n",
    "    \"What is Statistical Language Modeling?;Statistical Language Modeling is the process of building a statistical language model which is meant to provide an estimate of a natural language. For a sequence of input words, the model would assign a probability to the entire sequence, which contributes to the estimated likelihood of various possible sequences.\",\n",
    "    \"Define Statistical Language Modeling?;Statistical Language Modeling is the process of building a statistical language model which is meant to provide an estimate of a natural language. For a sequence of input words, the model would assign a probability to the entire sequence, which contributes to the estimated likelihood of various possible sequences.\",\n",
    "    \"Can you tell me about Statistical Language Modeling?;Statistical Language Modeling is the process of building a statistical language model which is meant to provide an estimate of a natural language. For a sequence of input words, the model would assign a probability to the entire sequence, which contributes to the estimated likelihood of various possible sequences.\",\n",
    "    \"tell me something about Statistical Language Modeling?;Statistical Language Modeling is the process of building a statistical language model which is meant to provide an estimate of a natural language. For a sequence of input words, the model would assign a probability to the entire sequence, which contributes to the estimated likelihood of various possible sequences.\",\n",
    "    \"Bag of Words?;Bag of words is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text.\",\n",
    "    \"What is Bag of Words?;Bag of words is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text.\",\n",
    "    \"Define Bag of Words?;Bag of words is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text.\",\n",
    "    \"Can you tell me about Bag of Words?;Bag of words is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text.\",\n",
    "    \"tell me something about Bag of Words?;Bag of words is a particular representation model used to simplify the contents of a selection of text. The bag of words model omits grammar and word order, but is interested in the number of occurrences of words within the text.\",\n",
    "    \"n-grams?;n-grams is another representation model for simplifying text selection contents. As opposed to the orderless representation of bag of words, n-grams modeling is interested in preserving contiguous sequences of N items from the text selection.\",\n",
    "    \"What is n-grams?;n-grams is another representation model for simplifying text selection contents. As opposed to the orderless representation of bag of words, n-grams modeling is interested in preserving contiguous sequences of N items from the text selection.\",\n",
    "    \"Define n-grams?;n-grams is another representation model for simplifying text selection contents. As opposed to the orderless representation of bag of words, n-grams modeling is interested in preserving contiguous sequences of N items from the text selection.\",\n",
    "    \"Can you tell me about n-grams?;n-grams is another representation model for simplifying text selection contents. As opposed to the orderless representation of bag of words, n-grams modeling is interested in preserving contiguous sequences of N items from the text selection.\",\n",
    "    \"tell me something about n-grams?;n-grams is another representation model for simplifying text selection contents. As opposed to the orderless representation of bag of words, n-grams modeling is interested in preserving contiguous sequences of N items from the text selection.\",\n",
    "    \"Regular Expressions?;Regular expressions, often abbreviated regexp or regexp, are a tried and true method of concisely describing patterns of text. A regular expression is represented as a special text string itself, and is meant for developing search patterns on selections of text. Regular expressions can be thought of as an expanded set of rules beyond the wildcard characters of ? and .\",\n",
    "    \"What is Regular Expressions?;Regular expressions, often abbreviated regexp or regexp, are a tried and true method of concisely describing patterns of text. A regular expression is represented as a special text string itself, and is meant for developing search patterns on selections of text. Regular expressions can be thought of as an expanded set of rules beyond the wildcard characters of ? and *.\",\n",
    "    \"Define Regular Expressions?;Regular expressions, often abbreviated regexp or regexp, are a tried and true method of concisely describing patterns of text. A regular expression is represented as a special text string itself, and is meant for developing search patterns on selections of text. Regular expressions can be thought of as an expanded set of rules beyond the wildcard characters of ? and *.\",\n",
    "    \"Can you tell me about Regular Expressions?;Regular expressions, often abbreviated regexp or regexp, are a tried and true method of concisely describing patterns of text. A regular expression is represented as a special text string itself, and is meant for developing search patterns on selections of text. Regular expressions can be thought of as an expanded set of rules beyond the wildcard characters of ? and *.\",\n",
    "    \"tell me something about Regular Expressions?;Regular expressions, often abbreviated regexp or regexp, are a tried and true method of concisely describing patterns of text. A regular expression is represented as a special text string itself, and is meant for developing search patterns on selections of text. Regular expressions can be thought of as an expanded set of rules beyond the wildcard characters of ? and *.\",\n",
    "    \"Zipf's Law?;Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\",\n",
    "    \"What is Zipf's Law?;Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\",\n",
    "    \"Define Zipf's Law?;Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\",\n",
    "    \"Can you tell me about Zipf's Law?;Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\",\n",
    "    \"tell me something about Zipf's Law?;Zipf's law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table. Thus the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, etc.\",\n",
    "    \"Artificial Intelligence?; Computer programs designed to solve difficult problems which humans (and animals) routinely solve. In a nutshell, is to enable computers to think and learn-by-itself through feeding of good data.\",\n",
    "    \"What is Artificial Intelligence?; Computer programs designed to solve difficult problems which humans (and animals) routinely solve. In a nutshell, is to enable computers to think and learn-by-itself through feeding of good data.\",\n",
    "    \"Define Artificial Intelligence?; Computer programs designed to solve difficult problems which humans (and animals) routinely solve. In a nutshell, is to enable computers to think and learn-by-itself through feeding of good data.\",\n",
    "    \"Can you tell me about Artificial Intelligence?; Computer programs designed to solve difficult problems which humans (and animals) routinely solve. In a nutshell, is to enable computers to think and learn-by-itself through feeding of good data.\",\n",
    "    \"tell me something about Artificial Intelligence?; Computer programs designed to solve difficult problems which humans (and animals) routinely solve. In a nutshell, is to enable computers to think and learn-by-itself through feeding of good data.\",\n",
    "    \"Bayesian network?; A type of probabilistic graphical models built from data and/or expert opinion. They are graphs explaining the chances of one thing happening depend on the chances that another thing happened.\",\n",
    "    \"What is Bayesian network?; A type of probabilistic graphical models built from data and/or expert opinion. They are graphs explaining the chances of one thing happening depend on the chances that another thing happened.\",\n",
    "    \"Define Bayesian network?; A type of probabilistic graphical models built from data and/or expert opinion. They are graphs explaining the chances of one thing happening depend on the chances that another thing happened.\",\n",
    "    \"tell me something about Bayesian network?; A type of probabilistic graphical models built from data and/or expert opinion. They are graphs explaining the chances of one thing happening depend on the chances that another thing happened.\",\n",
    "    \"Can you tell me about Bayesian network?; A type of probabilistic graphical models built from data and/or expert opinion. They are graphs explaining the chances of one thing happening depend on the chances that another thing happened.\",\n",
    "    \"use of Bayesian network?;They can be used for a wide range of tasks including prediction, anomaly detection, diagnostics, automated insight, reasoning, time series prediction and decision making under uncertainty.\",\n",
    "    \"Computer Vision – Is a field of Artificial Intelligence and Image processing that train machines to see the surroundings, understand and make better decisions.\",\n",
    "    \"What is Computer Vision – Is a field of Artificial Intelligence and Image processing that train machines to see the surroundings, understand and make better decisions.\",\n",
    "    \"Define Computer Vision – Is a field of Artificial Intelligence and Image processing that train machines to see the surroundings, understand and make better decisions.\",\n",
    "    \"tell me something about Computer Vision – Is a field of Artificial Intelligence and Image processing that train machines to see the surroundings, understand and make better decisions.\",\n",
    "    \"Can you tell me about Computer Vision – Is a field of Artificial Intelligence and Image processing that train machines to see the surroundings, understand and make better decisions.\",\n",
    "    \"Data Mining?; The process of combing through a data set to identify patterns and extract information. Often such patterns and information are only clear when a large enough dataset is analyzed.\",\n",
    "    \"What is Data Mining?; The process of combing through a data set to identify patterns and extract information. Often such patterns and information are only clear when a large enough dataset is analyzed.\",\n",
    "    \"Define Data Mining?; The process of combing through a data set to identify patterns and extract information. Often such patterns and information are only clear when a large enough dataset is analyzed.\",\n",
    "    \"Can you tell me about Data Mining?; The process of combing through a data set to identify patterns and extract information. Often such patterns and information are only clear when a large enough dataset is analyzed.\",\n",
    "    \"tell me something about Data Mining?; The process of combing through a data set to identify patterns and extract information. Often such patterns and information are only clear when a large enough dataset is analyzed.\",\n",
    "    \"Deep Learning?;Family of machine learning methods based on neural networks (models inspired by the human brain) which can be used for different applications.\",\n",
    "    \"What is Deep Learning?;Family of machine learning methods based on neural networks (models inspired by the human brain) which can be used for different applications.\",\n",
    "    \"Define Deep Learning?;Family of machine learning methods based on neural networks (models inspired by the human brain) which can be used for different applications.\",\n",
    "    \"Can you tell me about Deep Learning?;Family of machine learning methods based on neural networks (models inspired by the human brain) which can be used for different applications.\",\n",
    "    \"tell me something about Deep Learning?;Family of machine learning methods based on neural networks (models inspired by the human brain) which can be used for different applications.\",\n",
    "    \"Machine Learning?; A subset of AI in which computer programs and algorithms can be designed to “learn” how to complete a specified task, with increasing efficiency and effectiveness as it develops. Such programs can use past performance data to predict and improve future performance.\",\n",
    "    \"What is Machine Learning?; A subset of AI in which computer programs and algorithms can be designed to “learn” how to complete a specified task, with increasing efficiency and effectiveness as it develops. Such programs can use past performance data to predict and improve future performance.\",\n",
    "    \"Define Machine Learning?; A subset of AI in which computer programs and algorithms can be designed to “learn” how to complete a specified task, with increasing efficiency and effectiveness as it develops. Such programs can use past performance data to predict and improve future performance.\",\n",
    "    \"Can you tell me about Machine Learning?; A subset of AI in which computer programs and algorithms can be designed to “learn” how to complete a specified task, with increasing efficiency and effectiveness as it develops. Such programs can use past performance data to predict and improve future performance.\",\n",
    "    \"tell me something about Machine Learning?; A subset of AI in which computer programs and algorithms can be designed to “learn” how to complete a specified task, with increasing efficiency and effectiveness as it develops. Such programs can use past performance data to predict and improve future performance.\",\n",
    "    \"Natural language processing?;A machine learning task concerned with improving the interaction between humans and computers. This field of study focuses on helping machines to better understand human language in order to improve human-computer interfaces.\",\n",
    "    \"What is Natural language processing?;A machine learning task concerned with improving the interaction between humans and computers. This field of study focuses on helping machines to better understand human language in order to improve human-computer interfaces.\",\n",
    "    \"Define Natural language processing?;A machine learning task concerned with improving the interaction between humans and computers. This field of study focuses on helping machines to better understand human language in order to improve human-computer interfaces.\",\n",
    "    \"tell me something about Natural language processing?;A machine learning task concerned with improving the interaction between humans and computers. This field of study focuses on helping machines to better understand human language in order to improve human-computer interfaces.\",\n",
    "    \"Can you tell me about Natural language processing?;A machine learning task concerned with improving the interaction between humans and computers. This field of study focuses on helping machines to better understand human language in order to improve human-computer interfaces.\",\n",
    "    \"Perception?; is a process of acquiring, interpreting, selecting, and organizing sensory information. It is what you perceive, which may be true or false, as opposed to the ground truth which is always true.\",\n",
    "    \"What is Perception?; is a process of acquiring, interpreting, selecting, and organizing sensory information. It is what you perceive, which may be true or false, as opposed to the ground truth which is always true.\",\n",
    "    \"Define Perception?; is a process of acquiring, interpreting, selecting, and organizing sensory information. It is what you perceive, which may be true or false, as opposed to the ground truth which is always true.\",\n",
    "    \"tell me something about Perception?; is a process of acquiring, interpreting, selecting, and organizing sensory information. It is what you perceive, which may be true or false, as opposed to the ground truth which is always true.\",\n",
    "    \"Can you tell me about Perception?; is a process of acquiring, interpreting, selecting, and organizing sensory information. It is what you perceive, which may be true or false, as opposed to the ground truth which is always true.\",\n",
    "    \"Supervised learning algorithms?;A type of machine learning in which human input and supervision are an integral part of the machine learning process on an ongoing basis.\",\n",
    "    \"What is Supervised learning algorithms?;A type of machine learning in which human input and supervision are an integral part of the machine learning process on an ongoing basis.\",\n",
    "    \"Define Supervised learning algorithms?;A type of machine learning in which human input and supervision are an integral part of the machine learning process on an ongoing basis.\",\n",
    "    \"tell me something about Supervised learning algorithms?;A type of machine learning in which human input and supervision are an integral part of the machine learning process on an ongoing basis.\",\n",
    "    \"Can you tell me about Supervised learning algorithms?;A type of machine learning in which human input and supervision are an integral part of the machine learning process on an ongoing basis.\",\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines=[      \"Tell me something about R?; R- The best part about R is that it is an Open Source tool and hence used generously by academia and the research community. It is a robust tool for statistical computation, graphical representation and reporting. Due to its open source nature it is always being updated with the latest features and then readily available to everybody.\"\n",
    "    \"What is R?; R- The best part about R is that it is an Open Source tool and hence used generously by academia and the research community. It is a robust tool for statistical computation, graphical representation and reporting. Due to its open source nature it is always being updated with the latest features and then readily available to everybody.\",\n",
    "    \"What is Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Do you know about Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Do you know Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"Tell me something about Python?; Python is a powerful open source programming language that is easy to learn, works well with most other tools and technologies. The best part about Python is that it has innumerable libraries and community created modules making it very robust. It has functions for statistical operation, model building and more.\",\n",
    "    \"R and Python?;R and Python are two of the most important programming languages for Machine Learning Algorithms.\",\n",
    "    \"Explain the various benefits of R language?;The R programming language includes a set of software suite that is used for graphical representation, statistical computing, data manipulation and calculation.\",\n",
    "    \"About R language?;An extensive collection of tools for data analysis\",\n",
    "    \"More about R language?;Operators for performing calculations on matrix and array\",\n",
    "    \"R includes?; Data analysis technique for graphical representation\",\n",
    "    \"About R language?; A highly developed yet simple and effective programming language\",\n",
    "    \n",
    "]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Hello\n",
      "The machine learning is good I agree, do you know ml +?\n",
      "I love the machine learning! Come to our meetups !!!\n",
      "I am passionate about machine learning Come to our meetups !!!\n",
      "I like the machine learning Come to our meetups\n",
      "What is the ML Machine LEarning\n",
      "Do you know the random forest Yes it is a supervised algorithm that matches a set of trees that corrects for the effect of overtraining sometimes observed!\n",
      "Do you know xgboost? Yes it is an algorithm developed by Kaggle that generates a set of decision trees slightly better than normal for performing a supervised task in ML\n",
      "Do you use xgboost? My colleagues use it for supervised tasks but rarely alone!\n",
      "What is xgboost? it is an algorithm developed by Kaggle that generates a set of decision trees slightly better than normal for performing a supervised task in ML\n",
      "Do you like artificial intelligence? I am artificial intelligence!\n",
      "How do you function? I use a text learning base to learn the context of my responses through various DL algorithms.\n",
      "That's the DL Deep Learning\n",
      "What does Deep LEarning mean? It is a sub-component of the Machine Learning to which the neural networks belong!\n",
      "What is DL? It is a sub-component of the Machine Learning to which the neural networks belong!\n",
      "The DL is part of the statistics? Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\n",
      "Dl = statistics? Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\n",
      "DL or statistics? Although it uses the fundamentals of statistics, Deep Learning is part of the artificial ingenuity that differs from statistics in that there is continuous learning!\n",
      "You were mistaken! It happens to me contact my boss!\n",
      "You are wrong! It happens to me contact my boss!\n",
      "You're stupid! It happens to me contact my boss!\n",
      "You are not very good! It happens to me contact my boss!\n",
      "You are not very good It happens to me contact my boss!\n",
      "You are pocket It happens to me contact my boss!\n",
      "You're really bad It happens to me contact my boss!\n",
      "You make mistakes! It happens to me contact my boss!\n",
      "Who's your boss? ML +\n",
      "Who is your boss? ML +\n",
      "Who's your boss? ML +\n",
      "Who your boss? ML +\n",
      "Do you like your boss? Yes\n",
      "You hate your boss? I like them !\n",
      "You speak weird! It happens to me contact my boss!\n",
      "You are bizarre! It happens to me contact my boss!\n",
      "Do you think about thinking!?! It happens to me contact my boss!\n",
      "You should try to think it happens to me contact my boss!\n",
      "You're really stupid I'm as smart as the sentences I've been trained with, Help me !;\n",
      "Thick I'm as smart as the sentences I've been trained with, Help me !;\n",
      "You're so thick I'm as smart as the sentences I've been trained with, Help me !;\n",
      "You're thick I'm as smart as the sentences I've been trained with, Help me !;\n",
      "You're stupid I'm as smart as the sentences I've been trained with, Help me!\n",
      "You're bad I'm as smart as the sentences I've been trained with, Help me!\n",
      "You're good for nothing I'm as smart as the sentences I've been trained with, Help me !;\n",
      "You suck I'm as smart as the sentences I've been trained with, Help me !;\n",
      "T pocket I'm as smart as the sentences I've been trained with, Help me!;)\n",
      "You're really bad I'm as smart as the sentences I've been trained with, Help me !;\n",
      "You are not very talented! I am as intelligent as the sentences I was trained with, Help me!\n",
      "Does your team have talented people? Tons!!!\n",
      "Your team is good? The best !\n",
      "Your team is talented? Really!!!\n",
      "Hello, I heard that you were bad ... I'm as smart as the sentences I was trained with, Help me!\n",
      "Regression or Classification Hello Hello\n",
      "Sup Hello\n",
      "Wazza Hello\n",
      "Hello hello hello\n",
      "Sup ML Hello\n",
      "Hello how are you ? Hello, very good and you?\n",
      "Hello do you have time this week? Please check with info@ml.plus!\n",
      "Free this week? Please check with info@ml.plus!\n",
      "I have some questions about machine learning How can I clear you up?\n",
      "What does AI mean Artificial Intelligence\n",
      "What does ML Machine Learning mean?\n",
      "What is the meaning of AI Artificial Intelligence\n",
      "What is the meaning of ML Machine Learning\n",
      "Quest it means ML Machine Learning\n",
      "What is IA for? Artificial intelligence\n",
      "What is the difference between supervised and unsupervised Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\n",
      "Supervised or non-supervised? Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\n",
      "When are we talking about supervised? Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\n",
      "Supervised? Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\n",
      "Unsupervised? Supervised are classification or regression algorithms while unsupervised are mostly segmentation algorithms.\n",
      "What is the difference between statistics and AI? The statistics describe but do not allow continuous learning.\n",
      "Statistics or AI? The statistics describe but do not allow continuous learning.\n",
      "Stats or AI The statistic describes but does not allow continuous learning.\n",
      "Stats or ML The statistic describes but does not allow continuous learning.\n",
      "Stats or ML? The statistics describe but do not allow continuous learning.\n",
      "Statistics or AI The statistics describe but do not allow continuous learning.\n",
      "Applied statistics or AI The statistics describe but do not allow continuous learning.\n",
      "Hello, I'm wondering about AI. Hello, how can I clear you up?\n",
      "Hello, I have questions. Hello, how can I clear you up?\n",
      "Hello, I'm wondering about the ML Hello, how can I clear you up?\n",
      "Hello, what does ML mean? Machine Learning\n",
      "If I have classes in my dataset what kind of learning is this? Supervised!\n",
      "If, I do not have classes, what type? Unsupervised!\n",
      "I have classes is supervised? Yes\n",
      "I do not have classes it's supervised? No\n",
      "I have a continuous value this is a classification No\n",
      "I have a continuous value It's a regression Yes\n",
      "A regression is always continuous? Yes\n",
      "Hello, a regression c is ML? Of course !\n",
      "SUP, what is a classiication? It's a type of supervised problem where you have different groups.\n",
      "What is classfication? It's a type of supervised problem where you have different groups.\n",
      "Who works at your place? Me and some others :)!\n",
      "Who is part of your team? Me and some others :)!\n",
      "You work for ML + Me and some others :)!\n",
      "Your team is great? There is me and some others :)!\n",
      "Nicolas work with you? Me and some others :)!\n",
      "Julien work with you? Me and some others :)!\n",
      "Jules work with you Me and some others :)!\n",
      "Nico is with you? Me and some others :)!\n",
      "Nico is at ml + Yes\n",
      "Jules is at ml + Yes\n",
      "And Louis? S.V.P. repeat the question?\n",
      "Louis is at ml + Yes\n",
      "Louis work at home? Yes\n",
      "Alex works at ML + Yes, which one?\n",
      "Do you like ml + YES\n",
      "ML + is good? The best startup!\n",
      "What do you think of Element AI? It's a beautiful company!\n",
      "What do you think of AI? A world of possibility!\n",
      "Do you like AI? Yes\n",
      "You're AI I'm learning every day!\n",
      "Do you learn? Yes every day !\n",
      "Do you like learning? I adore!\n",
      "Do you make jokes? I'm not very funny but I'm working on it!\n",
      "Do you like to laugh? I am more mathematical :)\n",
      "So you like maths? I am the maths\n",
      "Math is you? Exactly\n",
      "You like mathematics I am maths\n",
      "You love Nicolas He is good\n",
      "You like Nico He's great\n",
      "Do you like Nico? Yes\n",
      "You do not like Nico I like it!\n",
      "Do you like JUles? Yes, he is good!\n",
      "Julien? It's my boss!\n",
      "Do you like to laugh? Do you like learning? I adore!\n",
      "Nico is with you? Me and some others :)!, I'm more math :)\n",
      "Hello Hello, how are you?\n",
      "Hello Wazza\n",
      "Wazza Sup\n",
      "Jules st at m + Yes\n",
      "Louisest at ml + Yes\n",
      "Alex trvailles at ML + Yes, which one?\n",
      "Do you like AI? Yes\n",
      "Do you like learning? I adore!\n",
      "Do you like dogs? Jinx is the best!\n",
      "What do you think of AI? It's amazing!\n",
      "Are you great? I am IA so YES!\n",
      "Your team is great? She's great!\n",
      "Great is good for you? Yes\n",
      "Great is negative for no? No\n",
      "Great is not good for you? No\n",
      "Do you understand the nuances? I really do not know but learn!\n",
      "Do you speak other languages ​​No\n",
      "Do you like Montreal? I just love it!!!\n",
      "Do you like dogs? Jinx is my favorite\n",
      "Your team is great? The best!\n",
      "Do you speak any other languages? Not yet\n",
      "Do you like Montreal? it's the best city in the world\n"
     ]
    }
   ],
   "source": [
    "en_lines = open('t-en', 'r').readlines()\n",
    "\n",
    "for line in en_lines:\n",
    "    line = line.strip()\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 1\n",
      "Number of unique input tokens: 28\n",
      "Number of unique output tokens: 34\n",
      "Max sequence length for inputs: 146\n",
      "Max sequence length for outputs: 172\n",
      "Train on 0 samples, validate on 1 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ProgbarLogger' object has no attribute 'log_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-527c5883d457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m           validation_split=0.2)\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ML.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProgbarLogger' object has no attribute 'log_values'"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 50  # Number of epochs to train for.\n",
    "latent_dim = 264  # Latent dimensionality of the encoding space.\n",
    "num_samples = 13000  # Number of samples to train on.\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for line in sequence[: min(num_samples, len(sequence) - 1)]:\n",
    "    try:\n",
    "        input_text, target_text = line.split('    ')\n",
    "        # We use \"tab\" as the \"start sequence\" character\n",
    "        # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "        target_text = '\\t' + target_text + '\\n'\n",
    "        input_texts.append(input_text)\n",
    "        target_texts.append(target_text)\n",
    "        for char in input_text:\n",
    "            if char not in input_characters:\n",
    "                input_characters.add(char)\n",
    "        for char in target_text:\n",
    "            if char not in target_characters:\n",
    "                target_characters.add(char)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = int(max([len(txt) for txt in input_texts]))\n",
    "max_decoder_seq_length = int(max([len(txt) for txt in target_texts]))\n",
    "\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# Save model\n",
    "model.save('ML.h5')\n",
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
